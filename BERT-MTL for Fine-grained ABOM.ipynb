{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled13.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b53f5eb27fe9430a91946c470f3554d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2cc0a1eabf9a4b718bfc5481fd66c804",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c151cd6f61c6438895bf1c74876d369f",
              "IPY_MODEL_83addfc484024a1ba06c45436f434805"
            ]
          }
        },
        "2cc0a1eabf9a4b718bfc5481fd66c804": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c151cd6f61c6438895bf1c74876d369f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b79f086b28cb402c897055b0e172ef25",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_29b6ab9532e249278125b31d8a42dc53"
          }
        },
        "83addfc484024a1ba06c45436f434805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c43d7098642043d9bd4d05488c58dab1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:01&lt;00:00, 163kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d2d24d547fa486496639bc298c6483a"
          }
        },
        "b79f086b28cb402c897055b0e172ef25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "29b6ab9532e249278125b31d8a42dc53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c43d7098642043d9bd4d05488c58dab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d2d24d547fa486496639bc298c6483a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24d2c1aaf728447784aa7600b7d66e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7f7ee778219d4b7badeceb7aef9dd25f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_636a9a3f42fe489ba464cb478ae650a1",
              "IPY_MODEL_4419bfa7d3fb429cadfcc7f3ec52d7a5"
            ]
          }
        },
        "7f7ee778219d4b7badeceb7aef9dd25f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "636a9a3f42fe489ba464cb478ae650a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2a2d7d092f76482d8b87048e545f3b8a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7904e02d491c448487974dcf0c531f68"
          }
        },
        "4419bfa7d3fb429cadfcc7f3ec52d7a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5920ecdc6f594e80ae119aea6e75c041",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:01&lt;00:00, 27.2B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71c46c42fe8b4d829dadf32d44655feb"
          }
        },
        "2a2d7d092f76482d8b87048e545f3b8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7904e02d491c448487974dcf0c531f68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5920ecdc6f594e80ae119aea6e75c041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71c46c42fe8b4d829dadf32d44655feb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "991c77aab42144ff86b691da2ee5d082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fd1281a80cd94f299cea2c3d66cbd114",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d43adfd7363f42199b62f7fbdeb14c9d",
              "IPY_MODEL_be387c77f6434ff0b2425c8fdf99219c"
            ]
          }
        },
        "fd1281a80cd94f299cea2c3d66cbd114": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d43adfd7363f42199b62f7fbdeb14c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_795fa999acdd45a3808f276d4fc120e2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_470caaa969124aa791640a66a6357576"
          }
        },
        "be387c77f6434ff0b2425c8fdf99219c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9dad56ce2f7849f39a0b97f100a4858a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 1.06MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_96b2e47cd50943629127d3e1672db34f"
          }
        },
        "795fa999acdd45a3808f276d4fc120e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "470caaa969124aa791640a66a6357576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9dad56ce2f7849f39a0b97f100a4858a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "96b2e47cd50943629127d3e1672db34f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c8e6ebc9caa4364ab29e68751be987f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_df6a198811c24358ae9dcbe8929caa3f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_36e2956ede534c90ae1abe01c84902ef",
              "IPY_MODEL_352fb175e39a4f9ab991b96a9676e1b4"
            ]
          }
        },
        "df6a198811c24358ae9dcbe8929caa3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36e2956ede534c90ae1abe01c84902ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5633df988ea74565861305921979ff7e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4744c736c3da47aa9f9130be212de5fa"
          }
        },
        "352fb175e39a4f9ab991b96a9676e1b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7db9901f29ac45a4837d8c7090bc9745",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:08&lt;00:00, 49.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fca5e7f600f1400e95d3d69fbecea84d"
          }
        },
        "5633df988ea74565861305921979ff7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4744c736c3da47aa9f9130be212de5fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7db9901f29ac45a4837d8c7090bc9745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fca5e7f600f1400e95d3d69fbecea84d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "738171b5811a47119009044c40751ce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fe8aed1d4e834961ae1fb0cd0e47b7c0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f74e9ee52b674cc28553bb277a533366",
              "IPY_MODEL_252e934abc814ac4842a9bea32bdd528"
            ]
          }
        },
        "fe8aed1d4e834961ae1fb0cd0e47b7c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f74e9ee52b674cc28553bb277a533366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fee7059287654f7691e50cdfa3aeade1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ebaf5e0eb39438f92e8e4fd1c31cef2"
          }
        },
        "252e934abc814ac4842a9bea32bdd528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c49bde7aead14b2685afc69954b1a5d8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:08&lt;00:00, 53.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea8d20c007de4f15872e0f849f47d29d"
          }
        },
        "fee7059287654f7691e50cdfa3aeade1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ebaf5e0eb39438f92e8e4fd1c31cef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c49bde7aead14b2685afc69954b1a5d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea8d20c007de4f15872e0f849f47d29d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcGcgPVYocEv",
        "outputId": "67f9288f-d3d0-4713-deba-ce9da1148a38"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.0MB 13.0MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870kB 36.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 55.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=9992b76608295a6fc83ec43f09059f2433966dce49cee56108e3af735121d3ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.44 tokenizers-0.10.2 transformers-4.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9hnYXthoev0"
      },
      "source": [
        "# Importing stock ml libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertModel, BertConfig"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lJnf3iEohzx",
        "outputId": "e06a40c2-c371-47f7-f6f6-6ee251bc456b"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fbb9757cbb0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnWMmajxrbIK"
      },
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8LhDMtXonB3",
        "outputId": "472d1ee5-ffe7-4800-ab5e-ccab49e34b82"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "OVB7PAi_oqZ0",
        "outputId": "2c20d3c8-2712-490c-de65-248b11201d07"
      },
      "source": [
        "df_te = pd.read_csv('/content/drive/My Drive/revisedATSA.csv')\n",
        "df_te = df_te.rename(columns={'sentence': 'text', 'aspect': 'aspect_term', 'sentiment': 'Class'})\n",
        "df_te.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>aspect_term</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the bread is top notch as well.</td>\n",
              "      <td>bread</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i have to say they have one of the fastest del...</td>\n",
              "      <td>delivery times</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>food is always fresh and hot- ready to eat!</td>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>did i mention that the coffee is outstanding?</td>\n",
              "      <td>coffee</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>certainly not the best sushi in new york, howe...</td>\n",
              "      <td>place</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text     aspect_term     Class\n",
              "0                    the bread is top notch as well.           bread  positive\n",
              "1  i have to say they have one of the fastest del...  delivery times  positive\n",
              "2        food is always fresh and hot- ready to eat!            food  positive\n",
              "3      did i mention that the coffee is outstanding?          coffee  positive\n",
              "4  certainly not the best sushi in new york, howe...           place  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXNbcGtm0kPi",
        "outputId": "196306ae-6567-485b-faf4-eacbb6ce3da7"
      },
      "source": [
        "df_te.Class.count()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1120"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ltZiZOO9o6iv",
        "outputId": "574bb569-b8f1-4f43-cc4e-dad49f0020d2"
      },
      "source": [
        "#df_te = df_te.drop(df_te.index[df_te['Class'] == 'conflict'], inplace = True)\n",
        "#df_te.Class = df_te.Class.replace('conflict', 'neutral') \n",
        "df_test = df_te\n",
        "df_test.shape\n",
        "df_test.head(50)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>aspect_term</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the bread is top notch as well.</td>\n",
              "      <td>bread</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i have to say they have one of the fastest del...</td>\n",
              "      <td>delivery times</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>food is always fresh and hot- ready to eat!</td>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>did i mention that the coffee is outstanding?</td>\n",
              "      <td>coffee</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>certainly not the best sushi in new york, howe...</td>\n",
              "      <td>place</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i trust the people at go sushi, it never disap...</td>\n",
              "      <td>people</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>straight-forward, no surprises, very decent ja...</td>\n",
              "      <td>japanese food</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>best spicy tuna roll, great asian salad.</td>\n",
              "      <td>asian salad</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>best spicy tuna roll, great asian salad.</td>\n",
              "      <td>spicy tuna roll</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>try the rose roll (not on menu).</td>\n",
              "      <td>rose roll</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>try the rose roll (not on menu).</td>\n",
              "      <td>menu</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>i love the drinks, esp lychee martini, and the...</td>\n",
              "      <td>drinks</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>i love the drinks, esp lychee martini, and the...</td>\n",
              "      <td>lychee martini</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>i love the drinks, esp lychee martini, and the...</td>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>in fact, this was not a nicoise salad and was ...</td>\n",
              "      <td>nicoise salad</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>while there's a decent menu, it shouldn't take...</td>\n",
              "      <td>menu</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>while there's a decent menu, it shouldn't take...</td>\n",
              "      <td>drinks</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>while there's a decent menu, it shouldn't take...</td>\n",
              "      <td>dessert pizza</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>once we sailed, the top-notch food and live en...</td>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>once we sailed, the top-notch food and live en...</td>\n",
              "      <td>live entertainment</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>our waiter was horrible; so rude and disintere...</td>\n",
              "      <td>waiter</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>the sangria's - watered down.</td>\n",
              "      <td>sangria</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>menu - uneventful, small.</td>\n",
              "      <td>menu</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>anytime and everytime i find myself in the nei...</td>\n",
              "      <td>sushi</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>anytime and everytime i find myself in the nei...</td>\n",
              "      <td>portions</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>anytime and everytime i find myself in the nei...</td>\n",
              "      <td>price</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>great food but the service was dreadful!</td>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>great food but the service was dreadful!</td>\n",
              "      <td>service</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>the portions of the food that came out were me...</td>\n",
              "      <td>portions of the food</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>the two waitress's looked like they had been s...</td>\n",
              "      <td>waitress's</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>from the beginning, we were met by friendly st...</td>\n",
              "      <td>staff memebers</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>from the beginning, we were met by friendly st...</td>\n",
              "      <td>parking</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>we enjoyed ourselves thoroughly and will be go...</td>\n",
              "      <td>desserts</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>desserts are almost incredible: my personal fa...</td>\n",
              "      <td>desserts</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>desserts are almost incredible: my personal fa...</td>\n",
              "      <td>tart of the day</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>the food was extremely tasty, creatively prese...</td>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>the food was extremely tasty, creatively prese...</td>\n",
              "      <td>wine</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>the lasagna was probably the best i have tasted.</td>\n",
              "      <td>lasagna</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>harumi sushi has the freshest and most delicio...</td>\n",
              "      <td>array of sushi</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>i highly recommend it for not just its superb ...</td>\n",
              "      <td>cuisine</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>i highly recommend it for not just its superb ...</td>\n",
              "      <td>owners</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>i highly recommend it for not just its superb ...</td>\n",
              "      <td>staff</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>if you're craving some serious indian food and...</td>\n",
              "      <td>indian food</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>if you're craving some serious indian food and...</td>\n",
              "      <td>ambiance</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>i definitely enjoyed the food as well.</td>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>it was pleasantly uncrowded, the service was d...</td>\n",
              "      <td>service</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>it was pleasantly uncrowded, the service was d...</td>\n",
              "      <td>garden</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>it was pleasantly uncrowded, the service was d...</td>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>it was pleasantly uncrowded, the service was d...</td>\n",
              "      <td>appetizers</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>it was pleasantly uncrowded, the service was d...</td>\n",
              "      <td>entrees</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text  ...     Class\n",
              "0                     the bread is top notch as well.  ...  positive\n",
              "1   i have to say they have one of the fastest del...  ...  positive\n",
              "2         food is always fresh and hot- ready to eat!  ...  positive\n",
              "3       did i mention that the coffee is outstanding?  ...  positive\n",
              "4   certainly not the best sushi in new york, howe...  ...  positive\n",
              "5   i trust the people at go sushi, it never disap...  ...  positive\n",
              "6   straight-forward, no surprises, very decent ja...  ...  positive\n",
              "7            best spicy tuna roll, great asian salad.  ...  positive\n",
              "8            best spicy tuna roll, great asian salad.  ...  positive\n",
              "9                    try the rose roll (not on menu).  ...  positive\n",
              "10                   try the rose roll (not on menu).  ...   neutral\n",
              "11  i love the drinks, esp lychee martini, and the...  ...  positive\n",
              "12  i love the drinks, esp lychee martini, and the...  ...  positive\n",
              "13  i love the drinks, esp lychee martini, and the...  ...  positive\n",
              "14  in fact, this was not a nicoise salad and was ...  ...  negative\n",
              "15  while there's a decent menu, it shouldn't take...  ...  positive\n",
              "16  while there's a decent menu, it shouldn't take...  ...   neutral\n",
              "17  while there's a decent menu, it shouldn't take...  ...   neutral\n",
              "18  once we sailed, the top-notch food and live en...  ...  positive\n",
              "19  once we sailed, the top-notch food and live en...  ...  positive\n",
              "20  our waiter was horrible; so rude and disintere...  ...  negative\n",
              "21                      the sangria's - watered down.  ...  negative\n",
              "22                          menu - uneventful, small.  ...  negative\n",
              "23  anytime and everytime i find myself in the nei...  ...  positive\n",
              "24  anytime and everytime i find myself in the nei...  ...  positive\n",
              "25  anytime and everytime i find myself in the nei...  ...  positive\n",
              "26           great food but the service was dreadful!  ...  positive\n",
              "27           great food but the service was dreadful!  ...  negative\n",
              "28  the portions of the food that came out were me...  ...   neutral\n",
              "29  the two waitress's looked like they had been s...  ...  negative\n",
              "30  from the beginning, we were met by friendly st...  ...  positive\n",
              "31  from the beginning, we were met by friendly st...  ...  positive\n",
              "32  we enjoyed ourselves thoroughly and will be go...  ...  positive\n",
              "33  desserts are almost incredible: my personal fa...  ...  positive\n",
              "34  desserts are almost incredible: my personal fa...  ...  positive\n",
              "35  the food was extremely tasty, creatively prese...  ...  positive\n",
              "36  the food was extremely tasty, creatively prese...  ...  positive\n",
              "37   the lasagna was probably the best i have tasted.  ...  positive\n",
              "38  harumi sushi has the freshest and most delicio...  ...  positive\n",
              "39  i highly recommend it for not just its superb ...  ...  positive\n",
              "40  i highly recommend it for not just its superb ...  ...  positive\n",
              "41  i highly recommend it for not just its superb ...  ...  positive\n",
              "42  if you're craving some serious indian food and...  ...  positive\n",
              "43  if you're craving some serious indian food and...  ...  positive\n",
              "44             i definitely enjoyed the food as well.  ...  positive\n",
              "45  it was pleasantly uncrowded, the service was d...  ...  positive\n",
              "46  it was pleasantly uncrowded, the service was d...  ...  positive\n",
              "47  it was pleasantly uncrowded, the service was d...  ...  positive\n",
              "48  it was pleasantly uncrowded, the service was d...  ...  positive\n",
              "49  it was pleasantly uncrowded, the service was d...  ...  positive\n",
              "\n",
              "[50 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "5H6hJfsVo-QK",
        "outputId": "2d3d9cd6-ea82-43b5-93f1-d2e8d957ab41"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# label_encoder object knows how to understand word labels. \n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "# Encode labels in column 'Country'. \n",
        "df_test['Class']= label_encoder.fit_transform(df_test['Class']) \n",
        "df_test.head()\n",
        "\n",
        "onehotencoder = preprocessing.OneHotEncoder()\n",
        "#reshape the 1-D country array to 2-D as fit_transform expects 2-D and finally fit the object \n",
        "X = onehotencoder.fit_transform(df_test.Class.values.reshape(-1,1)).toarray()\n",
        "#To add this back into the original dataframe \n",
        "dfOneHot = pd.DataFrame(X, columns = [\"Class_\"+str(int(i)) for i in range(df_test.shape[1])]) \n",
        "df_test = pd.concat([df_test, dfOneHot], axis=1)\n",
        "#droping the country column \n",
        "df_test= df_test.drop(['Class'], axis=1) \n",
        "#printing to verify \n",
        "df_test.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>aspect_term</th>\n",
              "      <th>Class_0</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the bread is top notch as well.</td>\n",
              "      <td>bread</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i have to say they have one of the fastest del...</td>\n",
              "      <td>delivery times</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>food is always fresh and hot- ready to eat!</td>\n",
              "      <td>food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>did i mention that the coffee is outstanding?</td>\n",
              "      <td>coffee</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>certainly not the best sushi in new york, howe...</td>\n",
              "      <td>place</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ... Class_2\n",
              "0                    the bread is top notch as well.  ...     1.0\n",
              "1  i have to say they have one of the fastest del...  ...     1.0\n",
              "2        food is always fresh and hot- ready to eat!  ...     1.0\n",
              "3      did i mention that the coffee is outstanding?  ...     1.0\n",
              "4  certainly not the best sushi in new york, howe...  ...     1.0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w0FdSU9nmKWn",
        "outputId": "fd12626b-6635-4585-c70b-deded01d25ab"
      },
      "source": [
        "\n",
        "df_test.info()\n",
        "df_test.head(50)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1120 entries, 0 to 1119\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   text         1120 non-null   object \n",
            " 1   aspect_term  1120 non-null   object \n",
            " 2   Class_0      1120 non-null   float64\n",
            " 3   Class_1      1120 non-null   float64\n",
            " 4   Class_2      1120 non-null   float64\n",
            "dtypes: float64(3), object(2)\n",
            "memory usage: 43.9+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>aspect_term</th>\n",
              "      <th>Class_0</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the bread is top notch as well.</td>\n",
              "      <td>bread</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i have to say they have one of the fastest del...</td>\n",
              "      <td>delivery times</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>food is always fresh and hot- ready to eat!</td>\n",
              "      <td>food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>did i mention that the coffee is outstanding?</td>\n",
              "      <td>coffee</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>certainly not the best sushi in new york, howe...</td>\n",
              "      <td>place</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i trust the people at go sushi, it never disap...</td>\n",
              "      <td>people</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>straight-forward, no surprises, very decent ja...</td>\n",
              "      <td>japanese food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>best spicy tuna roll, great asian salad.</td>\n",
              "      <td>asian salad</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>best spicy tuna roll, great asian salad.</td>\n",
              "      <td>spicy tuna roll</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>try the rose roll (not on menu).</td>\n",
              "      <td>rose roll</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>try the rose roll (not on menu).</td>\n",
              "      <td>menu</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>i love the drinks, esp lychee martini, and the...</td>\n",
              "      <td>drinks</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>i love the drinks, esp lychee martini, and the...</td>\n",
              "      <td>lychee martini</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>i love the drinks, esp lychee martini, and the...</td>\n",
              "      <td>food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>in fact, this was not a nicoise salad and was ...</td>\n",
              "      <td>nicoise salad</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>while there's a decent menu, it shouldn't take...</td>\n",
              "      <td>menu</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>while there's a decent menu, it shouldn't take...</td>\n",
              "      <td>drinks</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>while there's a decent menu, it shouldn't take...</td>\n",
              "      <td>dessert pizza</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>once we sailed, the top-notch food and live en...</td>\n",
              "      <td>food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>once we sailed, the top-notch food and live en...</td>\n",
              "      <td>live entertainment</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>our waiter was horrible; so rude and disintere...</td>\n",
              "      <td>waiter</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>the sangria's - watered down.</td>\n",
              "      <td>sangria</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>menu - uneventful, small.</td>\n",
              "      <td>menu</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>anytime and everytime i find myself in the nei...</td>\n",
              "      <td>sushi</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>anytime and everytime i find myself in the nei...</td>\n",
              "      <td>portions</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>anytime and everytime i find myself in the nei...</td>\n",
              "      <td>price</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>great food but the service was dreadful!</td>\n",
              "      <td>food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>great food but the service was dreadful!</td>\n",
              "      <td>service</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>the portions of the food that came out were me...</td>\n",
              "      <td>portions of the food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>the two waitress's looked like they had been s...</td>\n",
              "      <td>waitress's</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>from the beginning, we were met by friendly st...</td>\n",
              "      <td>staff memebers</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>from the beginning, we were met by friendly st...</td>\n",
              "      <td>parking</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>we enjoyed ourselves thoroughly and will be go...</td>\n",
              "      <td>desserts</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>desserts are almost incredible: my personal fa...</td>\n",
              "      <td>desserts</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>desserts are almost incredible: my personal fa...</td>\n",
              "      <td>tart of the day</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>the food was extremely tasty, creatively prese...</td>\n",
              "      <td>food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>the food was extremely tasty, creatively prese...</td>\n",
              "      <td>wine</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>the lasagna was probably the best i have tasted.</td>\n",
              "      <td>lasagna</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>harumi sushi has the freshest and most delicio...</td>\n",
              "      <td>array of sushi</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>i highly recommend it for not just its superb ...</td>\n",
              "      <td>cuisine</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>i highly recommend it for not just its superb ...</td>\n",
              "      <td>owners</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>i highly recommend it for not just its superb ...</td>\n",
              "      <td>staff</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>if you're craving some serious indian food and...</td>\n",
              "      <td>indian food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>if you're craving some serious indian food and...</td>\n",
              "      <td>ambiance</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>i definitely enjoyed the food as well.</td>\n",
              "      <td>food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>it was pleasantly uncrowded, the service was d...</td>\n",
              "      <td>service</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>it was pleasantly uncrowded, the service was d...</td>\n",
              "      <td>garden</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>it was pleasantly uncrowded, the service was d...</td>\n",
              "      <td>food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>it was pleasantly uncrowded, the service was d...</td>\n",
              "      <td>appetizers</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>it was pleasantly uncrowded, the service was d...</td>\n",
              "      <td>entrees</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text  ... Class_2\n",
              "0                     the bread is top notch as well.  ...     1.0\n",
              "1   i have to say they have one of the fastest del...  ...     1.0\n",
              "2         food is always fresh and hot- ready to eat!  ...     1.0\n",
              "3       did i mention that the coffee is outstanding?  ...     1.0\n",
              "4   certainly not the best sushi in new york, howe...  ...     1.0\n",
              "5   i trust the people at go sushi, it never disap...  ...     1.0\n",
              "6   straight-forward, no surprises, very decent ja...  ...     1.0\n",
              "7            best spicy tuna roll, great asian salad.  ...     1.0\n",
              "8            best spicy tuna roll, great asian salad.  ...     1.0\n",
              "9                    try the rose roll (not on menu).  ...     1.0\n",
              "10                   try the rose roll (not on menu).  ...     0.0\n",
              "11  i love the drinks, esp lychee martini, and the...  ...     1.0\n",
              "12  i love the drinks, esp lychee martini, and the...  ...     1.0\n",
              "13  i love the drinks, esp lychee martini, and the...  ...     1.0\n",
              "14  in fact, this was not a nicoise salad and was ...  ...     0.0\n",
              "15  while there's a decent menu, it shouldn't take...  ...     1.0\n",
              "16  while there's a decent menu, it shouldn't take...  ...     0.0\n",
              "17  while there's a decent menu, it shouldn't take...  ...     0.0\n",
              "18  once we sailed, the top-notch food and live en...  ...     1.0\n",
              "19  once we sailed, the top-notch food and live en...  ...     1.0\n",
              "20  our waiter was horrible; so rude and disintere...  ...     0.0\n",
              "21                      the sangria's - watered down.  ...     0.0\n",
              "22                          menu - uneventful, small.  ...     0.0\n",
              "23  anytime and everytime i find myself in the nei...  ...     1.0\n",
              "24  anytime and everytime i find myself in the nei...  ...     1.0\n",
              "25  anytime and everytime i find myself in the nei...  ...     1.0\n",
              "26           great food but the service was dreadful!  ...     1.0\n",
              "27           great food but the service was dreadful!  ...     0.0\n",
              "28  the portions of the food that came out were me...  ...     0.0\n",
              "29  the two waitress's looked like they had been s...  ...     0.0\n",
              "30  from the beginning, we were met by friendly st...  ...     1.0\n",
              "31  from the beginning, we were met by friendly st...  ...     1.0\n",
              "32  we enjoyed ourselves thoroughly and will be go...  ...     1.0\n",
              "33  desserts are almost incredible: my personal fa...  ...     1.0\n",
              "34  desserts are almost incredible: my personal fa...  ...     1.0\n",
              "35  the food was extremely tasty, creatively prese...  ...     1.0\n",
              "36  the food was extremely tasty, creatively prese...  ...     1.0\n",
              "37   the lasagna was probably the best i have tasted.  ...     1.0\n",
              "38  harumi sushi has the freshest and most delicio...  ...     1.0\n",
              "39  i highly recommend it for not just its superb ...  ...     1.0\n",
              "40  i highly recommend it for not just its superb ...  ...     1.0\n",
              "41  i highly recommend it for not just its superb ...  ...     1.0\n",
              "42  if you're craving some serious indian food and...  ...     1.0\n",
              "43  if you're craving some serious indian food and...  ...     1.0\n",
              "44             i definitely enjoyed the food as well.  ...     1.0\n",
              "45  it was pleasantly uncrowded, the service was d...  ...     1.0\n",
              "46  it was pleasantly uncrowded, the service was d...  ...     1.0\n",
              "47  it was pleasantly uncrowded, the service was d...  ...     1.0\n",
              "48  it was pleasantly uncrowded, the service was d...  ...     1.0\n",
              "49  it was pleasantly uncrowded, the service was d...  ...     1.0\n",
              "\n",
              "[50 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2EXq7tmvbxj",
        "outputId": "698ea24c-3245-4e70-bbf0-91941c4af496"
      },
      "source": [
        "df_test.iloc[217]\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text           waiters are very friendly and the pasta is out...\n",
              "aspect_term                                                pasta\n",
              "Class_0                                                        0\n",
              "Class_1                                                        0\n",
              "Class_2                                                        1\n",
              "Name: 217, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "4HsUY4WEpA4m",
        "outputId": "4c32c9eb-ef72-48b0-fa6b-f12db1a35cd1"
      },
      "source": [
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/data_2_train.csv')\n",
        "df.head()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>example_id</th>\n",
              "      <th>text</th>\n",
              "      <th>aspect_term</th>\n",
              "      <th>term_location</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3121_0</td>\n",
              "      <td>But the staff was so horrible to us.</td>\n",
              "      <td>staff</td>\n",
              "      <td>8--13</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2777_0</td>\n",
              "      <td>To be completely fair[comma] the only redeemin...</td>\n",
              "      <td>food</td>\n",
              "      <td>57--61</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1634_0</td>\n",
              "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
              "      <td>food</td>\n",
              "      <td>4--8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1634_1</td>\n",
              "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
              "      <td>kitchen</td>\n",
              "      <td>55--62</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1634_2</td>\n",
              "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
              "      <td>menu</td>\n",
              "      <td>141--145</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  example_id  ...  class\n",
              "0     3121_0  ...     -1\n",
              "1     2777_0  ...      1\n",
              "2     1634_0  ...      1\n",
              "3     1634_1  ...      1\n",
              "4     1634_2  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "C8mp0CbjpEAP",
        "outputId": "9a3f1d9b-ed99-4c5a-ad05-9cf7da632b55"
      },
      "source": [
        "\n",
        "def to_sentiment(rating):\n",
        "  rating = int(rating)\n",
        "  if rating == 1:\n",
        "    return 2\n",
        "  elif rating == 0:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "df['sentiment'] = df[' class'].apply(to_sentiment)\n",
        "\n",
        "#df['sentiment'] = df[' class']\n",
        "class_names = ['negative', 'neutral', 'positive']\n",
        "ax = sns.countplot(df.sentiment)\n",
        "plt.xlabel('review sentiment')\n",
        "ax.set_xticklabels(class_names);\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 410,
              "height": 272
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "2aoA-TwYpHWg",
        "outputId": "9ac26bac-9f3a-42ae-c7bd-5d8d927fe7c7"
      },
      "source": [
        "df.info()\n",
        "df = df.rename(columns={' text': 'text', ' aspect_term': 'aspect_term', ' term_location': 'term_location', ' example_id': 'example_id', ' class': 'class'})\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('[comma]',',').lower())\n",
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3602 entries, 0 to 3601\n",
            "Data columns (total 6 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   example_id      3602 non-null   object\n",
            " 1    text           3602 non-null   object\n",
            " 2    aspect_term    3602 non-null   object\n",
            " 3    term_location  3602 non-null   object\n",
            " 4    class          3602 non-null   int64 \n",
            " 5   sentiment       3602 non-null   int64 \n",
            "dtypes: int64(2), object(4)\n",
            "memory usage: 169.0+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>example_id</th>\n",
              "      <th>text</th>\n",
              "      <th>aspect_term</th>\n",
              "      <th>term_location</th>\n",
              "      <th>class</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3121_0</td>\n",
              "      <td>but the staff was so horrible to us.</td>\n",
              "      <td>staff</td>\n",
              "      <td>8--13</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2777_0</td>\n",
              "      <td>to be completely fair, the only redeeming fact...</td>\n",
              "      <td>food</td>\n",
              "      <td>57--61</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1634_0</td>\n",
              "      <td>the food is uniformly exceptional, with a very...</td>\n",
              "      <td>food</td>\n",
              "      <td>4--8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1634_1</td>\n",
              "      <td>the food is uniformly exceptional, with a very...</td>\n",
              "      <td>kitchen</td>\n",
              "      <td>55--62</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1634_2</td>\n",
              "      <td>the food is uniformly exceptional, with a very...</td>\n",
              "      <td>menu</td>\n",
              "      <td>141--145</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  example_id  ... sentiment\n",
              "0     3121_0  ...         0\n",
              "1     2777_0  ...         2\n",
              "2     1634_0  ...         2\n",
              "3     1634_1  ...         2\n",
              "4     1634_2  ...         1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "YN8vnG4wwPBU",
        "outputId": "71817c7e-5645-468c-be8a-9e78e377fd69"
      },
      "source": [
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "onehotencoder = preprocessing.OneHotEncoder()\n",
        "#reshape the 1-D country array to 2-D as fit_transform expects 2-D and finally fit the object \n",
        "X = onehotencoder.fit_transform(df.sentiment.values.reshape(-1,1)).toarray()\n",
        "#To add this back into the original dataframe \n",
        "df= df.drop(['example_id'], axis=1)\n",
        "df= df.drop(['class'], axis=1)\n",
        "df= df.drop(['term_location'], axis=1)\n",
        "dfOneHot = pd.DataFrame(X, columns = [\"Class_\"+str(int(i)) for i in range(df.shape[1])]) \n",
        "df = pd.concat([df, dfOneHot], axis=1)\n",
        "#droping the country column \n",
        "df= df.drop(['sentiment'], axis=1) \n",
        "#printing to verify \n",
        "df.head()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>aspect_term</th>\n",
              "      <th>Class_0</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>but the staff was so horrible to us.</td>\n",
              "      <td>staff</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>to be completely fair, the only redeeming fact...</td>\n",
              "      <td>food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the food is uniformly exceptional, with a very...</td>\n",
              "      <td>food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the food is uniformly exceptional, with a very...</td>\n",
              "      <td>kitchen</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the food is uniformly exceptional, with a very...</td>\n",
              "      <td>menu</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ... Class_2\n",
              "0               but the staff was so horrible to us.  ...     0.0\n",
              "1  to be completely fair, the only redeeming fact...  ...     1.0\n",
              "2  the food is uniformly exceptional, with a very...  ...     1.0\n",
              "3  the food is uniformly exceptional, with a very...  ...     1.0\n",
              "4  the food is uniformly exceptional, with a very...  ...     0.0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "YXfhVnr7yZ31",
        "outputId": "03b8167a-6cd7-45df-a31e-e8ab3a096c96"
      },
      "source": [
        "df_test['list'] = df_test[df_test.columns[2:]].values.tolist()\n",
        "new_df_test = df_test[['text', 'aspect_term', 'list']].copy()\n",
        "new_df_test.head(20)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>aspect_term</th>\n",
              "      <th>list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the bread is top notch as well.</td>\n",
              "      <td>bread</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i have to say they have one of the fastest del...</td>\n",
              "      <td>delivery times</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>food is always fresh and hot- ready to eat!</td>\n",
              "      <td>food</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>did i mention that the coffee is outstanding?</td>\n",
              "      <td>coffee</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>certainly not the best sushi in new york, howe...</td>\n",
              "      <td>place</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i trust the people at go sushi, it never disap...</td>\n",
              "      <td>people</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>straight-forward, no surprises, very decent ja...</td>\n",
              "      <td>japanese food</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>best spicy tuna roll, great asian salad.</td>\n",
              "      <td>asian salad</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>best spicy tuna roll, great asian salad.</td>\n",
              "      <td>spicy tuna roll</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>try the rose roll (not on menu).</td>\n",
              "      <td>rose roll</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>try the rose roll (not on menu).</td>\n",
              "      <td>menu</td>\n",
              "      <td>[0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>i love the drinks, esp lychee martini, and the...</td>\n",
              "      <td>drinks</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>i love the drinks, esp lychee martini, and the...</td>\n",
              "      <td>lychee martini</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>i love the drinks, esp lychee martini, and the...</td>\n",
              "      <td>food</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>in fact, this was not a nicoise salad and was ...</td>\n",
              "      <td>nicoise salad</td>\n",
              "      <td>[1.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>while there's a decent menu, it shouldn't take...</td>\n",
              "      <td>menu</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>while there's a decent menu, it shouldn't take...</td>\n",
              "      <td>drinks</td>\n",
              "      <td>[0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>while there's a decent menu, it shouldn't take...</td>\n",
              "      <td>dessert pizza</td>\n",
              "      <td>[0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>once we sailed, the top-notch food and live en...</td>\n",
              "      <td>food</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>once we sailed, the top-notch food and live en...</td>\n",
              "      <td>live entertainment</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text  ...             list\n",
              "0                     the bread is top notch as well.  ...  [0.0, 0.0, 1.0]\n",
              "1   i have to say they have one of the fastest del...  ...  [0.0, 0.0, 1.0]\n",
              "2         food is always fresh and hot- ready to eat!  ...  [0.0, 0.0, 1.0]\n",
              "3       did i mention that the coffee is outstanding?  ...  [0.0, 0.0, 1.0]\n",
              "4   certainly not the best sushi in new york, howe...  ...  [0.0, 0.0, 1.0]\n",
              "5   i trust the people at go sushi, it never disap...  ...  [0.0, 0.0, 1.0]\n",
              "6   straight-forward, no surprises, very decent ja...  ...  [0.0, 0.0, 1.0]\n",
              "7            best spicy tuna roll, great asian salad.  ...  [0.0, 0.0, 1.0]\n",
              "8            best spicy tuna roll, great asian salad.  ...  [0.0, 0.0, 1.0]\n",
              "9                    try the rose roll (not on menu).  ...  [0.0, 0.0, 1.0]\n",
              "10                   try the rose roll (not on menu).  ...  [0.0, 1.0, 0.0]\n",
              "11  i love the drinks, esp lychee martini, and the...  ...  [0.0, 0.0, 1.0]\n",
              "12  i love the drinks, esp lychee martini, and the...  ...  [0.0, 0.0, 1.0]\n",
              "13  i love the drinks, esp lychee martini, and the...  ...  [0.0, 0.0, 1.0]\n",
              "14  in fact, this was not a nicoise salad and was ...  ...  [1.0, 0.0, 0.0]\n",
              "15  while there's a decent menu, it shouldn't take...  ...  [0.0, 0.0, 1.0]\n",
              "16  while there's a decent menu, it shouldn't take...  ...  [0.0, 1.0, 0.0]\n",
              "17  while there's a decent menu, it shouldn't take...  ...  [0.0, 1.0, 0.0]\n",
              "18  once we sailed, the top-notch food and live en...  ...  [0.0, 0.0, 1.0]\n",
              "19  once we sailed, the top-notch food and live en...  ...  [0.0, 0.0, 1.0]\n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "r-WOXKcVyZni",
        "outputId": "25539ff2-df1c-44a7-8bcf-52e9444dab8f"
      },
      "source": [
        "df['list'] = df[df.columns[2:]].values.tolist()\n",
        "new_df = df[['text', 'aspect_term', 'list']].copy()\n",
        "new_df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>aspect_term</th>\n",
              "      <th>list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>but the staff was so horrible to us.</td>\n",
              "      <td>staff</td>\n",
              "      <td>[1.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>to be completely fair, the only redeeming fact...</td>\n",
              "      <td>food</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the food is uniformly exceptional, with a very...</td>\n",
              "      <td>food</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the food is uniformly exceptional, with a very...</td>\n",
              "      <td>kitchen</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the food is uniformly exceptional, with a very...</td>\n",
              "      <td>menu</td>\n",
              "      <td>[0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...             list\n",
              "0               but the staff was so horrible to us.  ...  [1.0, 0.0, 0.0]\n",
              "1  to be completely fair, the only redeeming fact...  ...  [0.0, 0.0, 1.0]\n",
              "2  the food is uniformly exceptional, with a very...  ...  [0.0, 0.0, 1.0]\n",
              "3  the food is uniformly exceptional, with a very...  ...  [0.0, 0.0, 1.0]\n",
              "4  the food is uniformly exceptional, with a very...  ...  [0.0, 1.0, 0.0]\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "b53f5eb27fe9430a91946c470f3554d8",
            "2cc0a1eabf9a4b718bfc5481fd66c804",
            "c151cd6f61c6438895bf1c74876d369f",
            "83addfc484024a1ba06c45436f434805",
            "b79f086b28cb402c897055b0e172ef25",
            "29b6ab9532e249278125b31d8a42dc53",
            "c43d7098642043d9bd4d05488c58dab1",
            "3d2d24d547fa486496639bc298c6483a",
            "24d2c1aaf728447784aa7600b7d66e91",
            "7f7ee778219d4b7badeceb7aef9dd25f",
            "636a9a3f42fe489ba464cb478ae650a1",
            "4419bfa7d3fb429cadfcc7f3ec52d7a5",
            "2a2d7d092f76482d8b87048e545f3b8a",
            "7904e02d491c448487974dcf0c531f68",
            "5920ecdc6f594e80ae119aea6e75c041",
            "71c46c42fe8b4d829dadf32d44655feb",
            "991c77aab42144ff86b691da2ee5d082",
            "fd1281a80cd94f299cea2c3d66cbd114",
            "d43adfd7363f42199b62f7fbdeb14c9d",
            "be387c77f6434ff0b2425c8fdf99219c",
            "795fa999acdd45a3808f276d4fc120e2",
            "470caaa969124aa791640a66a6357576",
            "9dad56ce2f7849f39a0b97f100a4858a",
            "96b2e47cd50943629127d3e1672db34f"
          ]
        },
        "id": "Q7V4T0RupWue",
        "outputId": "d6dcb29a-87c9-446c-928e-2478758a960f"
      },
      "source": [
        "# Sections of config\n",
        "\n",
        "# Defining some key variables that will be used later on in the training\n",
        "MAX_LEN = 100\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 8\n",
        "EPOCHS = 4\n",
        "#epochs = 3\n",
        "LEARNING_RATE = 2e-05\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',return_dict=False)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b53f5eb27fe9430a91946c470f3554d8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24d2c1aaf728447784aa7600b7d66e91",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "991c77aab42144ff86b691da2ee5d082",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jAli2nfpJzx"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.text\n",
        "        self.aspect_term = dataframe.aspect_term\n",
        "        self.targets = self.data.list\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "        aspect_term = str(self.aspect_term[index])\n",
        "        aspect_term = \" \".join(aspect_term.split())\n",
        "        #print(text)\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            aspect_term,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1j8XIrmpQbH",
        "outputId": "cbe14498-734d-4f3e-86e2-e48c6c805e20"
      },
      "source": [
        "# Creating the dataset and dataloader for the neural network\n",
        "\n",
        "train_size = 1.0\n",
        "test_size = 1.0\n",
        "train_dataset=new_df.sample(frac=train_size,random_state=200)\n",
        "test_dataset=new_df_test.sample(frac=test_size,random_state=200)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FULL Dataset: (3602, 6)\n",
            "TRAIN Dataset: (3602, 3)\n",
            "TEST Dataset: (1120, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__PM_crE0twH"
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0,\n",
        "                \n",
        "                }\n",
        "\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5c8e6ebc9caa4364ab29e68751be987f",
            "df6a198811c24358ae9dcbe8929caa3f",
            "36e2956ede534c90ae1abe01c84902ef",
            "352fb175e39a4f9ab991b96a9676e1b4",
            "5633df988ea74565861305921979ff7e",
            "4744c736c3da47aa9f9130be212de5fa",
            "7db9901f29ac45a4837d8c7090bc9745",
            "fca5e7f600f1400e95d3d69fbecea84d",
            "738171b5811a47119009044c40751ce4",
            "fe8aed1d4e834961ae1fb0cd0e47b7c0",
            "f74e9ee52b674cc28553bb277a533366",
            "252e934abc814ac4842a9bea32bdd528",
            "fee7059287654f7691e50cdfa3aeade1",
            "2ebaf5e0eb39438f92e8e4fd1c31cef2",
            "c49bde7aead14b2685afc69954b1a5d8",
            "ea8d20c007de4f15872e0f849f47d29d"
          ]
        },
        "id": "36wRZnSurPZ3",
        "outputId": "bd2137dc-467a-41d5-db69-ab805dc8ee9f"
      },
      "source": [
        "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
        "\n",
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
        "        self.l2 = torch.nn.Dropout(0.3)\n",
        "        self.l3 = torch.nn.Linear(768, 3)\n",
        "    \n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, pooled_output= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "        output_2 = self.l2(pooled_output)\n",
        "        output = self.l3(output_2)\n",
        "        return output\n",
        "\n",
        "fchidden = 256\n",
        "hiddendim_lstm = 256\n",
        "embeddim = 768\n",
        "numlayers = 12\n",
        "numclasses = 3\n",
        "num_heads = 2\n",
        "\n",
        "class Bert_LSTM(torch.nn.Module):\n",
        "    def __init__(self, numclasses):\n",
        "        super(Bert_LSTM, self).__init__()\n",
        "        self.numclasses = numclasses\n",
        "        self.embeddim = embeddim\n",
        "        self.numlayers = numlayers\n",
        "        self.hiddendim_lstm = hiddendim_lstm\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "\n",
        "        self.bert = transformers.BertModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
        "        print(\"BERT Model Loaded\")\n",
        "        self.lstm = torch.nn.LSTM(self.embeddim, self.hiddendim_lstm, bidirectional = False, batch_first=True) # noqa\n",
        "        self.fc = torch.nn.Linear(self.hiddendim_lstm, self.numclasses)\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "      last_hidden_state, pooled_output = self.bert(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "      #print(last_hidden_state.shape)\n",
        "      #print(pooled_output.shape)\n",
        "      out, _ = self.lstm(last_hidden_state, None)\n",
        "      print(out.shape)\n",
        "      out = self.dropout(out[:, -1, :])\n",
        "      #print(out.shape)\n",
        "      out = self.fc(out)\n",
        "      return out\n",
        "\n",
        "\n",
        "class Bert_GRU(torch.nn.Module):\n",
        "    def __init__(self, numclasses):\n",
        "        super(Bert_GRU, self).__init__()\n",
        "        self.numclasses = numclasses\n",
        "        self.embeddim = embeddim\n",
        "        self.numlayers = numlayers\n",
        "        self.hiddendim_lstm = hiddendim_lstm\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "\n",
        "        self.bert = transformers.BertModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
        "        print(\"BERT Model Loaded\")\n",
        "        self.Gru = torch.nn.GRU(self.embeddim, self.hiddendim_lstm, bidirectional = False, batch_first=True) # noqa\n",
        "        self.fc = torch.nn.Linear(self.hiddendim_lstm, self.numclasses)\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "      last_hidden_state, pooled_output = self.bert(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "      #print(last_hidden_state.shape)\n",
        "      #print(pooled_output.shape)\n",
        "      out, _ = self.Gru(last_hidden_state, None)\n",
        "      #print(out.shape)\n",
        "      out = self.dropout(out[:, -1, :])\n",
        "      #print(out.shape)\n",
        "      out = self.fc(out)\n",
        "      return out\n",
        "\n",
        "\n",
        "class Bert_BiLSTM(torch.nn.Module):\n",
        "    def __init__(self, numclasses):\n",
        "        super(Bert_BiLSTM, self).__init__()\n",
        "        self.numclasses = numclasses\n",
        "        self.embeddim = embeddim\n",
        "        self.numlayers = numlayers\n",
        "        self.hiddendim_lstm = hiddendim_lstm\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "\n",
        "        self.bert = transformers.BertModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
        "        print(\"BERT Model Loaded\")\n",
        "        self.lstm = torch.nn.LSTM(self.embeddim, self.hiddendim_lstm, bidirectional = True, batch_first=True) # noqa\n",
        "        self.fc = torch.nn.Linear(self.hiddendim_lstm*2, self.numclasses)\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "      last_hidden_state, pooled_output = self.bert(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "      #print(last_hidden_state.shape)\n",
        "      #print(pooled_output.shape)\n",
        "      out, _ = self.lstm(last_hidden_state, None)\n",
        "      #print(out.shape)\n",
        "      out = self.dropout(out[:, -1, :])\n",
        "      #print(out.shape)\n",
        "      out = self.fc(out)\n",
        "      return out\n",
        "\n",
        "\n",
        "class Bert_BiGRU(torch.nn.Module):\n",
        "    def __init__(self, numclasses):\n",
        "        super(Bert_BiGRU, self).__init__()\n",
        "        self.numclasses = numclasses\n",
        "        self.embeddim = embeddim\n",
        "        self.numlayers = numlayers\n",
        "        self.hiddendim_lstm = hiddendim_lstm\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "\n",
        "        self.bert = transformers.BertModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
        "        print(\"BERT Model Loaded\")\n",
        "        self.Gru = torch.nn.GRU(self.embeddim, self.hiddendim_lstm, bidirectional = True, batch_first=True) # noqa\n",
        "        self.fc = torch.nn.Linear(self.hiddendim_lstm*2, self.numclasses)\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "      last_hidden_state, pooled_output = self.bert(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "      #print(last_hidden_state.shape)\n",
        "      #print(pooled_output.shape)\n",
        "      out, _ = self.Gru(last_hidden_state, None)\n",
        "      #print(out.shape)\n",
        "      out = self.dropout(out[:, -1, :])\n",
        "      #print(out.shape)\n",
        "      out = self.fc(out)\n",
        "      return out\n",
        "\n",
        "\n",
        "class Bert_Attention(torch.nn.Module):\n",
        "    def __init__(self, numclasses):\n",
        "        super(Bert_Attention, self).__init__()\n",
        "        self.numclasses = numclasses\n",
        "        self.embeddim = embeddim\n",
        "        self.numlayers = numlayers\n",
        "        self.hiddendim_lstm = hiddendim_lstm\n",
        "        self.fchidden = fchidden\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "\n",
        "        self.bert = transformers.BertModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
        "        print(\"BERT Model Loaded\")\n",
        "        q_t = np.random.normal(loc=0.0, scale=0.1, size=(1, self.embeddim))\n",
        "        self.q = nn.Parameter(torch.from_numpy(q_t)).float().to(device)\n",
        "        w_ht = np.random.normal(loc=0.0, scale=0.1, size=(self.embeddim, self.fchidden)) # noqa\n",
        "        self.w_h = nn.Parameter(torch.from_numpy(w_ht)).float().to(device)\n",
        "\n",
        "        self.fc = nn.Linear(self.fchidden, self.numclasses)\n",
        "        #self.softmax = torch.nn.functional.softmax(self.fc, dim=0)\n",
        "    \n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "      last_hidden_state, pooled_output = self.bert(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "      #print(last_hidden_state.shape)\n",
        "      #print(pooled_output.shape)\n",
        "      att = self.attention(last_hidden_state)\n",
        "      #print(\"3\",att.shape)\n",
        "      out = self.dropout(att)\n",
        "      out = self.fc(out)\n",
        "      \n",
        "      #print(\"la\",out.shape)\n",
        "      return out\n",
        "\n",
        "    def attention(self, h):\n",
        "        #print(\"hhhhh\",h.shape)\n",
        "        v = torch.matmul(self.q, h.transpose(-2, -1)).squeeze(1)\n",
        "        v = torch.nn.functional.softmax(v, -1)\n",
        "        v_temp = torch.matmul(v.unsqueeze(1), h).transpose(-2, -1)\n",
        "        #print(\"tem\",v_temp.shape)\n",
        "        v = torch.matmul(self.w_h.transpose(1, 0), v_temp).squeeze(2)\n",
        "        #print(v.shape)\n",
        "        return v\n",
        "\n",
        "class Bert_BiLAttention(torch.nn.Module):\n",
        "    def __init__(self, numclasses, device):\n",
        "        super(Bert_BiLAttention, self).__init__()\n",
        "        self.numclasses = numclasses\n",
        "        self.embeddim = embeddim\n",
        "        self.numlayers = numlayers\n",
        "        self.hiddendim_lstm = hiddendim_lstm\n",
        "        self.fchidden = fchidden\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "\n",
        "        self.bert = transformers.BertModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
        "        print(\"BERT Model Loaded\")\n",
        "        self.lstm = torch.nn.LSTM(self.embeddim, self.hiddendim_lstm, bidirectional = True, batch_first=True)\n",
        "\n",
        "        q_t = np.random.normal(loc=0.0, scale=0.1, size=(1, self.hiddendim_lstm*2))\n",
        "        self.q = torch.nn.Parameter(torch.from_numpy(q_t)).float().to(device)\n",
        "        w_ht = np.random.normal(loc=0.0, scale=0.1, size=(self.hiddendim_lstm*2, self.fchidden)) # noqa\n",
        "        self.w_h = torch.nn.Parameter(torch.from_numpy(w_ht)).float().to(device)\n",
        "\n",
        "        self.fc = torch.nn.Linear(self.fchidden, self.numclasses)\n",
        "\n",
        "    def forward(self, inp_ids, att_mask, token_ids):\n",
        "        last_hidden_state, pooler_output = self.bert(input_ids=inp_ids, attention_mask=att_mask, token_type_ids=token_ids)\n",
        "        #print(\"1\",last_hidden_state.shape)\n",
        "        out, _ = self.lstm(last_hidden_state, None)\n",
        "        #print(\"2\",out.shape)\n",
        "        #out = self.attention(out)\n",
        "        att = self.attention(out)\n",
        "        #print(\"3\",att.shape)\n",
        "        out = self.dropout(att)\n",
        "        out = self.fc(out)\n",
        "        #print(\"la\",out.shape)\n",
        "        return out\n",
        "\n",
        "    def attention(self, h):\n",
        "        #print(\"hhhhh\",h.shape)\n",
        "        v = torch.matmul(self.q, h.transpose(-2, -1)).squeeze(1)\n",
        "        v = torch.nn.functional.softmax(v, -1)\n",
        "        v_temp = torch.matmul(v.unsqueeze(1), h).transpose(-2, -1)\n",
        "        #print(\"tem\",v_temp.shape)\n",
        "        v = torch.matmul(self.w_h.transpose(1, 0), v_temp).squeeze(2)\n",
        "        #print(v.shape)\n",
        "        return v\n",
        "\n",
        "\n",
        "class Bert_BiGAttention(torch.nn.Module):\n",
        "    def __init__(self, numclasses, device):\n",
        "        super(Bert_BiGAttention, self).__init__()\n",
        "        self.numclasses = numclasses\n",
        "        self.embeddim = embeddim\n",
        "        self.numlayers = numlayers\n",
        "        self.hiddendim_lstm = hiddendim_lstm\n",
        "        self.fchidden = fchidden\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "\n",
        "        self.bert = transformers.BertModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
        "        print(\"BERT Model Loaded\")\n",
        "        self.Gru = torch.nn.GRU(self.embeddim, self.hiddendim_lstm, bidirectional = True, batch_first=True)\n",
        "\n",
        "        q_t = np.random.normal(loc=0.0, scale=0.1, size=(1, self.hiddendim_lstm*2))\n",
        "        self.q = torch.nn.Parameter(torch.from_numpy(q_t)).float().to(device)\n",
        "        w_ht = np.random.normal(loc=0.0, scale=0.1, size=(self.hiddendim_lstm*2, self.fchidden)) # noqa\n",
        "        self.w_h = torch.nn.Parameter(torch.from_numpy(w_ht)).float().to(device)\n",
        "\n",
        "        self.fc = torch.nn.Linear(self.fchidden, self.numclasses)\n",
        "\n",
        "    def forward(self, inp_ids, att_mask, token_ids):\n",
        "        last_hidden_state, pooler_output = self.bert(input_ids=inp_ids, attention_mask=att_mask, token_type_ids=token_ids)\n",
        "        #print(\"1\",last_hidden_state.shape)\n",
        "        out, _ = self.Gru(last_hidden_state, None)\n",
        "        #print(\"2\",out.shape)\n",
        "        #out = self.attention(out)\n",
        "        att = self.attention(out)\n",
        "        #print(\"3\",att.shape)\n",
        "        out = self.dropout(att)\n",
        "        out = self.fc(out)\n",
        "        #print(\"la\",out.shape)\n",
        "        return out\n",
        "\n",
        "    def attention(self, h):\n",
        "        #print(\"hhhhh\",h.shape)\n",
        "        v = torch.matmul(self.q, h.transpose(-2, -1)).squeeze(1)\n",
        "        v = torch.nn.functional.softmax(v, -1)\n",
        "        v_temp = torch.matmul(v.unsqueeze(1), h).transpose(-2, -1)\n",
        "        #print(\"tem\",v_temp.shape)\n",
        "        v = torch.matmul(self.w_h.transpose(1, 0), v_temp).squeeze(2)\n",
        "        #print(v.shape)\n",
        "        return v\n",
        "\n",
        "#model = Bert_Attention(numclasses)\n",
        "#model = Bert_BiLAttention(numclasses, device)\n",
        "#model = Bert_BiGAttention(numclasses, device)\n",
        "#model = Bert_LSTM(numclasses)\n",
        "#model = Bert_BiLSTM(numclasses)\n",
        "model = Bert_GRU(numclasses)\n",
        "#model = Bert_BiGRU(numclasses)\n",
        "#model = BERTClass()\n",
        "model.to(device)\n",
        "model"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c8e6ebc9caa4364ab29e68751be987f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "738171b5811a47119009044c40751ce4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "BERT Model Loaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Bert_GRU(\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (Gru): GRU(768, 256, batch_first=True)\n",
              "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2Wt5eiSrTU9"
      },
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8MAvbovrqDn"
      },
      "source": [
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDmlWz2QoTaY"
      },
      "source": [
        "\n",
        "import copy\n",
        "#from sklearn.metrics import accuracy\n",
        "\n",
        "def evaluate(loader, model, device):\n",
        "    model.eval()\n",
        "    loss = 0.0\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    for _,data in enumerate(loader, 0):\n",
        "      #print(data)\n",
        "      ids = data['ids'].to(device, dtype = torch.long)\n",
        "      mask = data['mask'].to(device, dtype = torch.long)\n",
        "      token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "      targets = data['targets'].to(device, dtype = torch.float)\n",
        "      with torch.no_grad():\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "      \n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      preds = torch.sigmoid(outputs)\n",
        "      y_pred.extend(preds.tolist())\n",
        "      y_true.extend(targets.tolist())\n",
        "      y_predict = np.array(y_pred) >= 0.5\n",
        "\n",
        "    F1 = round((metrics.accuracy_score(y_true, y_predict)), 2) * 100\n",
        "    return loss, F1\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8Qw9ZkHrsHl"
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for _,data in enumerate(training_loader, 0):\n",
        "        #print(data)\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "        print(outputs)\n",
        "        #print(targets.shape)\n",
        "        #print(outputs.dtype)\n",
        "        #print(targets.dtype)\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        if _%5000==0:\n",
        "            print(f'Epoch: {epoch}, Train Loss:  {loss.item()}')\n",
        "        \n",
        "        #optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mGn2zejrulf",
        "outputId": "c8022c95-ab9a-4b0f-cb81-401c129d37d9"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    train(epoch)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        [-0.0833,  0.5156, -4.0707],\n",
            "        [-4.9692, -4.0961,  3.8039],\n",
            "        [-3.7929, -3.8364,  3.2095],\n",
            "        [-4.5682, -3.8696,  3.1618],\n",
            "        [-5.0407, -3.9443,  4.3111],\n",
            "        [ 3.8451, -3.2651, -3.3286],\n",
            "        [-4.7481, -2.6840,  3.2046],\n",
            "        [-4.3216, -3.6878,  4.0864],\n",
            "        [-4.1582, -3.5138,  3.2600],\n",
            "        [ 2.3232, -1.2765, -4.3384],\n",
            "        [-3.0450,  2.2386, -2.3249],\n",
            "        [ 1.5063, -2.3320, -3.4222],\n",
            "        [-3.8721, -3.2772,  3.9152],\n",
            "        [-2.0227,  2.8164, -3.3343],\n",
            "        [-4.4120, -3.7680,  3.6573]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.3301, -2.7822,  2.8695],\n",
            "        [-4.1689, -3.2116,  4.0367],\n",
            "        [-3.2281, -4.0167,  3.1079],\n",
            "        [-4.5062, -4.4609,  3.4451],\n",
            "        [ 2.6986, -3.1189, -3.7141],\n",
            "        [-4.6033, -3.7907,  3.9534],\n",
            "        [-0.2561,  0.2482, -3.3194],\n",
            "        [ 2.8808, -2.8721, -3.6754],\n",
            "        [-3.5789, -2.2422,  1.3713],\n",
            "        [ 2.5081, -2.1347, -4.4074],\n",
            "        [-4.4881, -4.3206,  3.5771],\n",
            "        [-3.5559, -3.9935,  3.5939],\n",
            "        [-4.2976, -3.6458,  3.4136],\n",
            "        [ 0.2202, -2.2977,  0.0329],\n",
            "        [ 2.8456, -2.9452, -3.5328],\n",
            "        [-3.4619,  1.8975, -1.9212]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.9410,  2.4360, -3.4032],\n",
            "        [-2.5406,  1.6883, -2.3972],\n",
            "        [-4.7840, -2.3258,  2.1969],\n",
            "        [ 1.2322, -1.2148, -4.1846],\n",
            "        [-3.8683, -2.7108,  2.1997],\n",
            "        [ 2.9274, -2.7299, -3.4926],\n",
            "        [-4.4098, -4.4708,  4.1995],\n",
            "        [ 3.2732, -2.9439, -3.2798],\n",
            "        [-4.6076, -3.5658,  3.3704],\n",
            "        [-3.8487, -3.5855,  4.2071],\n",
            "        [-2.5467,  2.1074, -2.9124],\n",
            "        [ 3.5900, -3.2464, -3.2263],\n",
            "        [-4.4415, -4.3518,  4.3880],\n",
            "        [-4.3141, -3.8889,  3.9867],\n",
            "        [-5.2349, -2.4129,  2.7088],\n",
            "        [-4.0755, -3.8214,  3.9442]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.7678, -4.1444,  3.8287],\n",
            "        [-0.7637,  0.9538, -3.0820],\n",
            "        [-4.8029, -4.4654,  3.4529],\n",
            "        [-0.6966,  1.6593, -3.5068],\n",
            "        [-4.2329, -4.2522,  3.6689],\n",
            "        [-2.5856,  2.8168, -3.6297],\n",
            "        [ 3.0670, -2.2410, -4.2140],\n",
            "        [-1.0612,  1.6381, -3.6132],\n",
            "        [ 1.6657, -1.4866, -3.3932],\n",
            "        [-4.6247, -3.6115,  3.3655],\n",
            "        [ 0.3553, -1.0329, -1.8048],\n",
            "        [-4.4606, -3.9703,  3.6027],\n",
            "        [ 4.2648, -3.0011, -3.7230],\n",
            "        [-3.1833, -3.5521,  2.9076],\n",
            "        [-4.0142, -4.4255,  3.8145],\n",
            "        [-3.5224, -3.8618,  3.4083]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.2030, -3.2437, -4.1329],\n",
            "        [ 3.3690, -3.3205, -3.9228],\n",
            "        [-4.3927, -3.6984,  3.7763],\n",
            "        [-4.4894, -3.8837,  3.4488],\n",
            "        [-3.9085, -4.0790,  3.4579],\n",
            "        [-4.2572, -3.8977,  3.6068],\n",
            "        [-1.5773,  2.6743, -3.2278],\n",
            "        [-4.4898, -3.9019,  3.8169],\n",
            "        [-4.5232, -4.4705,  3.7175],\n",
            "        [-4.1194, -3.4608,  2.8573],\n",
            "        [-2.3147,  2.1177, -2.9928],\n",
            "        [-4.7082, -4.4126,  4.2532],\n",
            "        [ 2.7544, -2.7176, -3.5940],\n",
            "        [-3.2165, -0.1114, -0.1383],\n",
            "        [-2.0467,  2.1723, -3.2184],\n",
            "        [ 1.1199, -1.9404, -2.1804]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.2266e+00, -3.6682e+00,  3.8909e+00],\n",
            "        [-4.6118e+00, -3.0356e+00,  3.0087e+00],\n",
            "        [-4.4438e+00, -3.3884e+00,  3.1511e+00],\n",
            "        [-2.6675e+00, -3.4172e-03,  6.9445e-02],\n",
            "        [ 3.4836e+00, -3.3176e+00, -3.1809e+00],\n",
            "        [ 2.9152e+00, -2.6259e+00, -3.5113e+00],\n",
            "        [-4.0299e+00, -3.2722e+00,  3.6539e+00],\n",
            "        [-4.5187e+00, -3.5684e+00,  4.2137e+00],\n",
            "        [-4.5049e+00, -3.9520e+00,  4.0653e+00],\n",
            "        [ 3.1896e+00, -3.0607e+00, -3.4552e+00],\n",
            "        [-1.7558e+00,  2.2471e+00, -3.1406e+00],\n",
            "        [-4.6950e+00, -3.5187e+00,  3.3093e+00],\n",
            "        [-3.1063e+00,  1.5547e-01, -1.2297e+00],\n",
            "        [-4.1679e+00, -2.4316e+00,  2.3230e+00],\n",
            "        [ 2.2040e+00, -1.8947e+00, -4.0737e+00],\n",
            "        [-3.2344e+00,  4.9207e-01, -7.4522e-01]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.8835,  2.7817, -4.2804],\n",
            "        [ 2.8810, -2.3857, -3.6614],\n",
            "        [-3.8617, -1.3741,  1.3181],\n",
            "        [-4.6603, -3.6308,  3.1758],\n",
            "        [-1.9552,  0.1011, -0.7547],\n",
            "        [-4.0216, -4.2934,  3.7173],\n",
            "        [ 3.3802, -3.1412, -4.1407],\n",
            "        [-3.7070, -3.4005,  3.1392],\n",
            "        [-1.5152,  2.0816, -3.5041],\n",
            "        [-4.0085, -3.4827,  3.7272],\n",
            "        [-4.1551, -4.0583,  3.9028],\n",
            "        [-3.9108, -4.3035,  3.8248],\n",
            "        [-4.0278, -4.1482,  3.2872],\n",
            "        [-2.0282,  1.1707, -2.6877],\n",
            "        [-3.9108, -0.6049,  0.2063],\n",
            "        [-1.1148,  2.3420, -4.4279]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.9023, -3.4326,  3.8404],\n",
            "        [-4.1373, -4.0525,  4.0733],\n",
            "        [ 0.4132, -0.9381, -3.2354],\n",
            "        [-3.9973, -3.6592,  4.5550],\n",
            "        [-4.5932, -3.9740,  3.8100],\n",
            "        [-1.7950,  2.2118, -3.1078],\n",
            "        [-3.7045, -3.2095,  2.8325],\n",
            "        [-3.2188, -2.3211,  2.1133],\n",
            "        [-2.7802, -1.0705,  0.1678],\n",
            "        [-2.6834,  2.4216, -3.0565],\n",
            "        [-1.5340, -2.0921,  0.4443],\n",
            "        [ 2.3504, -2.1214, -3.1455],\n",
            "        [-2.3619,  2.0897, -2.9587],\n",
            "        [-1.4311,  2.2089, -3.5048],\n",
            "        [ 2.9026, -3.1169, -3.7811],\n",
            "        [-3.9153, -4.1262,  4.2200]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.6425,  2.5600, -3.1545],\n",
            "        [-3.1323,  2.7261, -2.9572],\n",
            "        [-4.5318, -3.8889,  3.6112],\n",
            "        [ 2.5507, -2.8121, -3.9168],\n",
            "        [-3.8840, -4.4123,  3.9152],\n",
            "        [-3.8520, -3.8033,  2.9985],\n",
            "        [-3.5329, -3.7762,  2.9595],\n",
            "        [-2.6904,  2.6396, -2.8372],\n",
            "        [-2.0789,  1.2793, -3.3483],\n",
            "        [-4.4894, -2.6626,  2.1581],\n",
            "        [ 3.7443, -3.3575, -3.5188],\n",
            "        [ 0.6723, -1.0818, -3.6374],\n",
            "        [-3.8353, -3.6888,  3.6279],\n",
            "        [-4.7966, -1.6859,  1.9595],\n",
            "        [-1.9760,  1.4734, -3.0160],\n",
            "        [-0.6576, -0.4150, -1.3755]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.1131,  2.2329, -2.7227],\n",
            "        [-3.2887, -4.3173,  3.5949],\n",
            "        [ 0.2557, -1.5039, -2.8778],\n",
            "        [-4.8507, -2.9556,  2.7288],\n",
            "        [-3.9015, -4.3974,  3.7416],\n",
            "        [-3.4350, -3.2952,  3.6556],\n",
            "        [ 3.2915, -2.8514, -3.1755],\n",
            "        [ 3.8293, -2.9913, -3.5401],\n",
            "        [-4.3649, -4.2525,  3.6429],\n",
            "        [-4.4823, -3.7860,  4.0928],\n",
            "        [-4.1636, -3.4898,  2.5251],\n",
            "        [ 2.3514, -2.2458, -3.0560],\n",
            "        [-0.2188, -0.9649, -2.1681],\n",
            "        [-4.4064, -4.0512,  3.9180],\n",
            "        [-4.5422, -4.0200,  4.0272],\n",
            "        [-4.1592, -4.0091,  3.8604]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.5475,  2.5979, -3.7493],\n",
            "        [-3.3767, -4.0724,  2.9288],\n",
            "        [-4.6120, -2.0096,  2.3303],\n",
            "        [ 0.7362, -2.0043, -1.4482],\n",
            "        [-4.3852, -4.4397,  4.2404],\n",
            "        [-4.0821, -4.3198,  4.5199],\n",
            "        [-4.5305, -2.8010,  2.6930],\n",
            "        [-3.6018, -4.5317,  3.3283],\n",
            "        [-2.8022,  1.7552, -2.7439],\n",
            "        [ 3.4760, -3.0725, -3.6696],\n",
            "        [ 3.5549, -3.4448, -3.1501],\n",
            "        [-3.9604, -4.4172,  4.0437],\n",
            "        [ 2.7402, -3.3485, -3.8687],\n",
            "        [ 2.5284, -2.9449, -3.4929],\n",
            "        [-5.1442, -4.2590,  4.0017],\n",
            "        [-4.1651, -4.5551,  3.9049]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1756, -1.9812, -4.0540],\n",
            "        [-4.1520, -3.5726,  2.9316],\n",
            "        [-4.3006, -3.8707,  3.0391],\n",
            "        [-3.3093, -4.1355,  3.8285],\n",
            "        [-4.4590, -3.8674,  4.2673],\n",
            "        [-4.6082, -3.7397,  3.7968],\n",
            "        [ 0.7028, -1.4432, -1.9888],\n",
            "        [-4.5192, -1.7169,  2.5187],\n",
            "        [-3.3331,  2.8904, -2.9972],\n",
            "        [-3.6833, -3.9632,  3.5127],\n",
            "        [-3.6420, -1.0303,  1.2081],\n",
            "        [ 3.0526, -3.0274, -3.8400],\n",
            "        [-4.0883, -4.9046,  3.8466],\n",
            "        [ 2.8991, -2.7458, -3.7321],\n",
            "        [-3.9781, -3.9942,  4.3216],\n",
            "        [-2.0445,  2.6693, -3.1731]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.3190,  2.1504, -2.6246],\n",
            "        [-3.1182,  1.8185, -2.5365],\n",
            "        [ 2.1201, -2.2026, -3.9825],\n",
            "        [ 0.9370, -1.8486, -2.6664],\n",
            "        [ 1.4919, -0.9825, -3.5060],\n",
            "        [-0.3174, -2.0049, -0.3057],\n",
            "        [ 2.9569, -3.6683, -2.8005],\n",
            "        [-3.3664, -4.0724,  2.5770],\n",
            "        [-4.5788, -3.0622,  3.8299],\n",
            "        [-2.4304,  2.5611, -2.6352],\n",
            "        [-4.6577, -3.6611,  3.9870],\n",
            "        [-4.8717, -0.2078,  0.4557],\n",
            "        [ 1.6409, -2.8521, -2.1295],\n",
            "        [-4.1869, -3.7291,  4.3366],\n",
            "        [-3.8683, -4.1012,  3.7962],\n",
            "        [-3.4371, -3.7817,  3.3728]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0153, -0.8640, -2.9500],\n",
            "        [-4.0407, -3.8106,  4.3194],\n",
            "        [-4.2120, -4.5702,  4.1506],\n",
            "        [-4.3412, -4.2466,  3.8105],\n",
            "        [ 2.5382, -2.9134, -4.0596],\n",
            "        [-3.6684, -3.1671,  2.5063],\n",
            "        [-0.7744, -3.3034,  0.7718],\n",
            "        [-3.6146, -4.1710,  3.3849],\n",
            "        [-2.9551,  2.0108, -2.3626],\n",
            "        [ 2.9767, -2.8910, -3.8540],\n",
            "        [-4.3508, -3.9273,  3.8873],\n",
            "        [-4.8554, -3.3432,  4.1223],\n",
            "        [ 2.6640, -2.1443, -3.8524],\n",
            "        [-4.0336, -4.1526,  4.1611],\n",
            "        [-3.8242, -3.3819,  2.4467],\n",
            "        [-2.9603, -3.4337,  2.2617]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.9477, -2.8066, -3.0603],\n",
            "        [-3.7733, -3.9896,  2.9386],\n",
            "        [-1.6929,  2.1918, -3.2525],\n",
            "        [ 3.0362, -2.9409, -3.2777],\n",
            "        [-2.8518,  1.5808, -1.8863],\n",
            "        [-3.6962, -4.3048,  3.6891],\n",
            "        [ 0.8402, -2.6629, -0.5757],\n",
            "        [-3.3988, -3.4445,  2.6090],\n",
            "        [-3.8014, -2.8867,  2.8232],\n",
            "        [-3.5495, -4.4167,  3.8500],\n",
            "        [-0.7392, -3.4509,  0.5146],\n",
            "        [-4.1580, -3.8927,  3.9569],\n",
            "        [ 3.2779, -3.6040, -3.1768],\n",
            "        [-4.3003, -4.0328,  4.3903],\n",
            "        [-4.2178, -3.8477,  4.4438],\n",
            "        [-3.7719, -3.8046,  3.6129]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.7035, -3.6326,  3.8570],\n",
            "        [ 3.3448, -3.5380, -3.1742],\n",
            "        [-3.7491, -3.8458,  3.4032],\n",
            "        [-4.8138, -4.2606,  4.2694],\n",
            "        [-3.4707, -3.6734,  3.3883],\n",
            "        [-3.1141, -3.6320,  3.6304],\n",
            "        [-3.4298,  2.1200, -2.4977],\n",
            "        [-4.0847, -3.6256,  3.8897],\n",
            "        [-4.3185, -4.2792,  4.2801],\n",
            "        [-4.2471, -4.1162,  4.2511],\n",
            "        [ 2.9118, -2.2064, -3.2402],\n",
            "        [-0.7609, -1.8256, -0.8491],\n",
            "        [-3.8858, -4.2636,  4.2182],\n",
            "        [-4.2861, -4.0354,  4.5310],\n",
            "        [-4.2871, -3.9647,  4.0095],\n",
            "        [-0.4815, -0.5144, -2.8117]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.9076, -3.3297,  3.6706],\n",
            "        [-0.7373,  0.1029, -2.4178],\n",
            "        [ 3.4709, -3.2449, -3.2777],\n",
            "        [-4.3163, -3.9589,  4.3070],\n",
            "        [ 2.6952, -3.3765, -2.7604],\n",
            "        [-3.8128, -4.6257,  3.7524],\n",
            "        [-3.2711, -4.1798,  3.4125],\n",
            "        [-3.5764, -4.0610,  3.4278],\n",
            "        [-3.7390, -4.3459,  3.8966],\n",
            "        [-4.6621, -4.0794,  3.9417],\n",
            "        [-3.7351, -3.3653,  3.8830],\n",
            "        [ 2.8229, -2.5530, -4.0054],\n",
            "        [-4.0798, -4.0476,  3.9224],\n",
            "        [ 2.3753, -2.8029, -2.8380],\n",
            "        [ 3.3088, -3.5147, -2.9599],\n",
            "        [-3.5309, -3.9649,  3.3433]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.8444, -4.1593,  3.6102],\n",
            "        [-4.5469, -0.6792,  0.3677],\n",
            "        [ 3.0987, -2.8104, -3.3780],\n",
            "        [ 2.2536, -1.8754, -3.6758],\n",
            "        [-3.3930, -3.5063,  3.9627],\n",
            "        [-4.3977, -3.9380,  3.7736],\n",
            "        [-3.9330, -4.6958,  3.9686],\n",
            "        [ 2.9076, -2.7902, -2.9657],\n",
            "        [-4.0863, -4.4652,  3.7034],\n",
            "        [-4.1835, -4.4359,  3.9744],\n",
            "        [ 3.4649, -2.8262, -2.8419],\n",
            "        [ 2.2220, -2.7622, -3.4715],\n",
            "        [-3.6521, -4.0858,  4.1721],\n",
            "        [-4.0380, -3.8134,  3.2009],\n",
            "        [-4.5900, -3.8856,  3.7797],\n",
            "        [-4.0563, -4.0525,  4.1806]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.7411, -3.6711, -3.3575],\n",
            "        [-3.7272, -3.9145,  4.0235],\n",
            "        [-2.2830,  2.1234, -3.1208],\n",
            "        [ 2.1022, -2.4683, -3.3371],\n",
            "        [ 3.5636, -3.1505, -3.0964],\n",
            "        [-3.2904,  2.5639, -2.2635],\n",
            "        [-3.4002, -4.3234,  4.3804],\n",
            "        [-4.5780, -3.8101,  3.3697],\n",
            "        [-4.3112, -3.6577,  3.8443],\n",
            "        [-3.0576, -0.6619,  0.5135],\n",
            "        [-2.3045, -3.0854,  1.9114],\n",
            "        [-2.4837, -0.8817,  0.2720],\n",
            "        [-3.8395, -4.6605,  4.2769],\n",
            "        [-4.0624, -3.6505,  3.9662],\n",
            "        [-3.6935, -3.1251,  3.8858],\n",
            "        [-4.0943, -3.5538,  4.3113]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.1705, -4.2638,  4.4553],\n",
            "        [ 2.6853, -2.2170, -3.4480],\n",
            "        [-4.9841, -2.8302,  3.2150],\n",
            "        [-3.9803, -4.4196,  4.3379],\n",
            "        [-2.8338,  2.6246, -2.9513],\n",
            "        [-3.1617,  2.6469, -2.4355],\n",
            "        [-4.4882, -3.9382,  3.9743],\n",
            "        [ 3.5014, -2.6905, -3.7759],\n",
            "        [ 3.3756, -3.7818, -2.8614],\n",
            "        [ 3.0456, -3.6049, -2.8719],\n",
            "        [-1.0618, -0.6368, -0.3534],\n",
            "        [-1.2416,  1.3744, -3.1475],\n",
            "        [-2.3672, -2.3587,  0.1372],\n",
            "        [-3.6057, -4.4290,  3.5248],\n",
            "        [-4.1098, -3.3549,  3.5809],\n",
            "        [-1.4485, -3.4619,  0.8542]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.4990, -3.0771, -3.6645],\n",
            "        [-2.9287, -4.2659,  3.1035],\n",
            "        [-1.1952, -1.0086, -0.6641],\n",
            "        [-3.6999, -2.7089,  2.7873],\n",
            "        [-3.3172, -4.1850,  3.8193],\n",
            "        [ 0.2779,  0.2898, -3.8860],\n",
            "        [-3.5747, -3.7520,  3.5841],\n",
            "        [-3.7743, -4.0620,  3.4686],\n",
            "        [ 3.5888, -3.7938, -2.5291],\n",
            "        [-4.3838, -4.3513,  3.8605],\n",
            "        [ 3.6399, -3.7370, -3.3416],\n",
            "        [ 2.9757, -3.1753, -3.6702],\n",
            "        [ 3.3360, -3.4024, -3.0604],\n",
            "        [-3.7283, -4.1270,  4.3949],\n",
            "        [-4.0593, -4.3147,  3.9100],\n",
            "        [ 2.2180, -2.7268, -2.1488]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.5786, -3.8160,  4.1574],\n",
            "        [ 3.4788, -2.8301, -3.2670],\n",
            "        [ 4.0253, -2.9775, -3.6320],\n",
            "        [-3.9760, -3.7728,  2.9974],\n",
            "        [-4.1411, -4.2427,  3.8940],\n",
            "        [-3.3897, -3.2009,  2.9776],\n",
            "        [-3.9897, -3.7448,  3.6748],\n",
            "        [ 3.3859, -3.1855, -2.7955],\n",
            "        [-4.1991, -2.9930,  3.1502],\n",
            "        [ 3.5365, -3.1949, -3.1800],\n",
            "        [-1.4622, -3.1402,  1.2498],\n",
            "        [-3.3499, -3.6138,  3.8555],\n",
            "        [-2.8818, -4.8855,  3.2397],\n",
            "        [-2.3945, -0.5460, -0.2876],\n",
            "        [-4.2906, -4.1695,  3.9812],\n",
            "        [-4.1144, -4.0486,  3.8523]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.5502, -4.7978,  3.5408],\n",
            "        [-3.8732, -4.0657,  4.1162],\n",
            "        [-1.6508,  1.4571, -1.8150],\n",
            "        [ 1.6211, -2.0101, -3.5596],\n",
            "        [-1.3470,  0.9955, -3.0891],\n",
            "        [-2.7555, -4.3921,  2.8015],\n",
            "        [-4.5005, -4.1391,  3.8327],\n",
            "        [ 3.7705, -3.4230, -3.2743],\n",
            "        [-4.1140, -3.5205,  4.0438],\n",
            "        [-3.3334,  2.1703, -2.2477],\n",
            "        [-3.3417, -3.8949,  3.8453],\n",
            "        [-3.7991, -3.8969,  3.6114],\n",
            "        [ 2.5756, -2.7681, -3.0585],\n",
            "        [-3.4390, -4.2186,  3.5252],\n",
            "        [-3.6364, -4.1308,  3.6272],\n",
            "        [-2.6191, -4.4956,  3.3689]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.3926,  2.2212, -2.7227],\n",
            "        [ 0.2567, -1.3875, -2.3171],\n",
            "        [ 0.2077, -2.1237, -0.7904],\n",
            "        [-0.8152,  0.1313, -2.8750],\n",
            "        [ 0.7441, -1.8182, -2.6120],\n",
            "        [-3.7301, -4.4797,  3.9471],\n",
            "        [-3.9998, -3.6963,  3.9219],\n",
            "        [-4.5145, -4.1442,  4.8111],\n",
            "        [-2.8287,  2.4294, -3.3546],\n",
            "        [-4.3101, -4.0081,  3.4515],\n",
            "        [-1.3427, -3.2530,  1.6589],\n",
            "        [ 2.4696, -1.8998, -3.6974],\n",
            "        [-4.6016, -4.5521,  3.8591],\n",
            "        [-4.2404, -3.9919,  3.9887],\n",
            "        [-4.0639, -3.9113,  4.0990],\n",
            "        [-4.0995, -4.3345,  4.5606]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.4791, -3.0645,  1.6868],\n",
            "        [-3.6133, -4.0178,  3.5809],\n",
            "        [ 3.0257, -3.3025, -2.7145],\n",
            "        [-4.2066, -4.1142,  4.2206],\n",
            "        [-3.3776, -3.5862,  2.7735],\n",
            "        [-4.7016, -4.2181,  4.1691],\n",
            "        [-2.7260,  2.7416, -3.0980],\n",
            "        [-3.5617, -3.9020,  3.0803],\n",
            "        [-4.6893, -4.0523,  3.9586],\n",
            "        [-4.2404, -3.8731,  3.7404],\n",
            "        [-1.7443, -0.1344, -2.2744],\n",
            "        [ 3.1665, -3.2634, -2.8630],\n",
            "        [-2.3910,  1.9484, -2.6537],\n",
            "        [ 1.5544, -0.8861, -3.6784],\n",
            "        [-4.4724, -4.4193,  4.1076],\n",
            "        [-3.9679, -4.4525,  3.4007]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.5907,  2.6379, -3.5171],\n",
            "        [-3.6389, -4.2615,  3.1783],\n",
            "        [-3.8596, -3.9451,  4.1718],\n",
            "        [-4.0421, -4.1823,  3.8666],\n",
            "        [ 3.9554, -3.2840, -3.1123],\n",
            "        [-3.0877, -4.0694,  4.2118],\n",
            "        [-4.2840, -3.9559,  3.9030],\n",
            "        [ 1.6296, -1.4122, -4.1021],\n",
            "        [ 3.6451, -2.9997, -3.7993],\n",
            "        [-4.1615, -4.2100,  4.2314],\n",
            "        [-4.5709, -4.2831,  4.0757],\n",
            "        [-1.3404,  1.5157, -3.4475],\n",
            "        [-4.0839, -3.8317,  4.5192],\n",
            "        [-4.1323, -2.0880,  1.8096],\n",
            "        [-2.2569, -1.3840,  0.6116],\n",
            "        [ 1.1211, -1.8071, -2.2973]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.7038, -3.1497, -3.6493],\n",
            "        [ 2.4516, -2.3246, -4.2453],\n",
            "        [-4.1550, -4.0441,  3.9930],\n",
            "        [ 3.6140, -3.2787, -3.3487],\n",
            "        [-3.7783, -3.7445,  3.7819],\n",
            "        [ 0.4598, -1.8275, -1.9958],\n",
            "        [-3.6967, -3.7721,  3.7800],\n",
            "        [-2.5267, -3.6492,  2.9023],\n",
            "        [-3.6250, -4.2541,  3.5706],\n",
            "        [ 2.8535, -3.0437, -3.2222],\n",
            "        [ 2.9740, -1.7814, -4.1319],\n",
            "        [-4.1910, -3.4926,  3.8685],\n",
            "        [-0.0551, -2.2981, -0.9442],\n",
            "        [-4.2688, -2.0645,  1.6992],\n",
            "        [ 3.0939, -2.6800, -3.9577],\n",
            "        [ 2.5478, -3.5354, -2.9882]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.0480, -3.7102,  3.0417],\n",
            "        [-3.8514, -4.3925,  3.8247],\n",
            "        [-4.6024, -4.1680,  4.1464],\n",
            "        [-4.7862, -4.2274,  4.1415],\n",
            "        [-3.2469, -2.8048,  1.6316],\n",
            "        [-4.1312, -3.9347,  3.7725],\n",
            "        [-1.2148, -2.1195,  0.5520],\n",
            "        [-4.6571, -4.1662,  4.0121],\n",
            "        [-4.1988, -4.4383,  4.0132],\n",
            "        [-4.1316, -4.4254,  4.3835],\n",
            "        [ 2.0934, -2.6895, -2.8242],\n",
            "        [-4.0303, -3.8595,  3.9060],\n",
            "        [-3.9420, -4.1462,  4.3854],\n",
            "        [-3.9795, -4.4081,  4.2140],\n",
            "        [-2.9245,  2.3193, -3.4039],\n",
            "        [ 3.8376, -3.4264, -3.4064]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.8351, -3.6349,  3.9836],\n",
            "        [ 2.9933, -3.5644, -2.6095],\n",
            "        [ 3.2607, -3.8602, -3.3186],\n",
            "        [-1.3783, -1.0528, -1.2686],\n",
            "        [ 3.3611, -3.4625, -3.3502],\n",
            "        [-4.3850, -3.9610,  3.7305],\n",
            "        [ 3.6913, -2.8489, -3.2040],\n",
            "        [-4.0718, -4.5570,  4.1455],\n",
            "        [-3.9560, -4.2183,  4.5859],\n",
            "        [-2.2386,  2.5564, -3.4676],\n",
            "        [ 1.9387, -1.8429, -4.1016],\n",
            "        [ 3.4228, -3.2207, -2.9049],\n",
            "        [-4.3199, -4.0451,  3.7531],\n",
            "        [ 0.3459, -0.8551, -3.2140],\n",
            "        [ 3.1374, -2.9226, -3.7288],\n",
            "        [-3.3598, -3.1462,  2.7916]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.5431, -3.9970,  4.0565],\n",
            "        [ 3.5465, -3.3359, -3.4663],\n",
            "        [ 0.7370, -3.1476, -0.3695],\n",
            "        [-3.5179, -3.9579,  3.7227],\n",
            "        [-4.4537, -4.4222,  3.6090],\n",
            "        [-4.3849, -4.1565,  3.6777],\n",
            "        [-4.0818, -3.9047,  3.4205],\n",
            "        [-3.8029, -3.9095,  3.5001],\n",
            "        [-0.7194, -0.5946, -2.8199],\n",
            "        [-4.0585, -4.7570,  3.7705],\n",
            "        [-4.0541, -3.2018,  3.3919],\n",
            "        [-2.8911,  2.0613, -3.0958],\n",
            "        [ 3.1473, -2.8212, -3.8501],\n",
            "        [ 3.8165, -3.1536, -3.3379],\n",
            "        [-2.7714, -3.1263,  1.6867],\n",
            "        [ 0.4022, -1.1149, -2.6263]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.1581, -3.7670,  3.7410],\n",
            "        [-1.7358,  0.1216, -1.9819],\n",
            "        [-3.7607, -4.3829,  3.8523],\n",
            "        [-2.8428,  0.6040, -1.4825],\n",
            "        [-3.5646, -4.4321,  3.5456],\n",
            "        [-1.5999,  0.9143, -2.8831],\n",
            "        [-3.6375, -4.2589,  3.8651],\n",
            "        [-3.7747, -3.9582,  3.3236],\n",
            "        [-4.5737, -4.1458,  4.0528],\n",
            "        [-4.6801, -4.0339,  3.7994],\n",
            "        [-3.6974, -3.9019,  4.3833],\n",
            "        [-3.0692, -4.2833,  2.8452],\n",
            "        [ 3.8246, -3.0646, -3.7730],\n",
            "        [-4.1912, -4.4819,  4.0679],\n",
            "        [ 3.3800, -4.0386, -3.6587],\n",
            "        [ 1.5036, -2.3845, -3.6452]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.8425, -3.8727,  3.7159],\n",
            "        [-4.0136, -3.4644,  2.7793],\n",
            "        [ 2.3616, -2.2818, -3.4315],\n",
            "        [-4.3937, -3.8556,  3.3344],\n",
            "        [-4.2133, -3.9394,  4.4039],\n",
            "        [-1.3304,  0.1524, -2.6904],\n",
            "        [-4.5050, -4.1802,  3.9450],\n",
            "        [-4.2094, -3.5000,  3.7275],\n",
            "        [-4.2456, -4.0522,  3.7453],\n",
            "        [-3.8238, -0.9339,  0.2171],\n",
            "        [-2.0358,  2.2476, -3.5540],\n",
            "        [-1.6013,  1.3258, -2.8939],\n",
            "        [-4.1150, -4.4063,  4.3837],\n",
            "        [-3.9443, -4.4339,  3.1843],\n",
            "        [-1.2015,  0.6547, -3.9705],\n",
            "        [-3.9218, -4.3720,  4.1125]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.2004, -4.1275,  3.3589],\n",
            "        [-4.0263, -3.5870,  2.9160],\n",
            "        [-4.6713, -2.4910,  1.8180],\n",
            "        [-1.8779,  1.5584, -3.0282],\n",
            "        [-4.5493, -4.0873,  3.7617],\n",
            "        [ 3.4328, -3.6119, -3.0839],\n",
            "        [-2.6313, -4.0692,  2.0697],\n",
            "        [ 2.9813, -3.2243, -3.3597],\n",
            "        [ 1.8543, -1.6886, -4.2923],\n",
            "        [-4.2601, -3.7290,  3.8421],\n",
            "        [-4.2812, -3.8702,  3.6917],\n",
            "        [ 3.1643, -3.6777, -3.0401],\n",
            "        [-3.8259, -3.1782,  2.4321],\n",
            "        [-4.9039, -3.9501,  3.7887],\n",
            "        [-4.2097, -3.8217,  3.7061],\n",
            "        [-3.7115, -3.8068,  3.4761]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.5422, -3.3355,  3.3124],\n",
            "        [-3.4867,  0.2741, -0.7713],\n",
            "        [-3.7964,  0.1052, -0.2635],\n",
            "        [ 3.2277, -2.4318, -3.7845],\n",
            "        [ 2.2356, -2.9148, -3.0301],\n",
            "        [ 3.7512, -3.3472, -3.2454],\n",
            "        [-4.6137, -3.9244,  3.9942],\n",
            "        [-3.8984, -3.6436,  3.4350],\n",
            "        [-3.0081,  2.4506, -2.2892],\n",
            "        [-2.6177, -1.7321,  0.6190],\n",
            "        [-4.2203, -3.7865,  4.8100],\n",
            "        [-4.2438, -2.6906,  2.8643],\n",
            "        [-4.4347, -1.1892,  1.2635],\n",
            "        [-4.2379, -4.1486,  3.9368],\n",
            "        [ 1.6991, -2.4496, -2.8118],\n",
            "        [-3.7767, -2.7485,  3.6121]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.1133, -4.3071,  4.1998],\n",
            "        [-3.8758, -3.3402,  4.0022],\n",
            "        [-3.8800, -3.6776,  2.9159],\n",
            "        [-4.6432, -3.9951,  4.1133],\n",
            "        [-5.1111, -2.6734,  2.5213],\n",
            "        [-3.9095, -4.0928,  3.8626],\n",
            "        [-4.4810, -3.5456,  4.1849],\n",
            "        [-3.7317, -3.3193,  3.1543],\n",
            "        [-3.3078, -4.2644,  3.4150],\n",
            "        [-4.4366, -3.9133,  3.9349],\n",
            "        [-4.1816, -3.7204,  3.8671],\n",
            "        [-4.5147, -3.5652,  4.1111],\n",
            "        [-0.0358, -0.1426, -2.3859],\n",
            "        [-4.0658, -3.7096,  3.8625],\n",
            "        [-3.7695, -2.7526,  3.3460],\n",
            "        [ 3.1644, -2.9835, -3.6370]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.3337, -3.9832,  3.9352],\n",
            "        [-4.4601, -3.7275,  4.1516],\n",
            "        [-4.1061, -4.0712,  3.5088],\n",
            "        [-2.8589,  2.1809, -2.7105],\n",
            "        [ 0.2787, -0.8738, -4.2238],\n",
            "        [-3.9084, -4.4392,  3.8507],\n",
            "        [-4.0415, -3.9334,  3.3360],\n",
            "        [-4.5010, -4.1463,  4.0124],\n",
            "        [-3.8554, -3.7437,  4.0771],\n",
            "        [-5.0593, -2.8796,  2.8854],\n",
            "        [-4.8885, -2.7832,  2.4755],\n",
            "        [-3.8754, -4.3432,  3.7446],\n",
            "        [-4.1441, -3.9286,  4.1490],\n",
            "        [-2.6875,  2.0323, -2.7500],\n",
            "        [-4.2906, -3.8713,  4.3150],\n",
            "        [-4.2910, -0.2251, -0.1754]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9896,  0.5961, -3.1010],\n",
            "        [ 2.7425, -2.7982, -3.4759],\n",
            "        [-5.0993, -4.1253,  3.6255],\n",
            "        [-4.9882, -4.4956,  4.2354],\n",
            "        [-2.0883,  2.1805, -3.2413],\n",
            "        [ 3.1146, -2.9447, -3.3700],\n",
            "        [-4.8505, -1.8988,  2.0242],\n",
            "        [-4.1005, -3.2481,  4.3338],\n",
            "        [-4.6021, -3.1373,  3.0364],\n",
            "        [-4.4133, -3.7231,  4.3093],\n",
            "        [-4.8118, -3.7048,  4.4842],\n",
            "        [-3.8620, -3.9655,  3.2730],\n",
            "        [ 2.9672, -3.0735, -3.0658],\n",
            "        [-4.7707, -4.4199,  4.1846],\n",
            "        [ 2.2850, -2.7984, -2.7244],\n",
            "        [ 3.1434, -2.8221, -3.4742]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.8018,  3.5457, -3.0300],\n",
            "        [-4.4542, -4.9100,  4.8017],\n",
            "        [-3.6416, -3.8606,  3.7284],\n",
            "        [ 2.7825, -2.2800, -4.3499],\n",
            "        [ 1.3564, -1.9369, -4.0594],\n",
            "        [-3.4650,  2.8939, -2.7707],\n",
            "        [-4.5412, -3.6971,  4.0553],\n",
            "        [-4.0186, -3.3211,  3.5796],\n",
            "        [ 1.5790, -2.5346, -1.8699],\n",
            "        [-0.0147,  0.2382, -3.6557],\n",
            "        [ 3.3993, -3.0986, -2.9880],\n",
            "        [ 2.9097, -3.8303, -3.1741],\n",
            "        [ 3.3530, -2.6838, -3.2741],\n",
            "        [-1.8262,  3.1261, -3.3336],\n",
            "        [-2.5350, -0.3827, -0.4359],\n",
            "        [ 3.4164, -3.4387, -2.9408]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.2179, -3.1990,  3.4870],\n",
            "        [-4.6890, -3.7561,  3.9462],\n",
            "        [ 3.2013, -3.7983, -3.2064],\n",
            "        [-0.8266,  0.5903, -3.1952],\n",
            "        [-4.5949, -4.2384,  4.0018],\n",
            "        [-2.1025, -2.4940,  0.9702],\n",
            "        [-4.7574, -3.8164,  3.6426],\n",
            "        [ 3.0926, -3.5410, -2.0577],\n",
            "        [-4.3855, -3.9915,  4.0093],\n",
            "        [-3.1878,  2.5573, -2.5014],\n",
            "        [-4.4774, -3.9990,  3.9953],\n",
            "        [-4.3411, -3.9370,  4.0483],\n",
            "        [-3.9162, -4.1761,  3.9497],\n",
            "        [-3.8943, -4.1865,  4.1200],\n",
            "        [-4.3477, -3.9496,  3.7410],\n",
            "        [-4.6417, -4.0533,  4.1084]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.3082, -4.2648,  3.5911],\n",
            "        [-4.8168, -2.7278,  3.1730],\n",
            "        [ 3.1891, -3.4687, -3.1273],\n",
            "        [-2.7500,  3.1313, -3.1362],\n",
            "        [ 1.8072, -2.5435, -3.0063],\n",
            "        [-3.4704, -3.6145,  3.8223],\n",
            "        [-2.3773,  2.0241, -1.9410],\n",
            "        [ 3.5528, -4.0155, -3.6246],\n",
            "        [-4.4000, -3.5731,  4.0153],\n",
            "        [-3.8669, -3.8721,  3.4719],\n",
            "        [-1.5902,  0.6766, -2.8054],\n",
            "        [-4.0080, -3.3830,  4.0945],\n",
            "        [-2.4366,  3.3204, -3.2460],\n",
            "        [ 1.5232, -1.8480, -3.5079],\n",
            "        [ 3.1451, -2.7910, -3.1775],\n",
            "        [-4.1734, -3.3771,  3.5239]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.2408, -4.2013,  4.3972],\n",
            "        [-4.4767, -4.1908,  4.5465],\n",
            "        [ 3.9816, -3.7327, -3.8761],\n",
            "        [-4.4573, -3.6343,  4.3979],\n",
            "        [-4.6935, -3.4494,  4.0250],\n",
            "        [-3.9653, -3.6266,  3.7060],\n",
            "        [-4.3012, -4.0819,  3.7747],\n",
            "        [ 3.3352, -2.4347, -4.1861],\n",
            "        [-4.3385, -4.1141,  3.5793],\n",
            "        [-5.2355, -2.6387,  3.6035],\n",
            "        [ 2.4768, -2.8879, -2.6415],\n",
            "        [-3.5979,  2.1083, -1.7019],\n",
            "        [-4.3845, -3.9083,  4.5910],\n",
            "        [-2.9244,  3.0442, -2.8658],\n",
            "        [-4.7337, -3.1305,  3.0574],\n",
            "        [-1.8143, -0.7380, -0.7477]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.2131, -3.8409,  4.3004],\n",
            "        [ 1.7682, -1.5810, -3.1745],\n",
            "        [ 3.3054, -2.8951, -3.7195],\n",
            "        [-2.2332,  0.6477, -1.7662],\n",
            "        [-4.1252, -4.7049,  4.5515],\n",
            "        [-4.8330, -3.9263,  4.4553],\n",
            "        [-4.6768, -3.7733,  3.8490],\n",
            "        [-2.6883,  1.8248, -1.9496],\n",
            "        [-3.9618, -3.7932,  3.9538],\n",
            "        [-4.3918, -4.1938,  4.0586],\n",
            "        [-4.9974, -4.0768,  4.5455],\n",
            "        [-1.9535,  0.3391, -1.8978],\n",
            "        [-4.7555, -3.8341,  4.4514],\n",
            "        [-4.6189, -0.5034,  0.3694],\n",
            "        [-4.1437, -3.5505,  3.7033],\n",
            "        [-3.9368,  0.7510, -0.1234]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.6937,  2.4850, -3.3624],\n",
            "        [-4.1735, -3.5087,  3.7615],\n",
            "        [ 3.4163, -2.7913, -3.4638],\n",
            "        [-4.4950, -3.1062,  3.6844],\n",
            "        [-4.3908, -3.9532,  3.9808],\n",
            "        [-1.9788,  2.9708, -2.9798],\n",
            "        [-2.5227,  3.5654, -3.1329],\n",
            "        [-3.4697,  2.3680, -2.1391],\n",
            "        [-3.1059,  2.7478, -2.9896],\n",
            "        [ 3.3125, -3.7345, -3.9028],\n",
            "        [ 3.0921, -3.8256, -3.2769],\n",
            "        [-1.9675,  1.0192, -1.5859],\n",
            "        [-4.3546, -4.6661,  4.0040],\n",
            "        [ 2.3507, -2.1392, -3.1312],\n",
            "        [-0.8782,  1.1520, -3.9290],\n",
            "        [ 1.4909, -0.6894, -4.3306]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.1330, -4.1189,  4.4864],\n",
            "        [ 2.8277, -2.2388, -3.4688],\n",
            "        [-4.4620, -3.5729,  3.1183],\n",
            "        [-4.9169, -4.1196,  3.9769],\n",
            "        [-4.3488, -4.1129,  4.0502],\n",
            "        [-3.2740, -2.6707,  2.2488],\n",
            "        [-1.8446,  1.9921, -2.9923],\n",
            "        [-4.1255, -3.7669,  4.0418],\n",
            "        [-4.5856, -3.6190,  4.4106],\n",
            "        [-4.2553, -4.6181,  3.9693],\n",
            "        [-4.7462, -3.9790,  4.5598],\n",
            "        [-4.0838, -2.8991,  3.1572],\n",
            "        [-0.3362,  0.8886, -3.4014],\n",
            "        [-4.6369, -2.8260,  3.2740],\n",
            "        [-2.8463,  2.7557, -3.2014],\n",
            "        [-4.8201, -3.5663,  3.9203]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.0651, -4.6773,  3.7621],\n",
            "        [-4.1534, -3.3364,  3.7076],\n",
            "        [-4.7388, -3.4457,  4.6816],\n",
            "        [-3.7952, -4.0516,  3.5736],\n",
            "        [-4.5825, -3.7752,  3.8352],\n",
            "        [-2.7096,  3.0590, -3.4206],\n",
            "        [-4.4717, -2.5527,  2.6401],\n",
            "        [-5.1243, -3.7702,  3.5561],\n",
            "        [ 3.1879, -2.9823, -3.6304],\n",
            "        [-2.9605,  2.1683, -1.9136],\n",
            "        [-2.9628,  2.3200, -2.3529],\n",
            "        [-3.3911, -3.8921,  3.5182],\n",
            "        [-4.8207, -3.2659,  2.5381],\n",
            "        [-4.6186, -4.5576,  4.3993],\n",
            "        [-3.4182,  0.6225, -0.6565],\n",
            "        [-4.6722, -4.1927,  4.3791]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.3291,  3.1018, -2.8650],\n",
            "        [ 3.1774, -2.7181, -3.5425],\n",
            "        [-4.0858, -3.8900,  3.3340],\n",
            "        [ 2.7629, -2.8067, -2.8827],\n",
            "        [-4.6163, -4.1465,  4.2468],\n",
            "        [-4.2231, -3.0092,  3.4092],\n",
            "        [-3.7990, -4.1686,  3.8583],\n",
            "        [-0.5454, -0.1448, -2.5952],\n",
            "        [-4.1301, -4.6265,  4.5921],\n",
            "        [-4.2010, -3.2958,  2.6257],\n",
            "        [-4.3934, -4.3128,  3.8444],\n",
            "        [ 2.7864, -2.9205, -2.9031],\n",
            "        [ 2.9876, -1.9492, -4.0725],\n",
            "        [ 1.5128, -0.9681, -2.9677],\n",
            "        [-3.7179, -3.9609,  3.6926],\n",
            "        [-3.8203, -4.2041,  4.0471]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.2097,  2.7158, -3.2376],\n",
            "        [-4.5714, -3.8752,  3.7510],\n",
            "        [-3.6129, -2.4879,  2.3274],\n",
            "        [-3.9863, -3.9948,  3.3970],\n",
            "        [-2.7189,  3.0354, -3.2555],\n",
            "        [-4.6495, -3.9086,  3.8250],\n",
            "        [ 3.6355, -3.2232, -3.5031],\n",
            "        [-4.4021, -2.7859,  3.9905],\n",
            "        [-2.6857,  2.4165, -3.0619],\n",
            "        [-2.4490, -0.3851, -0.8017],\n",
            "        [-2.5910,  0.6177, -1.0401],\n",
            "        [-4.8945, -3.3204,  3.5076],\n",
            "        [-4.8279, -4.2506,  4.5527],\n",
            "        [-4.4695, -4.5018,  4.0624],\n",
            "        [-2.4358,  3.4460, -3.6588],\n",
            "        [-4.5986, -1.0617,  1.6183]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.8359, -2.9187, -3.4758],\n",
            "        [-4.1426, -5.0185,  4.0323],\n",
            "        [ 2.7624, -3.1882, -3.3232],\n",
            "        [-3.6496, -3.4355,  3.3435],\n",
            "        [-4.3543, -3.9016,  3.7078],\n",
            "        [ 3.7719, -3.4937, -3.3579],\n",
            "        [-4.6528, -4.4257,  4.2512],\n",
            "        [-4.4854, -3.8938,  3.8074],\n",
            "        [ 3.9375, -3.4668, -3.1617],\n",
            "        [-4.3464, -2.6055,  3.2938],\n",
            "        [-4.7504, -4.3495,  3.7609],\n",
            "        [-4.8810, -3.1496,  3.7598],\n",
            "        [-2.9583,  0.2499, -1.1831],\n",
            "        [ 3.3341, -3.2223, -3.1439],\n",
            "        [-2.5121,  2.5311, -2.4360],\n",
            "        [-3.4456,  0.8326, -1.2274]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7068,  0.1415, -4.4120],\n",
            "        [-4.8383, -4.5076,  4.1622],\n",
            "        [-4.1086, -3.7137,  3.2691],\n",
            "        [-2.5250,  0.8650, -0.7821],\n",
            "        [-4.9036, -3.2493,  3.5962],\n",
            "        [-2.7927,  2.1724, -2.5974],\n",
            "        [-4.0153, -4.0231,  4.2702],\n",
            "        [ 2.0532, -1.1965, -3.8907],\n",
            "        [-4.1029, -4.1250,  4.5443],\n",
            "        [-4.9342, -3.9193,  4.3609],\n",
            "        [-1.1695, -4.3695,  1.8163],\n",
            "        [-3.9123, -4.3606,  3.2798],\n",
            "        [-4.2504, -0.9936,  1.6908],\n",
            "        [-4.8450, -3.6405,  4.1211],\n",
            "        [-4.6437, -3.3790,  3.4825],\n",
            "        [-4.5174, -4.3576,  3.9341]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.6048, -3.9777,  4.2405],\n",
            "        [-4.2079, -3.3987,  3.7751],\n",
            "        [-5.2721, -3.3579,  2.9847],\n",
            "        [-4.5517, -3.8733,  3.5259],\n",
            "        [-4.4408, -3.8889,  4.1064],\n",
            "        [-1.8999,  2.4812, -3.1773],\n",
            "        [-4.3642, -3.7716,  3.8732],\n",
            "        [-0.1952, -0.2260, -3.1474],\n",
            "        [-4.2906, -3.5098,  3.9602],\n",
            "        [-4.5784, -2.8460,  2.6388],\n",
            "        [-3.3739, -0.7008,  0.9769],\n",
            "        [-3.8208, -0.9122,  0.7751],\n",
            "        [-4.4467, -3.7082,  3.0204],\n",
            "        [ 2.9256, -3.2881, -2.7057],\n",
            "        [-1.9044,  2.6921, -3.2691],\n",
            "        [-3.4553,  1.9773, -1.5311]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.6190, -3.0568,  3.7044],\n",
            "        [ 3.7423, -2.8489, -4.0637],\n",
            "        [-4.5667, -2.9282,  3.2036],\n",
            "        [ 3.6353, -2.8989, -3.5096],\n",
            "        [-4.4544, -3.4285,  4.1003],\n",
            "        [-4.6112, -3.0801,  3.4285],\n",
            "        [-4.0566, -3.0861,  3.2140],\n",
            "        [-4.4190, -4.0356,  3.9827],\n",
            "        [-5.0115, -3.8422,  3.4628],\n",
            "        [-4.1644, -3.7051,  3.2868],\n",
            "        [ 2.6628, -3.0637, -3.4460],\n",
            "        [-2.9626,  3.4183, -3.0865],\n",
            "        [-4.6673, -3.9531,  4.7531],\n",
            "        [-4.2248, -4.5750,  4.0756],\n",
            "        [-2.7292,  2.1994, -3.2529],\n",
            "        [ 3.7398, -3.3019, -3.6238]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7142, -0.2896, -3.8845],\n",
            "        [-4.5697, -4.3437,  4.4302],\n",
            "        [-3.5687, -3.2540,  2.3185],\n",
            "        [ 2.7436, -3.0982, -3.0188],\n",
            "        [ 2.2497, -1.9360, -3.4218],\n",
            "        [-3.7298, -3.9096,  4.7544],\n",
            "        [-2.2256,  2.9291, -3.4543],\n",
            "        [-4.0062, -4.1365,  4.1572],\n",
            "        [-1.6465,  0.1240, -1.4906],\n",
            "        [-2.3320,  2.0605, -3.6111],\n",
            "        [-2.2693,  2.1268, -2.4028],\n",
            "        [-3.9540, -2.0292,  2.3768],\n",
            "        [-4.5009, -3.3080,  3.3235],\n",
            "        [-4.6960, -3.6210,  3.8950],\n",
            "        [-4.4900, -3.5338,  3.6737],\n",
            "        [ 1.3223, -0.4716, -4.5099]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-5.5135, -3.9104,  4.2528],\n",
            "        [ 3.0216, -2.7293, -3.9895],\n",
            "        [-4.6593, -3.4322,  3.3183],\n",
            "        [-4.2920, -3.5954,  3.7051],\n",
            "        [-4.5920, -4.6423,  4.0240],\n",
            "        [-2.2392,  2.4993, -2.4909],\n",
            "        [-2.8096,  2.8983, -2.9840],\n",
            "        [-3.7087, -4.0830,  3.8547],\n",
            "        [-4.5916, -4.5059,  3.9260],\n",
            "        [-4.3719, -2.2411,  2.7475],\n",
            "        [-3.9145, -3.3974,  4.3163],\n",
            "        [-4.3282, -4.1842,  4.2095],\n",
            "        [ 0.6486,  0.2210, -4.4922],\n",
            "        [-2.3048,  2.7301, -3.6109],\n",
            "        [-4.4984, -3.9326,  4.0695],\n",
            "        [-3.7729,  1.5778, -1.2711]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.7179, -2.2336,  2.1198],\n",
            "        [-4.0081, -3.8379,  3.7524],\n",
            "        [-4.2507, -3.4980,  3.6881],\n",
            "        [ 1.3340, -1.5626, -2.4184],\n",
            "        [-4.3379, -3.2187,  4.5726],\n",
            "        [-4.8398, -3.7219,  3.6700],\n",
            "        [-0.2425, -0.1987, -2.8844],\n",
            "        [-4.8293, -3.3743,  3.5987],\n",
            "        [-2.5355,  1.4560, -2.0405],\n",
            "        [-4.9529, -3.7240,  4.1202],\n",
            "        [-4.1945, -3.4463,  3.8438],\n",
            "        [-4.1228, -2.8220,  2.5456],\n",
            "        [-4.3776, -3.9816,  3.9277],\n",
            "        [-0.5793,  1.6249, -4.2651],\n",
            "        [-3.8778, -1.8091,  2.0438],\n",
            "        [-4.0722, -4.4091,  4.2768]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0901, -0.6215, -4.0686],\n",
            "        [ 2.5613, -2.5917, -4.3287],\n",
            "        [-0.6922,  1.3471, -3.0444],\n",
            "        [-2.3022,  3.6285, -3.6624],\n",
            "        [-4.2705,  0.0623,  0.3232],\n",
            "        [-4.2284, -3.7598,  4.2202],\n",
            "        [-4.2568, -3.1891,  3.5114],\n",
            "        [-4.7554, -3.2394,  3.1039],\n",
            "        [-2.4332,  2.5038, -3.1827],\n",
            "        [-4.2055, -3.7788,  3.5313],\n",
            "        [-3.4170, -2.1723,  2.1149],\n",
            "        [-2.5093,  3.4899, -3.4121],\n",
            "        [-4.6500, -3.6119,  3.8570],\n",
            "        [-2.0604,  2.9297, -3.9088],\n",
            "        [-2.6904,  1.5371, -1.3348],\n",
            "        [-4.5906, -3.3231,  3.0236]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2974e+00, -2.1001e+00, -1.5901e+00],\n",
            "        [ 2.8252e+00, -3.3553e+00, -2.9065e+00],\n",
            "        [-4.6959e+00, -4.0589e+00,  4.0182e+00],\n",
            "        [-4.1669e+00, -3.9482e+00,  3.6696e+00],\n",
            "        [-4.3581e+00,  5.6558e-02,  6.7050e-04],\n",
            "        [-4.4839e+00, -2.1751e+00,  2.1522e+00],\n",
            "        [-4.3819e+00, -3.4619e+00,  4.2947e+00],\n",
            "        [-3.1365e+00,  3.0198e+00, -3.2678e+00],\n",
            "        [ 2.5088e+00, -3.1705e+00, -3.1998e+00],\n",
            "        [-2.9489e+00,  2.3498e+00, -2.8229e+00],\n",
            "        [ 1.4075e+00, -1.5308e+00, -4.0181e+00],\n",
            "        [-4.9935e+00, -2.8579e+00,  2.6227e+00],\n",
            "        [-4.7329e+00, -1.5412e+00,  2.2506e+00],\n",
            "        [-2.6900e+00,  2.9119e+00, -3.6365e+00],\n",
            "        [-4.4140e+00, -4.0898e+00,  4.2151e+00],\n",
            "        [-4.4750e+00, -3.8194e+00,  3.8577e+00]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.2365,  1.0894, -1.9642],\n",
            "        [-5.0421, -3.1303,  3.3994],\n",
            "        [ 3.3712, -3.1419, -4.0668],\n",
            "        [-3.7329, -3.4600,  2.9352],\n",
            "        [-4.3638, -3.5484,  3.6533],\n",
            "        [-3.6724,  2.2530, -2.3334],\n",
            "        [-3.4344, -0.5879,  0.7375],\n",
            "        [-2.6475,  2.1717, -2.9701],\n",
            "        [-4.8481, -3.1602,  3.2573],\n",
            "        [-4.5205, -3.8109,  3.6861],\n",
            "        [-3.0167,  1.9727, -2.0453],\n",
            "        [-4.3796, -3.5085,  3.8453],\n",
            "        [-1.5908,  1.6448, -3.3694],\n",
            "        [-2.6723,  1.2588, -1.5330],\n",
            "        [-4.7091, -4.2688,  4.4289],\n",
            "        [-4.3052, -4.2993,  4.2273]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.8999,  3.0140, -3.7719],\n",
            "        [-3.8175, -3.7917,  3.7501],\n",
            "        [-1.5965,  1.2480, -1.8729],\n",
            "        [-4.7372, -3.8322,  4.4197],\n",
            "        [-4.2333, -3.5105,  3.5443],\n",
            "        [-5.0329, -3.4254,  3.8934],\n",
            "        [ 1.6547, -1.5961, -4.4591],\n",
            "        [ 0.2736, -0.0708, -3.6353],\n",
            "        [-4.5144, -3.6197,  3.2764],\n",
            "        [-4.5552, -4.4801,  4.0887],\n",
            "        [-4.6462, -3.9783,  3.9835],\n",
            "        [-4.6617, -3.3395,  3.9704],\n",
            "        [-2.3174, -1.0418, -0.0334],\n",
            "        [ 3.1388, -2.2817, -4.5194],\n",
            "        [ 1.8444, -1.6591, -4.4173],\n",
            "        [-1.3112,  1.4538, -2.5143]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.0832,  2.1643, -2.0726],\n",
            "        [-1.8153,  0.1857, -1.4109],\n",
            "        [-4.6435, -3.5533,  3.6803],\n",
            "        [-5.0750, -3.8737,  4.0163],\n",
            "        [-4.2937, -4.0406,  3.9046],\n",
            "        [-4.6439, -2.0014,  2.1107],\n",
            "        [-4.3413, -2.7726,  2.8716],\n",
            "        [-0.6023,  0.1604, -2.2289],\n",
            "        [-4.5250, -2.2623,  2.4173],\n",
            "        [-4.6175, -3.4623,  3.3514],\n",
            "        [ 0.2630,  0.3412, -2.7007],\n",
            "        [-4.0104, -4.3041,  4.1006],\n",
            "        [-5.0138, -4.0110,  4.5595],\n",
            "        [-2.3928, -1.2432,  0.0058],\n",
            "        [ 2.9003, -3.4315, -3.6680],\n",
            "        [-4.3232, -3.6711,  4.0502]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.7861, -4.1350,  3.8544],\n",
            "        [-1.5448,  1.4137, -2.9192],\n",
            "        [-3.9935, -3.6668,  4.3351],\n",
            "        [-4.6648, -4.3203,  4.5753],\n",
            "        [-4.5032, -3.8186,  4.3691],\n",
            "        [-0.2489,  0.0993, -3.6501],\n",
            "        [ 3.3351, -3.5821, -3.2624],\n",
            "        [-4.7230, -3.6199,  3.5127],\n",
            "        [-4.6970, -4.1425,  4.1411],\n",
            "        [-5.0749, -3.5320,  3.5581],\n",
            "        [-2.3724,  1.7421, -2.8618],\n",
            "        [-3.9058, -3.9660,  4.1693],\n",
            "        [-4.4847, -4.3422,  3.4340],\n",
            "        [ 2.5972, -3.1163, -3.8057],\n",
            "        [-4.4429, -4.3232,  3.8125],\n",
            "        [-4.2882, -4.7152,  4.0391]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.6423e+00,  1.0074e+00, -1.0600e+00],\n",
            "        [-3.3735e+00,  2.6056e+00, -3.3077e+00],\n",
            "        [-3.6523e+00, -3.6767e+00,  3.8683e+00],\n",
            "        [-1.9580e+00,  8.7168e-01, -1.8136e+00],\n",
            "        [-4.6006e+00, -3.9855e+00,  5.1028e+00],\n",
            "        [ 1.4470e+00, -2.0883e+00, -3.4377e+00],\n",
            "        [-4.5852e+00, -4.2176e-03,  4.5874e-01],\n",
            "        [ 2.5146e+00, -2.0449e+00, -3.7687e+00],\n",
            "        [ 3.0077e+00, -2.6622e+00, -3.8225e+00],\n",
            "        [-5.0782e+00, -4.1078e+00,  3.7698e+00],\n",
            "        [-3.5944e+00, -4.2637e+00,  2.8078e+00],\n",
            "        [-4.1002e+00, -3.8645e+00,  4.6236e+00],\n",
            "        [-3.8236e+00, -4.2430e+00,  4.3760e+00],\n",
            "        [-3.7906e+00, -4.2475e+00,  3.8207e+00],\n",
            "        [ 2.6005e+00, -2.3781e+00, -3.5988e+00],\n",
            "        [-2.2826e+00,  2.3362e+00, -2.4449e+00]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.9845, -3.8418,  3.4812],\n",
            "        [-0.2596, -1.5273, -0.5942],\n",
            "        [-4.3143, -2.3149,  1.6047],\n",
            "        [-3.6506, -3.0948,  3.0847],\n",
            "        [ 0.1301, -4.3059,  0.0936],\n",
            "        [-4.1688, -4.1417,  4.2609],\n",
            "        [-4.4989, -3.2859,  3.6950],\n",
            "        [ 2.9536, -3.5732, -3.2048],\n",
            "        [-4.5148, -4.3901,  4.1120],\n",
            "        [ 1.4094, -1.4650, -3.2543],\n",
            "        [ 3.3439, -3.3835, -2.8878],\n",
            "        [-3.7945, -1.8243,  1.5269],\n",
            "        [ 3.0280, -3.9422, -3.0886],\n",
            "        [-2.3869, -2.5807,  1.4575],\n",
            "        [ 2.8515, -3.4027, -3.4759],\n",
            "        [-3.0506, -2.0649,  1.5758]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.4094,  1.4200, -1.7576],\n",
            "        [-4.3593, -4.4102,  4.5722],\n",
            "        [-2.1140,  2.3883, -3.5698],\n",
            "        [-2.1278,  1.2454, -2.0987],\n",
            "        [-4.4142, -4.0352,  4.2228],\n",
            "        [-4.1048, -4.1922,  4.2357],\n",
            "        [ 1.5865, -2.0053, -3.8452],\n",
            "        [-4.5185, -3.3884,  4.0730],\n",
            "        [ 1.7338, -2.6073, -2.9288],\n",
            "        [-4.3282, -4.1129,  4.5223],\n",
            "        [-4.3504, -4.0183,  4.2834],\n",
            "        [-4.2179, -4.1679,  4.0685],\n",
            "        [-4.1313, -4.2929,  4.1678],\n",
            "        [-4.4631, -3.4895,  3.3898],\n",
            "        [-4.3874, -3.4924,  4.3487],\n",
            "        [-2.3275, -0.1931, -0.7870]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.1640, -3.7385,  4.2334],\n",
            "        [-4.4890, -3.6602,  4.1172],\n",
            "        [-4.3112, -3.9839,  4.2466],\n",
            "        [-2.6468,  1.4476, -2.0769],\n",
            "        [-0.4646,  0.2741, -2.4714],\n",
            "        [-3.8961, -3.4421,  3.8115],\n",
            "        [-4.3401, -3.9297,  4.2976],\n",
            "        [-2.6573,  0.9785, -0.7963],\n",
            "        [-4.4311, -4.3307,  3.6225],\n",
            "        [-4.1698, -3.7329,  4.4077],\n",
            "        [ 2.5386, -3.0881, -3.2672],\n",
            "        [-4.0959, -4.8691,  4.2833],\n",
            "        [ 0.2753, -1.0243, -1.7093],\n",
            "        [ 2.7257, -3.4298, -3.2152],\n",
            "        [-4.3009, -4.2508,  4.2982],\n",
            "        [-4.2683, -3.4301,  3.8433]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.3404, -4.3819,  4.1801],\n",
            "        [ 2.4862, -3.1017, -3.4559],\n",
            "        [-4.8194, -4.4333,  4.3422],\n",
            "        [-3.9268, -2.0427,  1.7846],\n",
            "        [-4.2524, -3.5431,  3.5333],\n",
            "        [ 2.7235, -3.7260, -3.0652],\n",
            "        [-1.3971,  0.8089, -3.0923],\n",
            "        [-3.1471, -2.6188,  2.0885],\n",
            "        [-3.8309, -4.1191,  4.4961],\n",
            "        [ 0.9656, -1.6896, -3.4105],\n",
            "        [-2.4101,  2.6836, -3.2334],\n",
            "        [-4.5265, -3.9596,  4.0676],\n",
            "        [-2.8633,  1.0212, -1.3060],\n",
            "        [-4.3807, -3.5313,  3.5789],\n",
            "        [ 3.1469, -3.6479, -2.6224],\n",
            "        [ 3.0575, -3.3582, -3.9632]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2333, -1.1513, -3.2034],\n",
            "        [ 1.7558, -2.3954, -3.1066],\n",
            "        [-3.1759, -3.5651,  3.3790],\n",
            "        [-3.7534, -3.8231,  3.7048],\n",
            "        [-3.5940, -3.4165,  3.9618],\n",
            "        [ 0.0071, -1.5114, -0.8942],\n",
            "        [-4.4473, -4.1705,  3.8469],\n",
            "        [-4.4501, -4.6880,  4.1051],\n",
            "        [-1.2685,  0.8199, -2.5125],\n",
            "        [-4.0269, -1.5009,  1.9289],\n",
            "        [-3.9179, -4.3320,  4.5059],\n",
            "        [-4.1847, -4.6478,  4.1671],\n",
            "        [-3.6894, -4.2019,  3.8249],\n",
            "        [-3.9092, -4.5620,  4.3042],\n",
            "        [ 2.7423, -3.0122, -4.0963],\n",
            "        [-3.7766, -4.6164,  3.5693]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.3697, -3.5525,  4.6239],\n",
            "        [ 2.4673, -3.2574, -3.1492],\n",
            "        [-3.8563, -3.5825,  4.4858],\n",
            "        [-3.9437, -3.4351,  4.1244],\n",
            "        [ 3.4883, -3.7374, -3.1731],\n",
            "        [-3.5014, -3.2806,  4.3870],\n",
            "        [-3.2006, -3.2209,  2.1969],\n",
            "        [-4.0972, -4.7156,  4.1972],\n",
            "        [-2.4750,  0.5944, -1.9027],\n",
            "        [-0.8723, -4.0694,  1.2730],\n",
            "        [ 3.6778, -2.8972, -3.0752],\n",
            "        [ 1.3621, -2.8831, -1.6363],\n",
            "        [-1.6690,  0.5118, -2.0817],\n",
            "        [-3.2985, -3.3454,  3.2349],\n",
            "        [-3.0972,  2.7001, -3.0783],\n",
            "        [-4.4581, -3.8541,  4.1032]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.8360, -2.7529, -3.6585],\n",
            "        [-4.2581, -3.5775,  3.4923],\n",
            "        [ 0.6392, -0.2264, -3.9461],\n",
            "        [ 3.4189, -3.5369, -3.2085],\n",
            "        [-4.0304, -4.3246,  4.1710],\n",
            "        [-4.3154, -3.9110,  3.5916],\n",
            "        [ 3.6846, -3.8284, -3.5544],\n",
            "        [-4.4357, -4.0128,  4.0428],\n",
            "        [-4.2713, -3.9821,  4.4100],\n",
            "        [ 2.1585, -2.1729, -3.8495],\n",
            "        [-4.1591, -3.4510,  3.0022],\n",
            "        [-4.1234, -4.1919,  3.9791],\n",
            "        [-3.9953, -3.8290,  4.2428],\n",
            "        [-3.9405, -3.5187,  3.9638],\n",
            "        [-4.6534, -4.1238,  4.3500],\n",
            "        [-3.4418, -3.4939,  3.8092]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.8356, -4.0493,  4.3032],\n",
            "        [-3.6876, -2.0489,  1.7023],\n",
            "        [-0.8138,  0.5661, -2.1215],\n",
            "        [-4.5142, -3.9587,  4.2125],\n",
            "        [ 0.6275, -1.1173, -2.6533],\n",
            "        [-0.2422, -0.0091, -2.7691],\n",
            "        [-4.1583, -4.4896,  4.2278],\n",
            "        [ 3.1132, -3.3195, -2.9478],\n",
            "        [ 2.0046, -1.9538, -3.4697],\n",
            "        [-4.7707, -4.0057,  3.5643],\n",
            "        [-3.1765,  1.2343, -0.8799],\n",
            "        [-4.2401, -3.8983,  4.1634],\n",
            "        [ 2.4628, -3.3176, -2.9275],\n",
            "        [ 0.2287, -3.9167, -0.5006],\n",
            "        [ 2.4671, -2.8973, -3.8423],\n",
            "        [ 3.0106, -3.4414, -3.2755]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.4410, -4.3259,  3.9004],\n",
            "        [-4.1613, -3.5480,  4.1310],\n",
            "        [-4.1409, -3.9571,  4.1108],\n",
            "        [-1.2925, -4.4410,  2.3502],\n",
            "        [-3.8734, -3.1735,  4.0797],\n",
            "        [-1.5172, -1.1926, -1.3847],\n",
            "        [-4.4486, -4.1348,  4.0655],\n",
            "        [-4.0794, -4.2206,  4.1703],\n",
            "        [-2.3549, -2.2302,  1.6094],\n",
            "        [-4.1057, -4.6094,  3.9378],\n",
            "        [-4.4225, -4.0606,  3.8916],\n",
            "        [-4.5575, -4.0738,  4.4927],\n",
            "        [-4.4253, -4.0358,  4.0911],\n",
            "        [ 2.7510, -3.2038, -2.7892],\n",
            "        [-4.3865, -2.5743,  2.8684],\n",
            "        [-4.0465, -2.2337,  2.2071]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.7081, -4.5717,  3.8050],\n",
            "        [ 2.4979, -2.4726, -3.4736],\n",
            "        [ 3.1128, -2.8887, -3.2653],\n",
            "        [-4.4828, -3.0049,  3.5150],\n",
            "        [-4.2602, -3.4743,  3.2494],\n",
            "        [-4.0714, -4.2579,  3.9440],\n",
            "        [-4.6554, -2.9713,  2.8421],\n",
            "        [-4.2095, -3.4414,  3.5174],\n",
            "        [ 3.4912, -2.8815, -4.3826],\n",
            "        [ 2.9463, -3.3173, -3.1298],\n",
            "        [ 1.6580, -1.4600, -3.5885],\n",
            "        [-4.3720, -3.7464,  4.3682],\n",
            "        [-4.1681, -4.4936,  4.4521],\n",
            "        [ 1.2600, -1.8151, -2.5445],\n",
            "        [ 3.2226, -2.9180, -4.0074],\n",
            "        [-2.9117,  2.4881, -3.1625]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.8011, -3.8088,  3.5523],\n",
            "        [-4.3078, -3.4610,  3.6395],\n",
            "        [-3.9669, -4.0223,  3.7249],\n",
            "        [-4.0916, -3.9251,  2.7667],\n",
            "        [-5.0279, -3.8333,  3.7713],\n",
            "        [-4.4156, -3.7444,  3.7126],\n",
            "        [-4.4607, -3.8302,  4.1024],\n",
            "        [-2.0755,  1.1675, -3.0130],\n",
            "        [ 1.1168, -1.5826, -3.4591],\n",
            "        [-2.9271, -0.7392, -0.1399],\n",
            "        [-4.3907, -3.3723,  4.0173],\n",
            "        [-2.3673, -0.7051,  0.1315],\n",
            "        [-3.9534, -3.8522,  3.9254],\n",
            "        [-3.3208,  0.7434, -0.9398],\n",
            "        [-3.8275, -2.3818,  2.7084],\n",
            "        [ 2.8615, -3.3056, -3.3611]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.2439, -3.9872,  4.5699],\n",
            "        [-4.2443, -3.2835,  3.5051],\n",
            "        [-2.4423, -1.3417,  0.6184],\n",
            "        [ 3.3471, -3.6338, -3.3408],\n",
            "        [-4.2946, -4.2541,  4.1398],\n",
            "        [-2.3743, -2.0640,  0.9993],\n",
            "        [ 2.6026, -2.4975, -3.1010],\n",
            "        [-4.0089, -4.2951,  4.3569],\n",
            "        [-3.7995, -3.6511,  3.1619],\n",
            "        [ 0.5255,  0.1851, -4.1024],\n",
            "        [-4.0742, -3.5624,  4.2219],\n",
            "        [-3.4542, -3.8194,  3.6709],\n",
            "        [ 2.6817, -3.1360, -2.9456],\n",
            "        [-3.1279,  0.8382, -1.7805],\n",
            "        [-4.1898, -4.2606,  4.2322],\n",
            "        [-1.6349,  1.4725, -2.5111]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.4423, -2.4534, -4.0609],\n",
            "        [-3.9778, -3.9824,  4.0139],\n",
            "        [-3.9554, -3.8076,  4.0911],\n",
            "        [-2.2238, -0.7960, -0.4504],\n",
            "        [-4.1694, -3.3734,  3.1318],\n",
            "        [-4.5952, -4.0988,  3.8651],\n",
            "        [-3.4326, -2.4253,  2.1782],\n",
            "        [ 1.3482, -2.2532, -2.4001],\n",
            "        [ 2.9395, -3.4369, -3.4111],\n",
            "        [-3.8598, -3.9964,  4.4627],\n",
            "        [-1.8496, -0.8878, -0.2131],\n",
            "        [-4.4930, -4.6840,  4.1921],\n",
            "        [-4.0885, -3.8495,  4.2783],\n",
            "        [-2.5517,  2.2012, -2.2304],\n",
            "        [-4.1812, -3.9605,  4.2290],\n",
            "        [-4.6212, -3.3916,  4.1442]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.5013, -3.3992,  4.1034],\n",
            "        [ 2.2887, -3.2814, -3.6309],\n",
            "        [-4.0867, -4.0819,  3.8149],\n",
            "        [-3.8514, -3.9719,  4.6143],\n",
            "        [ 1.0627, -1.3898, -3.6996],\n",
            "        [-4.0515, -3.8445,  3.7505],\n",
            "        [ 2.7684, -2.9580, -3.4700],\n",
            "        [-4.2978, -3.7674,  3.4728],\n",
            "        [ 2.5765, -3.6139, -2.7866],\n",
            "        [-3.9708, -3.5275,  3.6701],\n",
            "        [-4.2264, -4.1798,  4.0712],\n",
            "        [ 2.3294, -2.2330, -3.9346],\n",
            "        [-4.2489, -4.0658,  3.4947],\n",
            "        [-4.6582, -4.5087,  4.4877],\n",
            "        [-4.4751, -3.8691,  4.8935],\n",
            "        [-1.7017,  0.2883, -1.4440]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.2754, -4.0713,  3.9841],\n",
            "        [-4.4212, -4.4555,  3.9800],\n",
            "        [ 1.1830, -0.9722, -3.1606],\n",
            "        [-3.6973, -3.7544,  3.5707],\n",
            "        [-4.6150, -4.5681,  3.5348],\n",
            "        [-3.9782, -3.7198,  3.7381],\n",
            "        [-4.8697, -1.9555,  1.8976],\n",
            "        [ 2.7798, -3.1556, -3.4327],\n",
            "        [-1.4070,  0.9822, -2.9671],\n",
            "        [-3.4108, -3.7573,  3.4145],\n",
            "        [ 1.1733, -2.6957, -2.5511],\n",
            "        [-4.0072, -4.5102,  4.2316],\n",
            "        [-5.0132, -4.2328,  3.9772],\n",
            "        [ 1.4202, -1.8956, -3.1980],\n",
            "        [-4.0845,  1.7712, -1.6834],\n",
            "        [-4.3624, -3.6344,  3.4468]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.6455, -2.6736, -3.3873],\n",
            "        [-4.1836, -4.5317,  4.3762],\n",
            "        [-4.2557, -3.5209,  4.0164],\n",
            "        [-4.9948, -3.7390,  4.2053],\n",
            "        [ 2.7747, -2.2765, -3.8709],\n",
            "        [-4.3075, -3.8334,  3.8192],\n",
            "        [-4.3026, -2.8613,  2.1244],\n",
            "        [-4.5288, -4.1374,  4.5914],\n",
            "        [-0.4292,  0.6184, -4.3162],\n",
            "        [-4.1706, -4.3439,  3.7158],\n",
            "        [-3.1118, -2.7180,  2.4543],\n",
            "        [-2.7715,  3.0021, -1.9569],\n",
            "        [-4.5243, -4.0544,  4.4401],\n",
            "        [-3.5557, -2.8952,  2.2136],\n",
            "        [-4.6520, -4.3764,  4.2096],\n",
            "        [-3.3748, -3.0522,  2.4293]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.9960, -3.5425,  4.1901],\n",
            "        [-4.4955, -4.6003,  4.0081],\n",
            "        [-3.3235,  2.3288, -2.8545],\n",
            "        [-3.9156, -4.0593,  3.9392],\n",
            "        [-4.5895, -3.6068,  4.0953],\n",
            "        [-4.1832, -4.0846,  4.2267],\n",
            "        [-4.7244, -2.0641,  2.5681],\n",
            "        [ 3.0697, -3.4011, -3.4696],\n",
            "        [ 2.5005, -2.7446, -4.4655],\n",
            "        [-4.8069, -4.3594,  3.9005],\n",
            "        [-0.6781, -0.1162, -2.7284],\n",
            "        [ 0.3350, -0.5545, -2.4992],\n",
            "        [-4.4271, -3.6407,  4.4565],\n",
            "        [ 2.1835, -2.5956, -2.9967],\n",
            "        [-3.9870, -3.7642,  3.7966],\n",
            "        [-4.7352, -3.4190,  4.4640]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.4803, -4.1756,  3.5606],\n",
            "        [ 3.2740, -3.0139, -3.3365],\n",
            "        [-4.1056, -3.6290,  3.7389],\n",
            "        [-3.7870, -4.1944,  3.6578],\n",
            "        [-4.5709, -3.8204,  3.7622],\n",
            "        [-4.9029, -2.1255,  2.6394],\n",
            "        [-4.6190, -3.2460,  3.5163],\n",
            "        [-3.9687, -4.7815,  3.8740],\n",
            "        [-2.7351,  2.9715, -2.9055],\n",
            "        [-4.2149, -4.2074,  3.6233],\n",
            "        [-4.2254, -4.1026,  3.3453],\n",
            "        [-3.9846, -3.9081,  3.7399],\n",
            "        [-4.1733, -3.9358,  4.0236],\n",
            "        [ 0.3960, -1.2642, -1.3074],\n",
            "        [-4.8507, -4.0755,  4.2217],\n",
            "        [-3.7904, -1.1560,  1.1459]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3320, -3.3432, -3.2633],\n",
            "        [-3.7207, -3.8765,  3.3041],\n",
            "        [-3.2886, -3.1848,  2.8255],\n",
            "        [ 2.2959, -2.3546, -3.9049],\n",
            "        [-3.8864,  1.0056, -1.3302],\n",
            "        [-1.6904, -0.1536, -1.2119],\n",
            "        [-4.5880, -3.9799,  3.9658],\n",
            "        [-4.7486, -2.2808,  2.3896],\n",
            "        [ 0.4775, -0.7018, -3.2937],\n",
            "        [-4.0034, -4.1204,  4.8122],\n",
            "        [ 2.6089, -2.1574, -4.5289],\n",
            "        [-4.7121, -4.2350,  4.0909],\n",
            "        [-3.5083, -4.1142,  4.2650],\n",
            "        [-3.7727, -3.8647,  3.1885],\n",
            "        [-4.7990, -2.2560,  2.2528],\n",
            "        [ 0.0248,  0.2379, -3.9356]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.6873, -3.4395,  3.3283],\n",
            "        [-2.9186,  2.3157, -2.7394],\n",
            "        [-4.9480, -3.4699,  4.0940],\n",
            "        [-0.5842,  0.1974, -2.8845],\n",
            "        [-4.3754, -3.8014,  4.0680],\n",
            "        [-4.8087, -2.9210,  3.6129],\n",
            "        [ 1.4043, -1.7886, -3.8807],\n",
            "        [-4.9997, -3.9196,  4.4082],\n",
            "        [ 3.7600, -3.1819, -3.4952],\n",
            "        [-3.7680, -1.8900,  1.9468],\n",
            "        [ 2.7071, -2.6721, -3.6787],\n",
            "        [-3.9803, -3.7328,  3.5391],\n",
            "        [-4.7003, -3.5421,  4.2223],\n",
            "        [-4.3750, -4.2290,  4.6057],\n",
            "        [-3.9992, -4.1621,  4.0696],\n",
            "        [-4.5910, -4.0745,  3.8423]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.9399,  2.2399, -1.8839],\n",
            "        [-4.7569, -1.4981,  2.1771],\n",
            "        [ 2.7865, -2.7815, -3.4941],\n",
            "        [-4.4993, -3.7138,  3.6583],\n",
            "        [-4.5573, -3.8238,  4.0303],\n",
            "        [ 2.6588, -2.2776, -4.0779],\n",
            "        [-4.3932, -3.9965,  4.2071],\n",
            "        [-4.8933, -0.4016,  0.7760],\n",
            "        [-4.6807, -2.5875,  2.9346],\n",
            "        [-3.9780, -2.6234,  2.4380],\n",
            "        [-3.4244, -2.0569,  2.7570],\n",
            "        [-4.6972, -3.9313,  3.9394],\n",
            "        [ 3.2682, -3.5656, -3.2021],\n",
            "        [-4.8210, -2.7996,  3.0119],\n",
            "        [-3.0683,  2.0263, -1.9866],\n",
            "        [-4.9194, -3.1576,  2.5187]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.1168, -3.9907,  3.8192],\n",
            "        [ 3.3634, -2.6612, -3.4771],\n",
            "        [-4.2939, -3.1436,  3.9215],\n",
            "        [ 2.6891, -3.0311, -4.0571],\n",
            "        [ 3.0641, -3.2659, -3.9954],\n",
            "        [-4.0736, -3.4427,  4.2802],\n",
            "        [-4.6041, -3.6625,  4.1963],\n",
            "        [-3.4601, -4.0479,  4.5959],\n",
            "        [-0.2277,  0.6482, -3.5095],\n",
            "        [-4.1766, -3.9688,  3.8428],\n",
            "        [-4.2149, -4.2859,  3.9870],\n",
            "        [-4.0486, -4.1312,  4.1508],\n",
            "        [-5.0277, -3.5458,  3.1996],\n",
            "        [-4.5852, -4.2193,  4.6707],\n",
            "        [-4.3586, -3.2237,  3.3057],\n",
            "        [ 2.6233, -2.8320, -3.6497]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.6784, -4.1722,  4.3067],\n",
            "        [ 2.0851, -2.7927, -4.0135],\n",
            "        [-3.4361,  2.0950, -2.1416],\n",
            "        [-4.6540, -4.3979,  4.0303],\n",
            "        [ 1.8261, -2.3433, -3.1181],\n",
            "        [-4.9775, -2.5128,  1.7586],\n",
            "        [-3.9218, -2.3444,  2.4343],\n",
            "        [-0.9041,  0.6721, -3.8056],\n",
            "        [-3.6998, -1.8908,  1.5239],\n",
            "        [-4.4725, -3.6187,  4.2202],\n",
            "        [ 2.6644, -2.9025, -3.7098],\n",
            "        [-4.3971, -4.1969,  4.3587],\n",
            "        [-2.7187,  3.0692, -3.1434],\n",
            "        [-2.6630,  2.4830, -3.5761],\n",
            "        [-5.0768, -3.8323,  3.8814],\n",
            "        [ 2.7232, -3.1069, -3.5082]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.7036, -2.7901, -3.5487],\n",
            "        [-4.5101, -3.7432,  3.7276],\n",
            "        [-1.0127,  1.8590, -3.3668],\n",
            "        [-0.2072,  0.0620, -2.4456],\n",
            "        [-4.1731, -3.0533,  3.6205],\n",
            "        [-4.4139, -2.4172,  2.5879],\n",
            "        [-4.0254, -3.2944,  3.1504],\n",
            "        [-5.1343, -3.5856,  4.4173],\n",
            "        [-4.5337, -3.6288,  4.2385],\n",
            "        [-4.3557, -3.7453,  4.0541],\n",
            "        [-4.4093, -0.4749,  0.9516],\n",
            "        [-1.3599,  1.0194, -2.5911],\n",
            "        [-4.0874, -4.1935,  4.3432],\n",
            "        [-3.7814,  0.9060, -0.9262],\n",
            "        [-1.4912,  0.1026, -0.7285],\n",
            "        [-3.9605, -4.1712,  3.3487]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.3980, -3.6544,  4.0413],\n",
            "        [-4.0846, -1.6358,  1.4709],\n",
            "        [-4.0699, -1.1952,  0.2741],\n",
            "        [ 1.9350, -2.7081, -3.0011],\n",
            "        [-5.0321, -2.8570,  3.2880],\n",
            "        [-4.3130, -3.7255,  3.3878],\n",
            "        [-4.4013, -4.6101,  4.1503],\n",
            "        [ 1.2542, -1.3546, -3.5122],\n",
            "        [-5.2957, -1.1999,  1.1540],\n",
            "        [-4.4311, -2.9438,  4.4542],\n",
            "        [-4.2551, -3.8985,  4.6400],\n",
            "        [-4.3409, -3.7821,  3.5751],\n",
            "        [-1.0509,  1.1057, -2.2394],\n",
            "        [-2.8274,  1.6394, -1.7768],\n",
            "        [-4.8732, -1.4648,  1.6073],\n",
            "        [ 0.6149, -1.7771, -2.8861]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.6475, -4.1400,  4.1442],\n",
            "        [-4.3681, -3.6242,  4.0608],\n",
            "        [ 2.1185, -1.9340, -3.3298],\n",
            "        [-4.3981, -3.6693,  3.8321],\n",
            "        [-4.9219, -3.0015,  3.7984],\n",
            "        [-3.0289,  2.2149, -3.1615],\n",
            "        [-4.2584, -4.0513,  4.1163],\n",
            "        [-4.6099, -4.1946,  4.1821],\n",
            "        [-3.9775, -4.3198,  3.8484],\n",
            "        [ 2.3103, -2.9509, -3.8198],\n",
            "        [-4.8106, -4.2261,  4.6830],\n",
            "        [-3.6012, -2.9883,  3.0338],\n",
            "        [-4.8642, -3.7187,  3.8112],\n",
            "        [-2.2274,  2.2554, -2.7893],\n",
            "        [-4.0154, -2.8187,  2.4356],\n",
            "        [-4.0663, -3.3508,  3.2080]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.5902,  0.9391, -1.4540],\n",
            "        [-2.4586,  2.2059, -2.5696]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-5.0678, -4.2368,  4.6580],\n",
            "        [-1.9603,  1.8954, -2.3127],\n",
            "        [ 1.4450, -1.6548, -3.7367],\n",
            "        [ 2.3392, -2.4634, -3.7063],\n",
            "        [-4.5069, -4.4655,  4.1501],\n",
            "        [-4.3114, -3.7980,  4.0705],\n",
            "        [ 3.0012, -2.5205, -3.7429],\n",
            "        [ 0.5939, -1.0825, -3.8678],\n",
            "        [-3.9707, -3.4826,  3.0777],\n",
            "        [-4.4603, -4.1083,  4.2021],\n",
            "        [-3.7047, -1.5678,  1.1700],\n",
            "        [-3.6539, -3.3571,  4.0127],\n",
            "        [-2.0582,  1.5805, -2.3285],\n",
            "        [ 1.3442, -1.6399, -3.8969],\n",
            "        [-4.6677, -3.2689,  4.4439],\n",
            "        [-4.6357, -4.5490,  3.5098]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Epoch: 3, Train Loss:  0.07566659152507782\n",
            "tensor([[ 3.1175, -2.8308, -4.0816],\n",
            "        [-2.6387,  2.4823, -2.5736],\n",
            "        [-3.6121,  1.6955, -2.4442],\n",
            "        [-4.6082, -4.4984,  4.0810],\n",
            "        [-4.3403, -4.0937,  4.4819],\n",
            "        [-1.9910,  1.6618, -3.8207],\n",
            "        [-4.4994, -3.5414,  3.8415],\n",
            "        [-4.3200, -4.1731,  4.2301],\n",
            "        [-4.4828, -4.3843,  4.1661],\n",
            "        [-4.2961, -4.5098,  4.0884],\n",
            "        [-0.5327,  0.5068, -3.6754],\n",
            "        [-4.8797, -3.7367,  4.1663],\n",
            "        [-4.8958, -4.2049,  3.6802],\n",
            "        [-3.1255,  2.4938, -1.8772],\n",
            "        [-4.4791, -4.1016,  3.8370],\n",
            "        [-4.6420, -3.6720,  4.2310]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.0865,  1.4350, -1.5279],\n",
            "        [-5.4192, -4.0207,  3.8347],\n",
            "        [-4.4637, -4.1395,  4.0814],\n",
            "        [-3.6052, -3.7011,  2.9923],\n",
            "        [-3.9557, -3.4797,  3.8596],\n",
            "        [-2.5733,  2.6642, -3.4985],\n",
            "        [-4.9632, -1.7605,  1.3204],\n",
            "        [-3.9430, -3.1268,  3.6127],\n",
            "        [-4.9731, -1.8544,  1.6197],\n",
            "        [-4.0296, -4.0743,  3.6726],\n",
            "        [-4.2328, -4.2554,  3.6059],\n",
            "        [-4.7090, -4.1771,  3.6025],\n",
            "        [ 1.8885, -1.6427, -3.2287],\n",
            "        [-3.4135, -3.6512,  3.8419],\n",
            "        [-4.5923, -4.1329,  4.2758],\n",
            "        [-4.8596, -4.3651,  3.6706]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.4712, -4.2021,  4.4191],\n",
            "        [-4.3219, -3.8345,  4.0520],\n",
            "        [-3.1666, -4.1359,  3.2651],\n",
            "        [ 1.4331, -2.5017, -2.7665],\n",
            "        [-5.0545, -3.8657,  4.3822],\n",
            "        [-4.0282, -4.2164,  3.4172],\n",
            "        [-3.3991,  3.0191, -3.1303],\n",
            "        [-4.2151, -3.9271,  4.6553],\n",
            "        [-4.3016, -3.5439,  4.0155],\n",
            "        [-1.2074,  1.0753, -3.3365],\n",
            "        [-4.7677, -3.9296,  4.1077],\n",
            "        [-4.5105, -3.9980,  3.5372],\n",
            "        [-4.4071, -3.1037,  2.9087],\n",
            "        [ 1.0672, -1.4331, -3.6622],\n",
            "        [ 2.0982, -2.7943, -2.3877],\n",
            "        [-4.0478, -3.6885,  3.7427]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.6274,  1.9553, -2.4610],\n",
            "        [-3.8549, -3.8527,  3.8493],\n",
            "        [-3.0809, -0.2088, -0.3694],\n",
            "        [-3.1013,  3.2672, -2.7806],\n",
            "        [ 1.4533, -1.5281, -2.4176],\n",
            "        [-4.4112, -4.2763,  3.8460],\n",
            "        [ 1.9053, -2.6402, -3.4303],\n",
            "        [-3.5570, -2.6307,  2.3807],\n",
            "        [-4.4818, -3.4631,  3.4047],\n",
            "        [-4.2377, -3.8592,  3.8687],\n",
            "        [-4.2385, -3.9674,  4.0203],\n",
            "        [-4.6169, -3.7521,  3.6536],\n",
            "        [ 3.0079, -3.0217, -4.0770],\n",
            "        [-3.9479, -4.2579,  4.2666],\n",
            "        [ 1.9058, -2.2452, -2.4322],\n",
            "        [-4.1169, -3.8217,  4.2622]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6406, -2.5923, -0.8662],\n",
            "        [-4.3167, -3.8780,  4.0095],\n",
            "        [-4.4369, -3.5424,  3.8282],\n",
            "        [-4.4190, -4.0725,  4.7277],\n",
            "        [-4.3965, -4.1695,  3.6736],\n",
            "        [ 2.8526, -3.0036, -3.7112],\n",
            "        [-4.0865,  1.0321, -1.2193],\n",
            "        [-2.0028, -0.3723,  0.1170],\n",
            "        [-4.6511, -3.9197,  4.2827],\n",
            "        [-4.4101, -3.1462,  3.3313],\n",
            "        [ 3.5453, -3.7631, -3.2175],\n",
            "        [ 2.8429, -3.2796, -3.9983],\n",
            "        [-0.5804,  0.0380, -2.0832],\n",
            "        [-4.6286, -3.1786,  4.3642],\n",
            "        [-1.2948,  1.0184, -2.9051],\n",
            "        [-4.4220, -2.8592,  2.8918]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.3764,  2.4883, -2.6969],\n",
            "        [-3.9388, -3.9928,  4.0836],\n",
            "        [-3.3919, -4.1766,  3.8633],\n",
            "        [ 2.9053, -2.7511, -3.9969],\n",
            "        [-4.9326, -3.9002,  3.6882],\n",
            "        [ 3.7274, -2.8527, -3.4530],\n",
            "        [-3.9717,  1.2367, -1.8035],\n",
            "        [-4.6774, -3.7834,  4.1563],\n",
            "        [-4.0501, -3.4493,  4.2027],\n",
            "        [-4.8112, -4.8487,  4.3597],\n",
            "        [-4.6761, -4.1525,  4.5077],\n",
            "        [ 1.2841, -1.7559, -3.3707],\n",
            "        [-4.0708, -4.2912,  4.0295],\n",
            "        [-4.4405, -3.8576,  3.9477],\n",
            "        [-4.2322, -3.9266,  3.8680],\n",
            "        [-3.8278, -3.5810,  3.8719]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.7115, -4.1778,  4.6011],\n",
            "        [ 0.8828, -1.9017, -1.7203],\n",
            "        [-4.8043, -4.1933,  4.0696],\n",
            "        [ 2.9996, -3.4011, -3.3418],\n",
            "        [-3.2362,  2.3219, -2.0859],\n",
            "        [-2.7496, -0.0531, -1.2376],\n",
            "        [-2.9379, -3.3801,  2.6774],\n",
            "        [-4.4527, -3.8839,  3.8997],\n",
            "        [-3.4657, -4.1091,  3.8947],\n",
            "        [ 0.6627, -2.1678, -1.9118],\n",
            "        [-2.3493,  0.0192, -1.4333],\n",
            "        [-4.3512, -3.9296,  4.3294],\n",
            "        [-4.4079, -3.5307,  4.2955],\n",
            "        [-3.1697, -3.4308,  2.5980],\n",
            "        [-4.1049, -4.4201,  4.9133],\n",
            "        [-4.1114, -3.5860,  3.9269]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.1268, -2.7865, -3.3167],\n",
            "        [-4.1257, -3.8814,  3.9733],\n",
            "        [-2.8543, -0.0380, -0.5437],\n",
            "        [-4.2338, -3.4018,  3.2687],\n",
            "        [-1.5123,  0.9174, -2.3680],\n",
            "        [ 3.0074, -2.8990, -4.0445],\n",
            "        [-4.7490, -4.7980,  4.4580],\n",
            "        [-4.9249, -4.6157,  4.4475],\n",
            "        [-4.2911, -4.3512,  4.0929],\n",
            "        [-3.8041, -3.2568,  3.2844],\n",
            "        [ 2.9359, -2.5178, -3.0524],\n",
            "        [-4.6753, -4.1248,  4.3122],\n",
            "        [-4.4500, -3.7019,  4.1982],\n",
            "        [-5.1693, -2.4001,  1.9804],\n",
            "        [ 3.1556, -3.2943, -3.4465],\n",
            "        [-4.1245, -3.9293,  3.6962]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.0570, -3.9452,  3.5396],\n",
            "        [-4.0111, -4.1014,  4.3708],\n",
            "        [-4.4668, -4.2795,  4.2938],\n",
            "        [-4.6423, -4.0381,  3.8163],\n",
            "        [-4.5497, -4.1272,  4.1337],\n",
            "        [-4.1219, -4.7609,  4.3297],\n",
            "        [-4.5428, -3.6817,  3.9125],\n",
            "        [ 1.0978, -2.1045, -2.6956],\n",
            "        [-4.4477, -4.2373,  3.9773],\n",
            "        [ 2.4669, -3.5697, -2.6842],\n",
            "        [-3.1767,  0.8124, -1.3679],\n",
            "        [-4.1331, -3.9655,  4.4139],\n",
            "        [-2.7780,  1.2032, -2.2655],\n",
            "        [-4.0808, -3.9551,  4.2355],\n",
            "        [-3.9701, -3.7952,  4.4080],\n",
            "        [-4.5765, -3.5385,  4.5809]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.1164,  3.5604, -3.1209],\n",
            "        [-4.2885, -4.0723,  3.7693],\n",
            "        [-4.9810, -3.8485,  4.6252],\n",
            "        [-1.5751,  3.0615, -3.8958],\n",
            "        [-3.1558,  1.3187, -2.0901],\n",
            "        [ 2.0447, -3.3888, -1.7396],\n",
            "        [-2.6572,  2.6483, -2.6932],\n",
            "        [ 3.2212, -2.8442, -4.5946],\n",
            "        [-4.4596, -4.2144,  4.0447],\n",
            "        [-4.4036, -4.1824,  3.8368],\n",
            "        [-2.3798,  2.6024, -3.6256],\n",
            "        [-3.1283,  1.7530, -2.1170],\n",
            "        [-4.2768, -2.0814,  1.6376],\n",
            "        [-4.2780, -3.7681,  3.9235],\n",
            "        [-2.6111,  0.4860, -0.4971],\n",
            "        [ 2.8864, -3.3835, -3.3302]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.8183, -3.7606, -3.0851],\n",
            "        [-4.2081, -4.6047,  4.1832],\n",
            "        [-2.0136, -0.1399, -0.7031],\n",
            "        [-4.5503, -3.9564,  4.0157],\n",
            "        [ 3.5785, -3.0135, -3.6999],\n",
            "        [ 1.1338, -1.7149, -2.7489],\n",
            "        [-3.6900, -4.5711,  3.8972],\n",
            "        [-4.5951, -3.7538,  4.3905],\n",
            "        [-4.0460, -3.9085,  3.9788],\n",
            "        [ 1.4941, -3.0940, -1.4719],\n",
            "        [-4.4956, -3.9666,  4.1981],\n",
            "        [ 3.0966, -2.8143, -3.6500],\n",
            "        [-0.2584, -0.7810, -3.1903],\n",
            "        [ 3.3101, -3.1570, -3.4659],\n",
            "        [ 1.2342, -4.1972, -0.4524],\n",
            "        [-4.2376, -3.8298,  4.0344]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.0073, -4.3582,  4.4892],\n",
            "        [ 1.9922, -2.6578, -3.5930],\n",
            "        [-3.4675, -2.8072,  2.6611],\n",
            "        [ 1.2245, -1.3904, -2.4021],\n",
            "        [-4.5395, -4.1597,  3.7960],\n",
            "        [-4.7161, -3.8544,  4.0094],\n",
            "        [-3.7938,  2.2589, -2.0192],\n",
            "        [-4.2130, -4.1486,  4.6441],\n",
            "        [-4.9096, -3.6901,  3.5434],\n",
            "        [ 2.8484, -3.0770, -3.7394],\n",
            "        [-4.1457, -4.1785,  3.7242],\n",
            "        [-4.4236, -4.3176,  4.5625],\n",
            "        [-3.0472,  2.1546, -2.8598],\n",
            "        [ 1.8483, -1.9333, -3.4665],\n",
            "        [ 3.3619, -3.3951, -3.5929],\n",
            "        [-4.5936, -4.1164,  4.3416]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.6564, -3.6342,  3.8487],\n",
            "        [-3.5045, -3.8188,  3.7640],\n",
            "        [ 3.0587, -3.2796, -3.8385],\n",
            "        [-3.9859, -4.6999,  4.2254],\n",
            "        [-2.2182,  1.0947, -2.8030],\n",
            "        [-4.3870, -3.7224,  4.5892],\n",
            "        [ 3.0016, -2.6259, -3.2987],\n",
            "        [-1.9048,  2.4197, -3.3800],\n",
            "        [-3.7365, -4.1135,  3.7033],\n",
            "        [-1.8311,  0.6536, -1.6429],\n",
            "        [-3.7061, -3.9072,  3.9546],\n",
            "        [ 2.5665, -2.6878, -3.5368],\n",
            "        [-4.5192, -3.8104,  3.3833],\n",
            "        [-2.5215,  2.1112, -2.8520],\n",
            "        [-4.4052, -3.8065,  3.5052],\n",
            "        [-4.9215, -3.9777,  4.2982]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.6166, -3.7328,  4.2792],\n",
            "        [-4.6812, -4.5681,  4.0574],\n",
            "        [-4.7323, -3.8928,  4.3086],\n",
            "        [-4.5582, -4.1819,  4.0934],\n",
            "        [-2.9475, -4.3786,  3.7672],\n",
            "        [-4.1752, -4.2787,  4.2172],\n",
            "        [-4.4681, -4.0617,  3.8619],\n",
            "        [-4.9100, -4.3025,  4.2521],\n",
            "        [-4.3755, -4.3706,  3.7909],\n",
            "        [ 2.9628, -3.2335, -3.1360],\n",
            "        [-0.6101, -0.7755, -2.1925],\n",
            "        [-4.3689, -4.2278,  4.1146],\n",
            "        [-2.7957,  1.1417, -1.8171],\n",
            "        [ 2.7766, -2.6605, -3.4340],\n",
            "        [-2.1107,  0.2399, -1.4755],\n",
            "        [-3.6239, -3.8806,  2.8163]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.2534, -2.4495,  2.8743],\n",
            "        [-4.1983, -3.8635,  3.9840],\n",
            "        [ 3.3228, -3.7886, -3.6436],\n",
            "        [-4.5816, -3.7335,  4.0161],\n",
            "        [-4.2068, -3.9356,  3.8661],\n",
            "        [-4.5320, -3.0460,  3.5316],\n",
            "        [-1.9415,  2.1669, -3.6517],\n",
            "        [-4.3383, -3.7568,  4.3480],\n",
            "        [-2.0356,  2.2885, -3.1302],\n",
            "        [-4.5273, -3.8150,  3.6953],\n",
            "        [-3.6630, -2.6941,  1.8597],\n",
            "        [-3.5246, -3.8802,  3.0542],\n",
            "        [-4.3865, -4.2782,  4.6190],\n",
            "        [-2.6071,  2.0176, -3.1915],\n",
            "        [-4.1865, -4.0452,  4.0828],\n",
            "        [ 2.1669, -2.6687, -3.2640]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.5203, -4.1250,  4.0458],\n",
            "        [-4.6717, -3.6722,  3.8122],\n",
            "        [ 2.3317, -2.5422, -4.1135],\n",
            "        [-1.9344,  1.8608, -3.1824],\n",
            "        [-3.5039, -2.1707,  1.7622],\n",
            "        [-4.4849, -3.5881,  3.9765],\n",
            "        [ 3.3612, -3.1208, -3.6901],\n",
            "        [ 2.8688, -3.1641, -4.2720],\n",
            "        [ 2.7520, -3.2227, -3.7483],\n",
            "        [-0.5888,  1.4193, -4.3554],\n",
            "        [-4.1028, -4.5835,  4.1776],\n",
            "        [-5.1793, -3.8116,  4.2281],\n",
            "        [-3.4345,  0.8300, -2.0425],\n",
            "        [ 3.1794, -3.1777, -3.5174],\n",
            "        [-3.9218, -4.2070,  4.1735],\n",
            "        [-0.2739,  0.2171, -2.5898]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.9732, -2.6106, -3.5811],\n",
            "        [-4.7862, -3.0623,  3.6063],\n",
            "        [ 2.7657, -3.2163, -3.8368],\n",
            "        [-2.2141,  2.4766, -2.8402],\n",
            "        [-3.7541, -4.3675,  4.3035],\n",
            "        [-3.6962, -3.0858,  3.8291],\n",
            "        [-0.7596,  0.1284, -1.7753],\n",
            "        [-2.9996, -4.3615,  3.4716],\n",
            "        [ 1.3402, -1.1912, -3.1751],\n",
            "        [-0.8417, -0.3585, -3.3526],\n",
            "        [-3.8271, -4.1256,  3.8451],\n",
            "        [-5.2634, -1.7284,  2.0296],\n",
            "        [-3.3945, -3.7880,  3.3727],\n",
            "        [-4.3400, -3.7398,  3.7765],\n",
            "        [-4.6221, -4.0664,  4.6385],\n",
            "        [-4.2079, -3.3225,  3.2138]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.9952,  1.2297, -3.3216],\n",
            "        [-3.6215, -3.9751,  3.7424],\n",
            "        [-4.3546, -4.0080,  4.2317],\n",
            "        [-2.7637,  2.5754, -3.5020],\n",
            "        [-4.2639, -3.5240,  3.8536],\n",
            "        [-4.8482, -2.3923,  2.3307],\n",
            "        [-4.6565, -1.8313,  1.9169],\n",
            "        [-4.9411, -3.3023,  3.4162],\n",
            "        [-4.7202, -3.8987,  4.1993],\n",
            "        [-2.6549,  2.0334, -3.4181],\n",
            "        [ 2.8214, -2.6898, -4.0628],\n",
            "        [ 2.4323, -2.1651, -2.7559],\n",
            "        [-4.5976, -4.3574,  4.1800],\n",
            "        [-4.3457, -3.8687,  4.0255],\n",
            "        [-4.1872, -3.4560,  3.1425],\n",
            "        [ 2.9420, -2.7589, -3.5933]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.8777,  2.8295, -3.5413],\n",
            "        [ 3.5560, -3.4317, -3.9281],\n",
            "        [-4.2325, -4.6936,  3.8042],\n",
            "        [ 3.2854, -3.7955, -4.3079],\n",
            "        [-4.4039, -4.3940,  4.5502],\n",
            "        [-5.0131, -3.0156,  3.4618],\n",
            "        [-2.1135, -0.3992, -0.8800],\n",
            "        [ 2.8466, -2.2313, -4.1381],\n",
            "        [-2.5381, -3.9358,  2.3266],\n",
            "        [-1.7721,  0.2734, -1.6005],\n",
            "        [-1.8435,  2.0305, -3.6583],\n",
            "        [ 2.9452, -2.1728, -4.2275],\n",
            "        [ 0.3868, -0.5014, -2.7333],\n",
            "        [-4.3072, -4.1205,  3.9061],\n",
            "        [-4.1163, -3.3622,  3.9889],\n",
            "        [-4.5830, -4.2779,  3.8219]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0003,  1.1449, -2.8645],\n",
            "        [-3.7124, -2.8831,  3.4108],\n",
            "        [-4.4751, -3.8890,  3.5046],\n",
            "        [ 3.7121, -2.9748, -4.1410],\n",
            "        [-3.7505, -4.2565,  4.4775],\n",
            "        [-3.8797, -3.7753,  3.6065],\n",
            "        [-3.2593,  2.4873, -2.3731],\n",
            "        [ 2.4141, -3.1396, -3.0460],\n",
            "        [-4.6882, -4.1253,  3.7486],\n",
            "        [-4.5187, -3.6329,  4.2109],\n",
            "        [-4.8056, -3.7510,  3.9032],\n",
            "        [-1.8222,  1.9355, -3.8985],\n",
            "        [-4.7978, -4.2506,  4.5494],\n",
            "        [-4.1961, -3.2939,  3.2180],\n",
            "        [ 2.8935, -2.9212, -4.0285],\n",
            "        [-4.5360, -3.9475,  4.1465]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.2174, -2.8512, -3.8439],\n",
            "        [-4.4336, -3.8982,  4.0023],\n",
            "        [-3.8634, -3.1159,  2.2979],\n",
            "        [-4.3593, -4.5207,  4.4754],\n",
            "        [-4.1195, -3.4601,  3.7492],\n",
            "        [-3.5735, -3.7156,  3.7913],\n",
            "        [-4.5367, -3.4831,  3.6405],\n",
            "        [ 3.2574, -2.6242, -4.4177],\n",
            "        [ 3.0614, -2.9030, -3.5639],\n",
            "        [-3.5597, -3.5228,  3.4784],\n",
            "        [-4.3518, -4.2680,  4.0454],\n",
            "        [ 3.3588, -3.4897, -3.2862],\n",
            "        [-4.2508, -3.5518,  3.8907],\n",
            "        [-4.8586, -3.1055,  3.6356],\n",
            "        [-4.5993, -3.9947,  4.1428],\n",
            "        [-4.3196, -3.6929,  4.2642]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.9927, -4.7140,  4.3487],\n",
            "        [-4.7389, -4.1605,  3.4973],\n",
            "        [-2.4951, -1.7099,  0.5910],\n",
            "        [-4.7059, -4.1441,  4.8583],\n",
            "        [-3.8768, -3.5882,  3.0452],\n",
            "        [-4.0540,  1.0927, -1.3019],\n",
            "        [ 3.8501, -3.2966, -3.7919],\n",
            "        [ 2.3043, -2.2058, -4.7518],\n",
            "        [-3.3813, -2.9674,  2.5906],\n",
            "        [-4.3323, -3.9045,  4.1230],\n",
            "        [-4.4452, -4.6187,  4.0382],\n",
            "        [-4.6336, -4.2027,  4.7717],\n",
            "        [ 3.3330, -2.9050, -3.8163],\n",
            "        [-4.3593, -3.4602,  3.0894],\n",
            "        [-2.7403,  2.4472, -2.7276],\n",
            "        [ 2.9632, -2.4666, -3.6698]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.3992, -4.4152,  4.1769],\n",
            "        [-4.9167, -3.2844,  3.4919],\n",
            "        [-0.7143,  0.4548, -3.9213],\n",
            "        [ 3.4592, -3.6346, -3.7508],\n",
            "        [ 3.5410, -3.2013, -3.6891],\n",
            "        [-2.4020,  1.8327, -3.2156],\n",
            "        [-2.2448,  3.3704, -3.0145],\n",
            "        [-4.3466, -4.8604,  4.0047],\n",
            "        [ 3.8897, -3.6179, -3.9297],\n",
            "        [ 3.8973, -2.7661, -3.9604],\n",
            "        [-4.3104, -4.3560,  4.1880],\n",
            "        [-4.4247, -4.3051,  4.2910],\n",
            "        [ 3.1952, -2.6105, -3.9924],\n",
            "        [-4.2004, -2.5170,  2.7382],\n",
            "        [-2.7357,  3.1587, -3.6444],\n",
            "        [-4.4893, -4.1102,  4.7422]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.2076, -1.2822,  1.0971],\n",
            "        [-1.7442,  1.9367, -3.2610],\n",
            "        [-3.1378,  3.0107, -2.7020],\n",
            "        [-4.9334, -3.5655,  3.6201],\n",
            "        [-0.6990,  0.1908, -3.4157],\n",
            "        [-4.1193, -4.0224,  3.8160],\n",
            "        [-2.9344,  2.5359, -3.4279],\n",
            "        [ 3.5832, -3.9203, -3.9725],\n",
            "        [-4.6117, -3.0023,  3.0350],\n",
            "        [-4.3470, -3.4400,  3.8817],\n",
            "        [ 3.7159, -3.2138, -3.7004],\n",
            "        [ 3.5850, -3.0610, -3.5738],\n",
            "        [ 0.4898,  0.3274, -4.7492],\n",
            "        [-3.3242,  2.5353, -2.0350],\n",
            "        [-4.8860, -4.2846,  4.5193],\n",
            "        [-3.0670,  3.0698, -3.3079]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.6113, -3.9877,  3.6365],\n",
            "        [ 2.6871, -2.8521, -4.0453],\n",
            "        [-4.6135, -0.4972,  0.6812],\n",
            "        [-3.8815, -2.7439,  2.7136],\n",
            "        [-4.3893, -4.0987,  4.2808],\n",
            "        [-4.9216, -3.7573,  4.5727],\n",
            "        [ 3.8442, -2.7614, -4.2974],\n",
            "        [-4.5037, -3.2544,  2.8619],\n",
            "        [-4.7813, -4.2455,  3.9224],\n",
            "        [-4.5716, -4.1947,  4.4103],\n",
            "        [-4.9913, -2.7218,  2.9603],\n",
            "        [ 2.2091, -1.7874, -4.3001],\n",
            "        [-4.5389, -3.6619,  3.9814],\n",
            "        [-4.4480, -4.4954,  4.1258],\n",
            "        [-3.7400,  2.8153, -1.3186],\n",
            "        [-4.7842, -3.6837,  3.2818]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.1495, -4.3664,  4.0338],\n",
            "        [-2.2354,  0.5658, -1.2534],\n",
            "        [-2.7778,  1.7385, -2.6791],\n",
            "        [-2.6353,  2.6252, -3.8313],\n",
            "        [ 3.1910, -3.1109, -3.7048],\n",
            "        [-2.9333,  2.5662, -2.7268],\n",
            "        [-4.2521, -3.8269,  3.9867],\n",
            "        [ 0.0802, -1.4652, -1.5243],\n",
            "        [-4.2111, -4.3099,  3.9877],\n",
            "        [-4.2070, -4.0701,  3.3309],\n",
            "        [-5.2330, -2.6725,  3.3455],\n",
            "        [ 3.2048, -2.7904, -3.9539],\n",
            "        [-4.3846, -4.4886,  4.5847],\n",
            "        [-3.0443,  2.8468, -2.9186],\n",
            "        [-4.7894, -4.0368,  3.5667],\n",
            "        [-4.3526, -4.4438,  4.0875]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.4974, -3.1860,  3.5463],\n",
            "        [-3.5930, -3.7953,  2.6759],\n",
            "        [ 3.6958, -3.3397, -4.2192],\n",
            "        [-4.3256,  0.3830,  0.1640],\n",
            "        [-5.1342, -3.5745,  4.1324],\n",
            "        [-2.9775,  3.1833, -3.0858],\n",
            "        [-1.5364,  1.0328, -2.4597],\n",
            "        [ 3.4404, -2.9907, -3.8345],\n",
            "        [-4.3807, -4.0304,  3.9940],\n",
            "        [-4.5655, -4.4132,  3.7152],\n",
            "        [-4.5602, -3.8634,  4.1550],\n",
            "        [-4.6872, -3.7637,  4.2483],\n",
            "        [ 2.6175, -2.4434, -3.5922],\n",
            "        [-4.3834, -4.0637,  3.9052],\n",
            "        [-4.3495, -3.4999,  2.6274],\n",
            "        [-5.0224, -3.6569,  4.0305]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.4209, -3.6944,  4.1628],\n",
            "        [-4.0506, -3.6383,  3.9977],\n",
            "        [-3.6291,  1.7707, -1.6352],\n",
            "        [-4.5048, -3.9605,  4.3321],\n",
            "        [-1.2934, -1.6064, -0.8403],\n",
            "        [-4.6922, -3.5781,  4.1893],\n",
            "        [-0.3877,  0.2705, -2.8468],\n",
            "        [-2.7561,  3.1210, -3.3225],\n",
            "        [-0.3900,  0.6773, -3.4955],\n",
            "        [-3.6349,  3.2041, -2.7727],\n",
            "        [ 2.6235, -1.4346, -3.5709],\n",
            "        [-4.1770, -4.0539,  3.8500],\n",
            "        [-4.2185, -3.8253,  3.8862],\n",
            "        [ 3.6133, -3.3829, -3.6683],\n",
            "        [-4.9217, -3.8546,  3.8124],\n",
            "        [-2.5449,  3.3197, -3.6220]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.4949, -2.8397, -4.1327],\n",
            "        [ 2.0003, -2.1631, -4.0963],\n",
            "        [ 3.1271, -2.6062, -3.7102],\n",
            "        [-4.7809, -4.5225,  4.2080],\n",
            "        [ 3.4904, -3.2382, -4.0004],\n",
            "        [ 0.4100, -2.1949, -1.8886],\n",
            "        [-4.7750, -2.8757,  3.8689],\n",
            "        [-4.5812, -3.7831,  4.6873],\n",
            "        [ 0.2877, -0.3187, -3.9919],\n",
            "        [-4.5815, -4.0045,  4.7636],\n",
            "        [ 3.6249, -2.8132, -4.0142],\n",
            "        [ 2.9418, -1.7981, -4.1699],\n",
            "        [ 1.0189, -1.2346, -3.4060],\n",
            "        [ 3.2126, -3.3260, -3.8060],\n",
            "        [-4.1585,  1.6483, -0.9228],\n",
            "        [-3.8957, -3.7806,  3.9872]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.8170, -3.9407,  4.4946],\n",
            "        [ 3.1961, -2.2440, -4.4813],\n",
            "        [-3.9197, -3.8382,  3.7000],\n",
            "        [-4.7191, -3.7977,  3.5348],\n",
            "        [-4.8917, -2.3182,  2.7026],\n",
            "        [-4.5024, -4.1231,  4.3365],\n",
            "        [-2.8404,  2.4026, -3.4450],\n",
            "        [ 2.1972, -2.0323, -4.6919],\n",
            "        [-4.5646, -2.6135,  2.9025],\n",
            "        [-4.6002, -4.3075,  4.1833],\n",
            "        [-4.6393, -3.6518,  4.3088],\n",
            "        [-4.1712, -3.8832,  4.2723],\n",
            "        [-4.8897, -3.8594,  4.4075],\n",
            "        [-5.2424, -3.9737,  3.9291],\n",
            "        [-4.5263, -4.4255,  4.1961],\n",
            "        [-4.4810, -4.1313,  3.8233]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 4.0235, -3.0419, -4.1354],\n",
            "        [-4.2733, -4.0580,  3.8320],\n",
            "        [-4.7092, -1.6724,  1.6216],\n",
            "        [-4.0463, -4.3165,  3.6935],\n",
            "        [ 3.3647, -3.1705, -3.9021],\n",
            "        [ 2.6748, -2.1942, -4.3509],\n",
            "        [-3.9623, -4.0852,  4.7344],\n",
            "        [-4.7102, -3.7268,  3.8027],\n",
            "        [ 3.4659, -2.8596, -4.0629],\n",
            "        [-3.9880, -3.9297,  3.6580],\n",
            "        [-4.1141, -4.0559,  4.5425],\n",
            "        [ 3.4011, -2.9711, -4.2567],\n",
            "        [-3.7534, -2.4725,  2.2888],\n",
            "        [-4.4718, -3.8674,  3.9338],\n",
            "        [-4.7592, -3.4612,  3.9082],\n",
            "        [-4.2333, -4.3554,  4.1834]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.6471, -4.1731,  3.8997],\n",
            "        [ 2.6271, -2.8797, -4.1931],\n",
            "        [ 3.7908, -3.2169, -3.7177],\n",
            "        [ 2.3457, -2.5744, -3.6932],\n",
            "        [-4.5111, -4.0129,  3.8715],\n",
            "        [-4.0652, -4.1300,  4.5018],\n",
            "        [-4.7370, -3.7561,  3.9561],\n",
            "        [-4.9626, -3.8195,  4.4951],\n",
            "        [-4.1406, -2.7933,  3.2524],\n",
            "        [-4.5603, -4.3325,  4.2961],\n",
            "        [-4.8874, -3.5821,  4.0807],\n",
            "        [-4.0360,  2.8782, -2.8336],\n",
            "        [ 3.0621, -2.7439, -4.1800],\n",
            "        [-4.8096, -3.4868,  2.9643],\n",
            "        [ 2.2997, -1.6382, -4.4231],\n",
            "        [-4.5180, -3.7670,  4.1235]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.0335, -0.8573,  1.1439],\n",
            "        [ 1.7953, -1.0823, -4.6152],\n",
            "        [-4.4592, -3.5159,  3.6933],\n",
            "        [-4.2105, -4.2101,  3.7855],\n",
            "        [ 2.8835, -2.7531, -4.2086],\n",
            "        [-4.6144, -4.5237,  4.4150],\n",
            "        [-4.1648,  1.9277, -1.6753],\n",
            "        [ 1.7146, -2.1504, -3.7257],\n",
            "        [-3.6473, -2.7556,  2.3539],\n",
            "        [-4.7120, -3.3934,  4.3203],\n",
            "        [-4.3410, -3.4421,  3.4735],\n",
            "        [ 3.2141, -3.3906, -4.6820],\n",
            "        [-4.2975, -3.5942,  3.4011],\n",
            "        [-4.0939, -3.5708,  3.8451],\n",
            "        [-4.9558, -4.1740,  4.1848],\n",
            "        [-3.9624, -4.2392,  4.3673]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.5674, -2.9261, -4.1657],\n",
            "        [-5.0180, -3.6270,  3.8183],\n",
            "        [ 3.3304, -3.7029, -2.9474],\n",
            "        [-4.5783, -3.8068,  4.0022],\n",
            "        [ 0.8520, -0.9311, -3.6182],\n",
            "        [-2.4089,  2.4865, -3.3781],\n",
            "        [-4.1989, -3.8415,  3.9779],\n",
            "        [-4.5587, -4.6929,  4.3061],\n",
            "        [ 3.3429, -3.5961, -3.1465],\n",
            "        [-4.4016, -4.3855,  3.9432],\n",
            "        [-2.7420,  1.7365, -1.3426],\n",
            "        [-4.0760, -4.0098,  4.0801],\n",
            "        [-4.9241, -3.8785,  4.7518],\n",
            "        [-4.2435, -3.6755,  4.0752],\n",
            "        [-1.4720,  0.6989, -1.8633],\n",
            "        [-3.6233, -3.5978,  3.6254]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.5871, -3.5575,  3.7849],\n",
            "        [-3.2175, -4.0132,  3.0255],\n",
            "        [-4.1342, -4.0435,  3.9106],\n",
            "        [ 0.7260, -0.6124, -4.5313],\n",
            "        [ 2.5525, -3.3183, -3.2811],\n",
            "        [-2.1813, -0.8311, -0.8135],\n",
            "        [-4.3578, -4.1532,  4.2273],\n",
            "        [-4.3861, -4.2633,  3.7963],\n",
            "        [-4.4179, -2.9012,  3.7137],\n",
            "        [-3.3047,  2.6968, -2.6307],\n",
            "        [ 2.7645, -3.3907, -3.3420],\n",
            "        [-4.7042, -4.4583,  4.1374],\n",
            "        [-4.2866, -4.2930,  4.3597],\n",
            "        [-4.7256, -4.2909,  3.9970],\n",
            "        [-4.3429, -3.6815,  4.1135],\n",
            "        [-4.4680, -2.8715,  3.4036]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.1061, -4.8560,  4.1251],\n",
            "        [-3.8841, -4.0494,  3.9179],\n",
            "        [-3.9495, -4.0827,  4.3968],\n",
            "        [-3.1787,  3.1275, -3.3316],\n",
            "        [-5.0955, -4.4748,  4.0793],\n",
            "        [ 3.1785, -2.6677, -3.5403],\n",
            "        [-3.5231, -3.9364,  3.9068],\n",
            "        [-4.4830, -4.1541,  4.7439],\n",
            "        [-4.1554, -5.0751,  4.2054],\n",
            "        [-4.8234, -3.8137,  4.5853],\n",
            "        [-4.7321, -4.2383,  4.6427],\n",
            "        [-4.3732, -4.2156,  3.7243],\n",
            "        [-4.1686, -4.1985,  4.5673],\n",
            "        [-3.6109, -3.5575,  3.9376],\n",
            "        [-4.4092, -4.3624,  4.3933],\n",
            "        [ 2.9192, -3.2007, -3.9044]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.9334, -4.1335,  3.9004],\n",
            "        [-3.8498, -3.8439,  3.8722],\n",
            "        [-4.2911, -4.2377,  4.1615],\n",
            "        [-2.4664, -1.5695,  0.6268],\n",
            "        [-4.2715, -4.2308,  4.1211],\n",
            "        [-3.7146,  1.9276, -1.5794],\n",
            "        [-4.3602, -3.9643,  3.7627],\n",
            "        [-4.4838, -4.5260,  4.6767],\n",
            "        [ 0.8152, -0.9226, -4.4232],\n",
            "        [-4.7939, -4.1075,  4.2680],\n",
            "        [-2.9634,  2.8269, -2.1216],\n",
            "        [-4.8218, -3.6069,  4.1614],\n",
            "        [-4.9315, -4.0116,  4.1940],\n",
            "        [-5.1704, -4.0868,  4.3849],\n",
            "        [-4.1201,  1.9708, -1.3966],\n",
            "        [-3.6371, -3.8126,  3.4643]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.9217, -3.3180,  3.8315],\n",
            "        [-2.7618, -0.0683, -0.2240],\n",
            "        [-2.7099,  2.5370, -2.6678],\n",
            "        [-4.4666, -4.2367,  4.3735],\n",
            "        [-4.1056, -3.9674,  3.8147],\n",
            "        [-4.4200, -4.4187,  4.4618],\n",
            "        [ 0.7139, -0.5291, -3.2548],\n",
            "        [-3.9941, -4.6517,  4.4792],\n",
            "        [-4.2632, -4.5240,  4.1873],\n",
            "        [-3.6877, -3.6397,  3.0250],\n",
            "        [-5.0795, -4.6101,  4.1564],\n",
            "        [-4.6683, -3.8050,  4.0060],\n",
            "        [-4.4084, -3.7547,  4.0607],\n",
            "        [-3.5074, -3.8281,  3.9953],\n",
            "        [ 3.5855, -3.1407, -3.2230],\n",
            "        [-2.8672,  2.5356, -2.1220]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.3356, -3.9320,  4.4714],\n",
            "        [ 3.5201, -3.5787, -3.7512],\n",
            "        [ 3.0249, -3.1698, -3.6861],\n",
            "        [-1.3190,  1.6761, -3.2563],\n",
            "        [-5.1491, -4.3020,  4.2248],\n",
            "        [-4.6720, -0.8986,  2.0954],\n",
            "        [-4.0793, -3.4754,  2.3504],\n",
            "        [-4.5462, -3.6430,  3.9706],\n",
            "        [-4.7250, -4.2579,  4.6600],\n",
            "        [-3.9404, -0.7642,  0.7102],\n",
            "        [-4.4580, -4.0874,  4.3424],\n",
            "        [-4.9577, -3.9896,  3.6169],\n",
            "        [-4.0498,  0.8742, -0.5940],\n",
            "        [-4.5015, -3.0481,  4.4567],\n",
            "        [-4.0892, -3.3708,  4.2560],\n",
            "        [-4.6014, -4.0385,  3.7530]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.8490, -3.6173,  3.9811],\n",
            "        [-4.4327, -4.2462,  4.3244],\n",
            "        [-4.9027, -4.0369,  4.0998],\n",
            "        [ 3.8479, -3.0639, -3.7505],\n",
            "        [ 4.0524, -3.0680, -3.6659],\n",
            "        [ 2.7638, -3.0678, -3.4304],\n",
            "        [-0.6264, -0.3158, -1.7195],\n",
            "        [-3.3466,  2.7024, -2.4444],\n",
            "        [-4.0120, -4.0322,  4.2293],\n",
            "        [ 3.9023, -3.5908, -3.5447],\n",
            "        [-4.4068, -4.3417,  4.3467],\n",
            "        [-2.1183,  1.9774, -3.7482],\n",
            "        [-3.8092, -3.9614,  4.1721],\n",
            "        [-2.3786,  2.6914, -3.0396],\n",
            "        [-0.6380,  0.3771, -2.3258],\n",
            "        [-4.5437, -3.4703,  4.5173]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.1094,  2.4485, -1.9891],\n",
            "        [ 3.7598, -3.0661, -3.7186],\n",
            "        [-4.0482, -4.2299,  3.8964],\n",
            "        [ 3.4047, -2.5335, -4.2617],\n",
            "        [ 3.9707, -4.2952, -3.3279],\n",
            "        [-4.7400, -4.4517,  4.2677],\n",
            "        [-4.0725, -4.7277,  4.9368],\n",
            "        [-4.8721, -4.4585,  4.0276],\n",
            "        [-4.7180, -4.2289,  4.4221],\n",
            "        [-4.1044, -4.3831,  4.5118],\n",
            "        [-4.1487, -3.6049,  4.4302],\n",
            "        [-3.0871,  3.2453, -3.3827],\n",
            "        [ 3.0692, -2.9037, -3.3699],\n",
            "        [-4.4472, -4.3897,  4.7699],\n",
            "        [ 3.7535, -3.1053, -3.5687],\n",
            "        [-4.6568, -4.0797,  3.8327]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.9292, -3.0020, -2.9614],\n",
            "        [-4.1641, -4.0637,  4.6983],\n",
            "        [-2.5806,  2.9567, -3.3130],\n",
            "        [-4.1767, -3.3806,  3.5774],\n",
            "        [-3.9866, -3.4746,  3.8755],\n",
            "        [-4.7888, -4.7271,  4.1527],\n",
            "        [-4.4468, -4.2116,  3.6249],\n",
            "        [-3.8460, -3.7616,  3.5398],\n",
            "        [ 3.3480, -3.3040, -3.3004],\n",
            "        [-4.6584, -4.3373,  4.1946],\n",
            "        [-4.4582, -3.5315,  3.8108],\n",
            "        [-2.8488,  2.9356, -1.7477],\n",
            "        [-4.5310, -4.8161,  4.0711],\n",
            "        [-4.7936, -4.5413,  3.3742],\n",
            "        [-4.6631, -4.3517,  4.0722],\n",
            "        [-3.6312,  1.3674, -1.4976]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.7182, -3.5846,  4.9116],\n",
            "        [-4.3079, -3.7958,  3.7906],\n",
            "        [-3.6886, -1.6851,  1.7094],\n",
            "        [ 2.4237, -2.9625, -3.4046],\n",
            "        [-3.4620, -4.2013,  3.5781],\n",
            "        [-4.0430, -4.7805,  3.7336],\n",
            "        [-3.6527, -1.9709,  1.7046],\n",
            "        [-3.9596, -1.4944,  1.5479],\n",
            "        [-3.7220, -4.2134,  4.0462],\n",
            "        [ 3.7096, -3.6999, -3.8832],\n",
            "        [-4.0239, -4.3219,  3.6988],\n",
            "        [ 3.3466, -2.2773, -3.9207],\n",
            "        [-4.3681, -3.9012,  4.5133],\n",
            "        [-3.0251,  2.6324, -2.8887],\n",
            "        [-4.9489, -3.8964,  4.3912],\n",
            "        [-2.0497,  2.9632, -3.8584]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-5.4664, -1.7236,  1.4606],\n",
            "        [-3.8178, -4.2370,  4.2839],\n",
            "        [ 2.9024, -3.5042, -3.7327],\n",
            "        [-4.6926, -3.9152,  4.2054],\n",
            "        [-4.5541, -1.7372,  2.3449],\n",
            "        [-5.1899, -4.0201,  4.5590],\n",
            "        [ 3.1151, -3.2534, -3.5367],\n",
            "        [-4.4661, -4.1275,  4.0518],\n",
            "        [-3.9394, -3.9333,  4.0031],\n",
            "        [-4.4285,  0.9166, -0.4311],\n",
            "        [-1.8306,  1.8304, -2.0435],\n",
            "        [-3.3618,  1.3969, -1.5351],\n",
            "        [-4.0909, -4.2836,  4.0877],\n",
            "        [-1.9015,  1.6426, -3.1061],\n",
            "        [-4.9059, -4.2554,  3.9563],\n",
            "        [ 3.2880, -3.0166, -3.2936]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.6491, -2.2391,  0.7752],\n",
            "        [-3.1580,  2.9718, -3.1812],\n",
            "        [-4.6505, -4.3506,  3.3802],\n",
            "        [-2.1397,  2.4188, -2.9540],\n",
            "        [-4.3697, -3.6703,  3.7836],\n",
            "        [-3.4083, -2.6356,  2.0328],\n",
            "        [-4.4798, -3.7657,  3.7514],\n",
            "        [-4.4894, -4.3015,  4.1079],\n",
            "        [-3.6965,  2.8516, -2.2545],\n",
            "        [-2.6009,  2.3591, -2.9415],\n",
            "        [ 1.6740, -0.9945, -3.6056],\n",
            "        [-4.8215, -3.0667,  3.5691],\n",
            "        [-1.4982, -1.9860,  0.2045],\n",
            "        [-4.0627, -4.4157,  3.4379],\n",
            "        [-1.5973,  2.2342, -3.8446],\n",
            "        [-4.0354, -3.0306,  3.4998]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3936, -1.6843, -3.2513],\n",
            "        [-3.2062,  1.9198, -1.5210],\n",
            "        [ 2.9129, -2.4631, -3.7005],\n",
            "        [-3.3737, -0.0511, -0.0851],\n",
            "        [ 1.4522, -1.7711, -4.4157],\n",
            "        [-5.5167, -2.5794,  3.6773],\n",
            "        [-4.9242, -4.1492,  4.3676],\n",
            "        [-4.6721, -4.2308,  4.9168],\n",
            "        [ 0.6779, -0.1591, -3.4373],\n",
            "        [-4.5238, -3.4875,  3.6478],\n",
            "        [-3.4067, -2.5253,  2.1489],\n",
            "        [-4.5549, -3.9215,  4.5994],\n",
            "        [-3.8742, -3.7116,  3.6114],\n",
            "        [-5.0299, -3.1798,  3.2243],\n",
            "        [-4.5680, -4.3312,  4.1609],\n",
            "        [-0.4117,  1.5328, -3.8540]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.4868, -3.2820,  4.4690],\n",
            "        [-4.5522, -2.7390,  2.9262],\n",
            "        [-4.7530, -4.5580,  4.6566],\n",
            "        [-3.0280,  2.4993, -2.7371],\n",
            "        [-4.9020, -4.1022,  4.0594],\n",
            "        [-4.3929, -4.4466,  4.3724],\n",
            "        [ 1.2621, -0.6893, -4.9342],\n",
            "        [-4.3637, -4.2999,  4.7485],\n",
            "        [-3.2807, -3.2930,  3.0854],\n",
            "        [ 0.0877, -1.2750, -2.1210],\n",
            "        [-4.5286, -4.5756,  4.8221],\n",
            "        [-4.5364, -2.2593,  3.2763],\n",
            "        [-4.9046, -4.4097,  3.7884],\n",
            "        [ 3.3546, -2.5992, -3.6724],\n",
            "        [ 3.2318, -3.2716, -3.8132],\n",
            "        [-2.8760,  2.6380, -3.0669]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.1125,  3.5218, -3.4135],\n",
            "        [ 1.1951, -1.4631, -3.3558],\n",
            "        [-2.0498,  3.0820, -3.8224],\n",
            "        [-3.9692, -3.7608,  4.0339],\n",
            "        [-4.6525, -3.3673,  3.8828],\n",
            "        [-4.0486, -1.2554,  1.2976],\n",
            "        [-4.6817, -3.2709,  2.9448],\n",
            "        [-3.3617,  2.1115, -1.5515],\n",
            "        [-4.7165, -3.7656,  4.0091],\n",
            "        [ 3.5496, -3.5132, -4.0882],\n",
            "        [ 2.2445, -2.9515, -3.7007],\n",
            "        [ 3.2030, -3.4438, -4.1463],\n",
            "        [-4.7210, -3.8913,  3.7363],\n",
            "        [ 3.0581, -2.7311, -4.0226],\n",
            "        [-4.2393, -4.3676,  4.6424],\n",
            "        [-4.9346, -1.0140,  2.0797]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.8719, -3.9110,  4.1071],\n",
            "        [ 3.3017, -3.8655, -3.9546],\n",
            "        [-3.9132, -3.7617,  3.9647],\n",
            "        [-4.2653, -4.2575,  3.6226],\n",
            "        [-2.4919,  3.1652, -3.3688],\n",
            "        [-4.8230, -0.1990,  1.4106],\n",
            "        [-4.0697, -4.0690,  4.5857],\n",
            "        [-5.1332, -3.8355,  3.8411],\n",
            "        [-2.9325,  3.7355, -3.5621],\n",
            "        [-4.6035, -4.0323,  4.4025],\n",
            "        [ 3.8681, -3.2711, -3.7477],\n",
            "        [ 3.4995, -3.4487, -2.9102],\n",
            "        [-3.0256,  3.2758, -2.9794],\n",
            "        [ 3.7647, -4.0892, -3.5515],\n",
            "        [ 2.2612, -1.7508, -3.9103],\n",
            "        [-4.4694, -4.3724,  3.9610]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.4243, -2.9333, -3.8531],\n",
            "        [-3.6783,  1.4605, -0.8527],\n",
            "        [ 3.6142, -3.1094, -3.8602],\n",
            "        [-4.3391, -4.0614,  4.0151],\n",
            "        [-4.5357, -3.6797,  4.9912],\n",
            "        [ 2.5952, -2.0019, -4.3249],\n",
            "        [-4.6453, -3.4541,  3.8778],\n",
            "        [-4.5637, -2.9777,  3.8996],\n",
            "        [-4.7644, -4.1807,  4.3305],\n",
            "        [-5.2928, -4.1673,  4.1337],\n",
            "        [-4.6317, -4.1463,  4.5273],\n",
            "        [-2.4107,  1.6364, -1.9132],\n",
            "        [ 3.7034, -2.9571, -3.6861],\n",
            "        [-1.8493,  1.7901, -2.5397],\n",
            "        [-4.3386, -3.9230,  3.8684],\n",
            "        [-4.2270, -4.0097,  4.1822]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.3690, -3.6305,  4.1026],\n",
            "        [-4.6198, -4.1215,  4.0863],\n",
            "        [ 4.1210, -3.1931, -3.3869],\n",
            "        [ 3.4236, -3.4571, -3.6513],\n",
            "        [-4.6479, -2.8725,  2.7670],\n",
            "        [ 3.3272, -3.0272, -3.9020],\n",
            "        [-4.7589, -3.6061,  3.7298],\n",
            "        [-4.4823, -4.1981,  4.3834],\n",
            "        [-2.1531,  3.6640, -3.7631],\n",
            "        [-4.0939, -3.7821,  3.6915],\n",
            "        [-3.5397, -2.9087,  2.8031],\n",
            "        [-4.6651, -4.0926,  3.7059],\n",
            "        [-3.6281,  2.6607, -2.7832],\n",
            "        [-4.4646, -4.0876,  3.6717],\n",
            "        [-3.4929, -2.6391,  2.0425],\n",
            "        [-3.1482,  2.9740, -2.6513]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.4461, -3.5804,  4.5219],\n",
            "        [-3.7469, -4.2153,  3.9437],\n",
            "        [-4.4162, -4.3027,  3.9349],\n",
            "        [-5.0880, -1.9510,  3.2775],\n",
            "        [-4.3489, -4.2785,  2.9152],\n",
            "        [ 2.4921, -2.8480, -4.5003],\n",
            "        [-3.2250,  3.5474, -3.0166],\n",
            "        [-5.4059, -2.2379,  3.2693],\n",
            "        [-4.9255, -3.5152,  3.9176],\n",
            "        [-4.4793, -4.5152,  4.2834],\n",
            "        [-4.5971, -3.7981,  4.8588],\n",
            "        [-4.4851, -3.6832,  3.6566],\n",
            "        [-4.3992, -4.1457,  4.0168],\n",
            "        [-2.7234,  3.0895, -2.8064],\n",
            "        [ 2.7393, -3.3433, -4.5192],\n",
            "        [-4.5964, -3.4663,  4.0234]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.4206, -3.7083, -3.1543],\n",
            "        [-4.4956, -4.1893,  4.1130],\n",
            "        [ 3.6010, -3.6617, -3.3748],\n",
            "        [ 2.4583, -2.9037, -3.7911],\n",
            "        [-2.0323,  1.5508, -3.4178],\n",
            "        [-3.0760,  2.6884, -2.1220],\n",
            "        [-5.3160, -3.3762,  3.4532],\n",
            "        [-4.1080, -3.8125,  3.7899],\n",
            "        [ 3.4750, -3.2021, -3.4926],\n",
            "        [-3.9748, -2.4330,  2.7079],\n",
            "        [-4.7637, -3.7418,  4.1553],\n",
            "        [-4.7714, -4.3039,  4.6350],\n",
            "        [-4.1180, -4.0114,  3.8448],\n",
            "        [ 3.7336, -3.5138, -3.6836],\n",
            "        [ 3.0560, -2.9138, -3.9794],\n",
            "        [-4.2658, -4.0393,  4.7367]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.2174, -4.1365,  3.9668],\n",
            "        [-5.1373, -4.5859,  4.5031],\n",
            "        [-2.9822,  3.3381, -2.8167],\n",
            "        [-4.7214, -3.8912,  4.0865],\n",
            "        [-2.6922, -2.7483,  1.5017],\n",
            "        [-3.2986,  3.0239, -2.4345],\n",
            "        [ 3.3679, -3.5814, -3.3881],\n",
            "        [-2.8828, -0.9260,  0.7687],\n",
            "        [ 3.6368, -3.2127, -3.4749],\n",
            "        [-2.8692,  2.5754, -2.2635],\n",
            "        [ 2.5546, -2.7779, -3.4829],\n",
            "        [ 3.4394, -4.1215, -4.3558],\n",
            "        [ 3.6507, -3.5499, -3.5802],\n",
            "        [-4.5951, -4.2659,  4.6728],\n",
            "        [-4.7438, -4.6632,  4.4687],\n",
            "        [-2.7244,  2.9875, -3.1961]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.3160, -3.7614, -3.8237],\n",
            "        [-4.2767, -4.2222,  3.5269],\n",
            "        [-3.9851, -3.4021,  3.5412],\n",
            "        [-3.8714, -3.3217,  2.6051],\n",
            "        [-4.2118, -4.1245,  4.7773],\n",
            "        [-3.7902, -1.0370,  0.6505],\n",
            "        [-4.4324, -4.3208,  4.6103],\n",
            "        [-4.5249, -3.8437,  4.0700],\n",
            "        [-4.3748, -4.1862,  4.1889],\n",
            "        [ 1.9415, -2.2149, -4.2923],\n",
            "        [-4.4585, -4.3745,  4.5932],\n",
            "        [-3.9978, -2.2365,  1.7429],\n",
            "        [-2.2728,  1.9535, -2.6679],\n",
            "        [-3.3223,  2.1862, -2.5958],\n",
            "        [ 3.0613, -2.6402, -3.9406],\n",
            "        [-4.2181, -3.9875,  4.5888]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.9928, -3.6165,  3.7535],\n",
            "        [-4.8591, -2.9961,  3.2014],\n",
            "        [-2.8106,  1.6316, -2.3038],\n",
            "        [ 3.3309, -3.3961, -3.2733],\n",
            "        [ 3.6218, -3.4986, -4.4632],\n",
            "        [-4.4895, -1.5756,  1.9358],\n",
            "        [-4.4197, -4.2646,  4.0692],\n",
            "        [-4.3161, -3.8582,  4.1453],\n",
            "        [-4.3335, -4.0197,  3.9372],\n",
            "        [-4.3116, -3.7538,  4.0699],\n",
            "        [-3.3681,  3.0522, -2.9728],\n",
            "        [-4.6074, -4.4248,  4.5266],\n",
            "        [-3.9114, -4.2854,  4.4800],\n",
            "        [-5.0946, -3.9358,  4.6479],\n",
            "        [-4.2852, -4.1264,  4.3466],\n",
            "        [-3.9899, -0.2811,  0.3601]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-5.1698, -4.4720,  4.1281],\n",
            "        [-1.9727,  2.6105, -3.2452],\n",
            "        [-0.9833,  0.9762, -2.8446],\n",
            "        [-4.0369, -3.3666,  2.9712],\n",
            "        [-3.8345, -3.8035,  3.5799],\n",
            "        [-4.3570, -3.5302,  3.6886],\n",
            "        [-4.7609, -4.0834,  3.4765],\n",
            "        [ 4.1516, -3.4829, -4.0164],\n",
            "        [ 1.4392, -1.6126, -2.1167],\n",
            "        [-4.3828, -3.8256,  4.4076],\n",
            "        [ 3.6459, -3.4954, -3.4760],\n",
            "        [ 0.8050, -1.0574, -3.2197],\n",
            "        [-4.5588, -4.7196,  4.0173],\n",
            "        [-4.5314, -3.6336,  4.3782],\n",
            "        [ 3.0662, -3.2234, -3.5864],\n",
            "        [ 3.2777, -3.1658, -3.6387]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.5304, -3.9544,  4.1965],\n",
            "        [-4.4564, -3.9118,  4.2716],\n",
            "        [-4.0484, -3.3135,  4.4416],\n",
            "        [ 3.6151, -3.7572, -3.6539],\n",
            "        [-4.9460, -3.7614,  4.3550],\n",
            "        [-4.5647, -3.8965,  4.5227],\n",
            "        [-1.3471,  0.6503, -2.4706],\n",
            "        [-4.2929, -4.1280,  3.9427],\n",
            "        [ 2.7132, -2.3348, -4.0488],\n",
            "        [-3.6348, -3.6104,  3.5403],\n",
            "        [-4.0163, -3.9322,  4.1707],\n",
            "        [-4.9004, -3.7405,  4.2882],\n",
            "        [ 3.2828, -3.0833, -3.8637],\n",
            "        [ 3.1649, -3.1169, -3.5456],\n",
            "        [-3.8779, -3.7400,  3.7275],\n",
            "        [-2.6005,  2.5186, -3.1004]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.3762, -3.1836, -3.1930],\n",
            "        [-4.4321, -4.3507,  4.4110],\n",
            "        [ 3.1046, -3.2917, -4.1931],\n",
            "        [ 3.1193, -2.8965, -4.7029],\n",
            "        [-2.2100,  2.9131, -3.2236],\n",
            "        [-4.5729, -3.6346,  3.5232],\n",
            "        [-4.1633, -4.3319,  3.8911],\n",
            "        [-4.7401, -4.1199,  4.3677],\n",
            "        [-2.9347,  3.3276, -2.4958],\n",
            "        [ 3.2419, -3.8632, -3.6405],\n",
            "        [-4.1767, -4.7170,  3.9825],\n",
            "        [-3.7020, -3.6264,  3.7302],\n",
            "        [-4.6212, -4.5755,  4.3458],\n",
            "        [ 3.5962, -3.6754, -3.4055],\n",
            "        [-4.2960, -4.2482,  4.5463],\n",
            "        [-4.6198, -4.4936,  3.7408]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.4954, -1.4962,  1.8203],\n",
            "        [-4.6453, -3.9346,  3.6047],\n",
            "        [ 2.9629, -3.1140, -3.8186],\n",
            "        [-4.4793, -5.1640,  4.6699],\n",
            "        [-5.1653, -3.8898,  4.2244],\n",
            "        [-4.3652, -4.0018,  4.6432],\n",
            "        [-4.3100, -3.9692,  4.3556],\n",
            "        [-0.8305, -0.4328, -1.7451],\n",
            "        [ 3.4066, -3.6796, -3.3781],\n",
            "        [ 2.8050, -2.5691, -3.3643],\n",
            "        [-4.6097, -4.2151,  4.5099],\n",
            "        [-2.8182,  2.1566, -2.8026],\n",
            "        [-1.3021,  1.1172, -3.3993],\n",
            "        [-5.0692, -4.6488,  4.4724],\n",
            "        [-4.6664, -3.6415,  4.1625],\n",
            "        [-4.5489, -4.2539,  4.2698]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.9380, -3.6415,  3.2070],\n",
            "        [-4.3444, -4.2969,  4.6922],\n",
            "        [-3.9422, -4.1781,  3.3838],\n",
            "        [-3.7165, -4.0846,  4.5454],\n",
            "        [-4.5397, -3.6873,  4.8660],\n",
            "        [-3.9132, -3.6962,  4.1807],\n",
            "        [-4.2313, -3.5890,  4.1122],\n",
            "        [-4.6732, -4.0632,  3.8038],\n",
            "        [-4.2406, -3.7407,  3.8259],\n",
            "        [-2.1159,  2.1282, -3.3357],\n",
            "        [ 3.2189, -3.3350, -3.9467],\n",
            "        [-4.2345, -4.7166,  4.3328],\n",
            "        [ 3.6896, -3.6079, -3.4896],\n",
            "        [-4.3811, -4.0667,  3.9953],\n",
            "        [-2.9134,  2.8090, -2.4776],\n",
            "        [-4.5834, -3.5503,  3.7566]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.8459, -4.5456,  4.6319],\n",
            "        [-3.2222, -0.3585, -0.3493],\n",
            "        [-4.2120, -4.1871,  4.5102],\n",
            "        [-4.7804, -4.1385,  4.0912],\n",
            "        [ 3.4842, -3.5412, -3.6071],\n",
            "        [-4.1893, -4.5909,  4.3060],\n",
            "        [-4.7810, -4.8216,  4.5806],\n",
            "        [-4.4125, -3.6699,  4.7001],\n",
            "        [-4.1597, -4.7684,  4.2748],\n",
            "        [-4.1380, -4.2607,  3.7504],\n",
            "        [-4.3078, -4.6047,  4.5563],\n",
            "        [ 3.4451, -3.7638, -3.2217],\n",
            "        [-3.9649,  2.7232, -2.7681],\n",
            "        [-4.7311, -4.6723,  4.3345],\n",
            "        [-4.2407, -3.6577,  4.2492],\n",
            "        [ 3.2873, -4.0120, -3.1766]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.5009, -3.8124,  3.8282],\n",
            "        [-4.8998, -4.4990,  4.8803],\n",
            "        [-4.5945, -4.1837,  4.4703],\n",
            "        [ 3.1249, -3.8969, -3.3637],\n",
            "        [ 2.8713, -2.4019, -3.9481],\n",
            "        [-4.0539, -3.9814,  3.8175],\n",
            "        [-4.4345, -4.4308,  4.2071],\n",
            "        [-4.0994, -4.5061,  3.5350],\n",
            "        [-4.6434, -4.4095,  3.1926],\n",
            "        [-5.4177,  0.6978,  0.3543],\n",
            "        [ 3.6029, -3.5820, -3.9665],\n",
            "        [-2.7234,  2.8617, -3.2556],\n",
            "        [ 3.0850, -3.1884, -3.2945],\n",
            "        [-5.1215, -3.8546,  3.6158],\n",
            "        [-4.5858, -3.1778,  3.5359],\n",
            "        [-4.0109, -4.8142,  4.5637]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.4917, -1.5052,  0.7179],\n",
            "        [-1.6562,  0.8369, -2.8980],\n",
            "        [-4.1907, -4.2993,  4.3370],\n",
            "        [-3.6214, -3.5338,  3.3328],\n",
            "        [-3.3485,  2.9923, -3.4774],\n",
            "        [-4.9187, -1.0037,  1.6861],\n",
            "        [ 3.6408, -2.9612, -3.5942],\n",
            "        [-2.5206,  2.0991, -1.4044],\n",
            "        [-4.4959, -3.9458,  3.9254],\n",
            "        [-4.7774, -4.2169,  3.9148],\n",
            "        [-3.1139,  2.6744, -2.5680],\n",
            "        [-4.7656, -3.5278,  4.1377],\n",
            "        [-4.7039, -4.6545,  4.8998],\n",
            "        [-4.9414, -4.4889,  4.0778],\n",
            "        [-3.4956, -0.9054,  0.9586],\n",
            "        [-4.4095, -3.0946,  3.3809]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.7332,  3.8259, -3.2160],\n",
            "        [ 2.9059, -3.8478, -2.1514],\n",
            "        [ 3.7123, -3.8517, -3.6331],\n",
            "        [-4.8360, -4.2238,  4.3980],\n",
            "        [ 3.6464, -3.1068, -3.6935],\n",
            "        [-4.1412, -3.9627,  4.5121],\n",
            "        [-4.7668, -4.1696,  4.5493],\n",
            "        [ 3.1194, -2.4855, -3.9984],\n",
            "        [ 3.1839, -2.8283, -3.6662],\n",
            "        [-4.9383, -4.6462,  4.3667],\n",
            "        [ 2.4875, -3.1938, -2.7169],\n",
            "        [-4.1251, -4.6386,  3.9426],\n",
            "        [-4.3743, -4.3084,  4.6194],\n",
            "        [-4.3252, -4.2773,  4.5916],\n",
            "        [-3.9316, -4.2238,  4.2323],\n",
            "        [-2.7329,  2.7547, -3.0101]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.9628, -2.8344, -3.1881],\n",
            "        [-4.2611, -4.1468,  4.1556],\n",
            "        [-3.9358, -4.3783,  4.4997],\n",
            "        [-4.8880, -4.8244,  4.9940],\n",
            "        [-2.8144,  2.7247, -2.9001],\n",
            "        [-4.0104, -4.0966,  4.1769],\n",
            "        [ 2.6559, -3.0439, -3.2010],\n",
            "        [ 3.5692, -3.2500, -3.3802],\n",
            "        [-3.9649, -3.7295,  3.9612],\n",
            "        [-4.4495, -4.8314,  4.4979],\n",
            "        [-2.1409,  0.8775, -1.2414],\n",
            "        [-4.8980, -4.0560,  3.9428],\n",
            "        [-3.8404, -4.6110,  4.2928],\n",
            "        [-4.5993, -4.2556,  4.2013],\n",
            "        [-2.3686,  1.5504, -2.4478],\n",
            "        [-3.6564,  3.6590, -2.8552]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.8919, -3.5961, -3.2466],\n",
            "        [-2.9328,  3.4688, -3.1553],\n",
            "        [-3.0454,  3.1999, -3.6496],\n",
            "        [-4.3151, -3.7798,  4.0426],\n",
            "        [-0.3120, -2.4246, -0.1132],\n",
            "        [-4.5748, -3.6112,  4.2120],\n",
            "        [-2.0423,  2.9466, -3.0556],\n",
            "        [ 2.4264, -1.9724, -3.0424],\n",
            "        [-4.0476, -3.8539,  4.4593],\n",
            "        [-4.8767, -0.6120,  0.5270],\n",
            "        [ 1.7998, -1.7840, -4.1463],\n",
            "        [ 2.7065, -2.6310, -3.7992],\n",
            "        [-4.6017, -4.6134,  4.1109],\n",
            "        [-2.0075,  1.3600, -3.3268],\n",
            "        [-4.1291, -4.3940,  4.2675],\n",
            "        [ 4.2221, -3.5570, -3.7974]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.4993,  3.5935, -3.3901],\n",
            "        [-2.8401,  2.4072, -2.6398],\n",
            "        [ 2.7922, -2.5333, -3.7193],\n",
            "        [ 2.9684, -3.7743, -3.5835],\n",
            "        [-1.0388, -0.0492, -1.7232],\n",
            "        [-4.5124, -3.7776,  3.9339],\n",
            "        [-0.9353,  1.2116, -3.5668],\n",
            "        [-5.2111, -4.2637,  4.5644],\n",
            "        [-4.3946, -3.2681,  3.2697],\n",
            "        [-5.3987, -4.1415,  4.2335],\n",
            "        [ 3.3866, -3.0508, -3.5223],\n",
            "        [-4.4007, -3.8422,  3.8439],\n",
            "        [-4.0990, -4.2119,  4.3424],\n",
            "        [-1.6558,  0.0541, -1.2370],\n",
            "        [ 0.3719, -0.6051, -2.9425],\n",
            "        [ 3.5759, -3.6466, -3.7248]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.5047,  3.2309, -3.6456],\n",
            "        [ 3.6495, -3.4793, -3.7096],\n",
            "        [-4.3642, -4.2775,  4.2133],\n",
            "        [ 3.8006, -3.1359, -4.0870],\n",
            "        [-4.7390, -4.4578,  4.5770],\n",
            "        [-4.4065, -4.1015,  4.1608],\n",
            "        [-4.3093, -4.1740,  3.5873],\n",
            "        [-5.2835, -3.6697,  4.8614],\n",
            "        [-4.8232, -3.8727,  4.3239],\n",
            "        [-4.7043, -4.0413,  4.1138],\n",
            "        [-4.2613, -3.9369,  3.6257],\n",
            "        [ 1.1868, -1.3382, -3.1002],\n",
            "        [ 0.2698, -0.1837, -3.9800],\n",
            "        [-4.0365, -4.3675,  4.5252],\n",
            "        [-4.6316, -4.3317,  4.0861],\n",
            "        [-3.8177, -4.5283,  3.8316]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.1985, -3.0810,  3.7826],\n",
            "        [-5.6894, -3.2522,  3.2629],\n",
            "        [-3.3970,  2.7706, -2.6680],\n",
            "        [-4.2401,  2.1483, -2.1503],\n",
            "        [ 3.0907, -2.7143, -3.6773],\n",
            "        [-3.9705,  1.3422, -0.8284],\n",
            "        [-4.1101, -3.9775,  4.6383],\n",
            "        [-3.4044,  3.1544, -3.2071],\n",
            "        [-3.6904,  1.8904, -1.1462],\n",
            "        [ 0.4042, -0.7209, -2.3558],\n",
            "        [-3.9782, -2.9923,  3.2109],\n",
            "        [-2.1948,  2.5604, -3.5557],\n",
            "        [-3.9988, -4.3058,  4.3749],\n",
            "        [-4.0465, -4.7198,  4.6318],\n",
            "        [-4.6047, -3.8844,  3.9122],\n",
            "        [-3.8006, -4.2704,  3.7151]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3206, -2.1762, -3.0684],\n",
            "        [-4.7828, -4.1323,  4.5994],\n",
            "        [ 3.3255, -3.0972, -3.7184],\n",
            "        [-5.0191, -3.2598,  4.0994],\n",
            "        [ 3.7820, -3.4587, -3.5401],\n",
            "        [-4.6109, -4.4563,  4.0501],\n",
            "        [-4.7122, -4.2324,  3.9402],\n",
            "        [-4.8289, -1.5406,  2.0615],\n",
            "        [-2.4960,  3.3813, -3.5479],\n",
            "        [ 3.9405, -3.5176, -3.8488],\n",
            "        [ 1.3811, -1.6550, -4.1442],\n",
            "        [ 3.5435, -3.4223, -3.3730],\n",
            "        [-4.7006, -4.1358,  4.2987],\n",
            "        [ 3.5186, -3.5297, -3.3143],\n",
            "        [-4.2029, -4.2277,  3.9196],\n",
            "        [-3.0413,  4.1039, -3.0757]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.1840, -3.7976,  4.5526],\n",
            "        [-4.2334, -3.9017,  3.5944],\n",
            "        [ 3.4869, -3.1129, -3.7394],\n",
            "        [ 2.1987, -2.8355, -4.1793],\n",
            "        [-4.6004, -3.4388,  3.7816],\n",
            "        [ 3.5233, -3.8366, -3.1956],\n",
            "        [-4.3064, -3.8788,  4.3864],\n",
            "        [-4.4571, -4.5828,  4.6032],\n",
            "        [-4.1534, -3.1153,  2.2496],\n",
            "        [ 3.1800, -2.8647, -3.6506],\n",
            "        [-3.8918, -3.2548,  3.0929],\n",
            "        [ 2.9607, -3.1324, -3.4267],\n",
            "        [-2.3303, -4.5029,  2.6931],\n",
            "        [-4.4356, -4.9093,  4.1876],\n",
            "        [-4.4101, -3.6776,  3.6510],\n",
            "        [ 2.0780, -1.5815, -3.4898]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.6666, -2.9278, -4.0069],\n",
            "        [-4.2258, -4.1153,  4.3668],\n",
            "        [-3.5876,  2.5862, -2.6809],\n",
            "        [-3.1234,  1.9296, -2.6512],\n",
            "        [-4.9972, -4.4299,  4.7430],\n",
            "        [ 3.9940, -3.6245, -3.3165],\n",
            "        [-4.6064, -4.8307,  4.3866],\n",
            "        [ 3.7567, -3.2331, -3.5995],\n",
            "        [-1.7996, -0.5009, -0.5324],\n",
            "        [-2.8981,  3.3011, -3.1670],\n",
            "        [-2.2734,  2.0209, -2.0707],\n",
            "        [-5.1434, -3.5984,  3.7598],\n",
            "        [-4.3960, -3.3837,  3.7201],\n",
            "        [ 3.9941, -2.9377, -4.2324],\n",
            "        [-4.1758, -3.9673,  3.9325],\n",
            "        [-3.0154,  2.0163, -1.9146]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.4295, -2.3689, -3.2598],\n",
            "        [-2.3791,  3.0528, -3.0959],\n",
            "        [-4.7456, -3.6283,  4.5281],\n",
            "        [-4.7907, -3.3777,  3.9323],\n",
            "        [-4.2718, -4.0445,  3.8723],\n",
            "        [-4.5251, -3.4350,  4.1577],\n",
            "        [-4.2201, -4.4488,  3.7504],\n",
            "        [ 3.3193, -3.1776, -3.9076],\n",
            "        [-4.7280, -4.3247,  4.3932],\n",
            "        [ 3.6308, -3.4446, -3.2904],\n",
            "        [-3.1058,  0.9679, -1.4939],\n",
            "        [ 3.8607, -3.5930, -3.8979],\n",
            "        [ 3.2843, -3.7882, -3.6489],\n",
            "        [-3.8333, -4.3625,  4.2667],\n",
            "        [-1.1628, -0.2566, -2.8265],\n",
            "        [-4.6478, -4.3097,  4.5082]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.5874,  0.0302, -0.0052],\n",
            "        [ 3.5541, -3.5853, -3.7769],\n",
            "        [ 3.3059, -3.4375, -3.6273],\n",
            "        [-4.5939, -4.7202,  4.2921],\n",
            "        [-1.3939,  0.1307, -1.0172],\n",
            "        [-4.2345, -3.1016,  2.6950],\n",
            "        [ 3.6756, -3.5481, -3.6330],\n",
            "        [-4.7479, -4.3321,  3.9648],\n",
            "        [-4.4765, -4.2988,  4.5275],\n",
            "        [-4.8688, -0.1320,  0.4471],\n",
            "        [-4.2724, -3.0037,  4.1375],\n",
            "        [-2.5531,  2.7846, -2.6412],\n",
            "        [-5.0612, -4.0967,  4.7367],\n",
            "        [-4.8891, -2.6153,  3.8863],\n",
            "        [-4.2434, -3.9109,  3.7191],\n",
            "        [-4.2073, -1.0160,  1.0568]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.5778,  2.4385, -2.5811],\n",
            "        [-4.3467, -1.4304,  1.3592],\n",
            "        [-4.7170, -3.7154,  3.9351],\n",
            "        [-4.1310, -3.5528,  4.3046],\n",
            "        [-4.7603, -3.4700,  3.9051],\n",
            "        [-0.8595,  0.4717, -3.4522],\n",
            "        [-2.4279,  2.9290, -3.3634],\n",
            "        [-4.0268, -3.5928,  3.7458],\n",
            "        [ 3.5237, -2.9052, -3.9880],\n",
            "        [ 3.1479, -3.4931, -3.9380],\n",
            "        [ 3.7246, -3.8785, -3.7991],\n",
            "        [-4.3968, -4.3464,  4.4378],\n",
            "        [-4.6195, -2.8773,  3.0385],\n",
            "        [-4.3530, -3.7712,  4.3448],\n",
            "        [-4.4112, -4.4249,  3.9394],\n",
            "        [-4.8767, -0.2071,  0.8170]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.9828, -3.4286, -3.4833],\n",
            "        [-4.1711, -0.7448,  1.0905],\n",
            "        [ 2.8871, -2.2515, -3.8701],\n",
            "        [-4.4042, -4.6903,  4.1985],\n",
            "        [ 2.8363, -3.1283, -3.7935],\n",
            "        [-4.0216,  1.2845, -1.6433],\n",
            "        [ 0.5237, -0.2396, -3.5561],\n",
            "        [-3.7318, -2.9804,  2.0334],\n",
            "        [ 2.9161, -3.5699, -3.1687],\n",
            "        [-3.4918, -3.1412,  2.4128],\n",
            "        [-5.1798, -4.3650,  4.7058],\n",
            "        [-4.3871, -3.7967,  4.3051],\n",
            "        [-2.3023,  1.9946, -4.0440],\n",
            "        [-5.5979, -4.3355,  4.1169],\n",
            "        [-3.4510,  1.9946, -2.4859],\n",
            "        [-4.5058, -4.2339,  3.8613]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.5844, -4.5838,  4.4886],\n",
            "        [-3.9576, -0.3388,  0.7568],\n",
            "        [-4.9206, -3.1077,  3.2097],\n",
            "        [-4.0366, -0.0812,  0.3524],\n",
            "        [-4.5450, -4.3615,  4.4276],\n",
            "        [-5.3137, -4.1507,  3.6379],\n",
            "        [-4.2686, -3.6872,  3.9463],\n",
            "        [-2.9669,  2.0999, -2.2482],\n",
            "        [-4.0462, -3.3984,  2.8434],\n",
            "        [-4.4198, -2.9715,  3.5231],\n",
            "        [-4.1444,  0.8566, -0.6127],\n",
            "        [ 2.7271, -3.5097, -3.6740],\n",
            "        [-3.0813,  2.8414, -2.9208],\n",
            "        [-3.0739,  3.6277, -3.3973],\n",
            "        [ 2.0779, -1.8464, -3.3264],\n",
            "        [-4.2365, -4.6180,  4.0005]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.1922, -3.3765, -3.7959],\n",
            "        [-4.6250, -3.8920,  4.2806],\n",
            "        [-4.3355, -3.6553,  3.5596],\n",
            "        [-4.4633, -4.1017,  4.2663],\n",
            "        [ 2.7935, -2.6274, -3.5548],\n",
            "        [-4.5584, -4.0723,  3.9889],\n",
            "        [-3.6363, -2.6266,  3.3927],\n",
            "        [-4.3647, -3.9448,  3.6519],\n",
            "        [-2.4314, -3.8534,  2.2940],\n",
            "        [-4.8768, -3.5893,  4.1238],\n",
            "        [-3.8243, -3.8608,  3.9191],\n",
            "        [-3.0479,  1.4926, -2.5762],\n",
            "        [-4.4398, -3.8816,  3.9676],\n",
            "        [-0.9077,  0.8711, -3.8482],\n",
            "        [ 3.8461, -3.4795, -3.5849],\n",
            "        [-3.7207, -3.8290,  3.4227]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.3579, -4.2064,  4.2236],\n",
            "        [-4.2085, -4.5959,  3.9966],\n",
            "        [-4.8261, -3.9212,  4.2712],\n",
            "        [ 3.6118, -3.0461, -3.7725],\n",
            "        [-5.0974, -4.1560,  3.8620],\n",
            "        [-2.3911,  1.7127, -2.6863],\n",
            "        [-4.3705, -3.9783,  4.0582],\n",
            "        [-3.5939, -4.6882,  4.6018],\n",
            "        [-2.6812,  2.5514, -2.9059],\n",
            "        [-4.0624, -4.3228,  4.1396],\n",
            "        [-2.8466, -3.8518,  2.1217],\n",
            "        [-3.3421,  3.5558, -3.0308],\n",
            "        [-4.6194, -4.0252,  3.7929],\n",
            "        [ 3.5220, -2.5376, -3.1830],\n",
            "        [-2.9439,  1.7475, -1.7418],\n",
            "        [-4.8840, -4.3692,  4.6141]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.8439, -3.5337,  3.7431],\n",
            "        [-4.2625, -3.7146,  4.2669],\n",
            "        [-4.0888, -3.9263,  3.6947],\n",
            "        [-4.3704, -3.2490,  3.3005],\n",
            "        [-4.5731, -4.4123,  4.1421],\n",
            "        [ 3.6325, -3.7032, -3.0457],\n",
            "        [-3.8158, -3.5567,  4.3758],\n",
            "        [-4.1504, -4.2608,  4.1715],\n",
            "        [ 3.4346, -3.1274, -3.2360],\n",
            "        [ 3.2267, -2.9741, -3.5255],\n",
            "        [-4.4264, -3.8303,  4.3824],\n",
            "        [-2.9996,  1.2622, -1.4772],\n",
            "        [ 2.5627, -2.6705, -3.6417],\n",
            "        [-4.5402, -3.9947,  4.4385],\n",
            "        [-3.5433,  1.3826, -1.1115],\n",
            "        [ 3.1305, -3.5058, -3.9500]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.4561, -4.2168,  3.9691],\n",
            "        [-4.6810, -4.4353,  4.3205],\n",
            "        [-4.5889, -3.9541,  4.1645],\n",
            "        [-4.4564, -4.3176,  4.2623],\n",
            "        [-4.8128, -4.0926,  4.6190],\n",
            "        [ 3.8893, -3.3640, -3.4881],\n",
            "        [ 3.6296, -3.8938, -3.3687],\n",
            "        [-4.3614, -3.9309,  3.9298],\n",
            "        [-4.6079, -4.5675,  4.0792],\n",
            "        [ 3.3833, -3.9004, -3.7057],\n",
            "        [ 3.2798, -3.3757, -3.8033],\n",
            "        [-4.3296, -3.9298,  4.2187],\n",
            "        [ 3.0735, -3.7325, -3.5541],\n",
            "        [-4.6887, -4.2683,  4.5257],\n",
            "        [-4.8250, -4.1690,  3.9687],\n",
            "        [-5.1640, -4.1874,  3.9430]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.7052, -3.4769, -3.6047],\n",
            "        [-4.5529, -3.6811,  4.4415],\n",
            "        [ 3.5097, -3.8528, -3.4290],\n",
            "        [ 4.0256, -3.9998, -3.3954],\n",
            "        [ 4.0860, -3.7912, -3.8071],\n",
            "        [ 2.7846, -2.7869, -3.3289],\n",
            "        [-4.5049, -4.1632,  4.2062],\n",
            "        [-4.8221, -4.1522,  4.8884],\n",
            "        [-4.6367, -4.2825,  4.4412],\n",
            "        [-4.1000, -4.0150,  4.8281],\n",
            "        [ 3.6734, -3.3781, -3.4034],\n",
            "        [-4.6609, -4.2694,  3.9980],\n",
            "        [-2.0965,  0.7727, -1.3409],\n",
            "        [-4.3643, -4.6544,  4.5002],\n",
            "        [-5.0812, -3.8827,  4.3541],\n",
            "        [-4.8788, -4.5852,  4.3262]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.5667, -4.1533, -3.1767],\n",
            "        [-4.3989, -4.1464,  3.9328],\n",
            "        [-4.6810, -4.4285,  4.3817],\n",
            "        [-3.1461,  1.6561, -2.0001],\n",
            "        [-4.7436, -3.5442,  4.1893],\n",
            "        [-4.5989, -4.1214,  4.1277],\n",
            "        [ 3.1208, -3.1504, -3.9265],\n",
            "        [-3.2989,  2.0751, -2.7042],\n",
            "        [ 2.5100, -2.2090, -2.7084],\n",
            "        [-2.0102,  1.1021, -3.2725],\n",
            "        [-4.3809, -4.2030,  4.0946],\n",
            "        [ 1.9923, -1.9232, -3.9950],\n",
            "        [-4.1170, -4.5297,  4.7873],\n",
            "        [ 3.0303, -3.3345, -3.7253],\n",
            "        [ 2.7237, -2.4171, -3.7866],\n",
            "        [-0.5203,  0.6520, -3.6638]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.4381, -4.1919,  4.4377],\n",
            "        [ 4.1095, -3.9892, -4.2948],\n",
            "        [-3.4396,  1.5747, -1.5796],\n",
            "        [-4.6617, -3.8244,  4.7044],\n",
            "        [ 3.5639, -3.5820, -3.1281],\n",
            "        [-3.7585,  2.1662, -2.3307],\n",
            "        [ 3.4146, -3.3749, -3.4880],\n",
            "        [ 3.5840, -4.1619, -3.3547],\n",
            "        [ 3.6367, -4.0260, -3.4312],\n",
            "        [ 1.3940, -1.6059, -2.9360],\n",
            "        [-4.8118, -4.0806,  4.6291],\n",
            "        [-4.5241, -4.1106,  4.8866],\n",
            "        [-3.8914, -1.6914,  0.7782],\n",
            "        [-2.8491,  2.4953, -3.2571],\n",
            "        [-3.8050, -3.5659,  3.7752],\n",
            "        [-4.3871, -4.4696,  4.2573]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.1757, -3.2364, -3.4280],\n",
            "        [-3.6593, -3.7285,  4.4721],\n",
            "        [ 3.2872, -3.9080, -3.9321],\n",
            "        [-3.7362, -4.2157,  4.1921],\n",
            "        [ 2.6103, -3.9850, -3.3295],\n",
            "        [-4.7998, -4.0539,  4.2805],\n",
            "        [-3.4932, -4.1488,  3.4448],\n",
            "        [-3.5165, -3.8852,  4.3839],\n",
            "        [-4.4911, -4.4201,  5.2370],\n",
            "        [-4.6503, -4.2885,  4.3069],\n",
            "        [ 2.9641, -3.1810, -3.3270],\n",
            "        [-4.2924, -4.0880,  3.9362],\n",
            "        [-4.2325, -4.6130,  4.3405],\n",
            "        [-4.6472, -4.4049,  3.7856],\n",
            "        [-4.1019, -3.7565,  3.6420],\n",
            "        [-5.0159, -4.2187,  4.1851]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.1351, -4.5858,  4.0117],\n",
            "        [-4.5812, -3.9557,  3.8336],\n",
            "        [ 2.1592, -2.7501, -2.6099],\n",
            "        [-4.1616, -0.0584,  0.5991],\n",
            "        [-4.1085, -3.8177,  4.1678],\n",
            "        [-4.2844,  2.1939, -2.5250],\n",
            "        [-4.8086, -4.3281,  3.9384],\n",
            "        [-4.7736, -4.2932,  4.1751],\n",
            "        [-1.2901, -0.3339, -1.4673],\n",
            "        [-4.4843, -4.4547,  4.4960],\n",
            "        [-4.1887,  0.4956, -0.6890],\n",
            "        [-3.7976, -4.1285,  4.0465],\n",
            "        [-4.4079, -3.8788,  3.8644],\n",
            "        [-4.6649, -3.7582,  4.3915],\n",
            "        [-5.2090, -3.8908,  4.8747],\n",
            "        [-4.9884, -4.9703,  4.1808]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.3974, -4.6228,  3.7940],\n",
            "        [-3.2478, -0.5119,  0.5669],\n",
            "        [-4.4747, -4.4349,  4.2121],\n",
            "        [-4.9261,  0.3902, -0.4055],\n",
            "        [-5.0334, -4.0421,  4.3134],\n",
            "        [ 1.4164, -1.8659, -3.0140],\n",
            "        [-4.8667, -3.9759,  4.3095],\n",
            "        [ 2.0418, -1.9828, -4.3166],\n",
            "        [-1.8553,  1.9409, -2.6702],\n",
            "        [-4.1495, -4.4516,  4.2894],\n",
            "        [-4.6926, -3.9875,  4.2804],\n",
            "        [-3.4685,  1.6744, -1.8407],\n",
            "        [-3.1279,  0.6372, -0.3534],\n",
            "        [-4.2970, -4.1422,  4.3063],\n",
            "        [-0.9627,  0.6405, -3.1560],\n",
            "        [-2.4956, -1.3497,  0.9118]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.4344, -3.8755,  4.4304],\n",
            "        [-4.5718, -4.1272,  4.6015],\n",
            "        [-4.5340, -4.7491,  4.2945],\n",
            "        [-0.8358, -0.0766, -2.0147],\n",
            "        [-4.4106, -4.8620,  4.6062],\n",
            "        [-3.6037,  3.0704, -2.4334],\n",
            "        [-4.7394, -4.5381,  4.4331],\n",
            "        [-5.0635, -3.7191,  3.7014],\n",
            "        [-4.8932, -4.0665,  4.3786],\n",
            "        [-2.8397,  1.6375, -2.3396],\n",
            "        [-4.1256, -4.5822,  4.4044],\n",
            "        [-2.2311,  2.5815, -3.7598],\n",
            "        [-4.4712, -3.9095,  4.0066],\n",
            "        [ 3.7983, -3.4493, -3.2687],\n",
            "        [-5.1205,  0.7145, -0.3504],\n",
            "        [-4.4986, -4.0356,  4.4198]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.6374, -1.7102,  0.3100],\n",
            "        [ 2.8187, -3.0100, -3.7795],\n",
            "        [-4.3361, -4.1839,  3.7315],\n",
            "        [-1.0622,  0.1036, -1.7498],\n",
            "        [-2.4939,  2.4957, -2.5750],\n",
            "        [-4.8321, -4.2709,  4.3030],\n",
            "        [-4.3658, -4.0351,  4.0733],\n",
            "        [-0.5344,  0.2337, -2.7330],\n",
            "        [-2.8671,  1.3321, -2.1194],\n",
            "        [-4.4769, -4.4797,  3.8595],\n",
            "        [ 3.2824, -3.8355, -3.3633],\n",
            "        [-4.5725, -3.6199,  4.1066],\n",
            "        [-4.1418, -4.0771,  4.1794],\n",
            "        [-4.4274, -3.8050,  4.1056],\n",
            "        [-5.2984, -4.2299,  4.5854],\n",
            "        [ 3.8897, -3.9458, -3.3768]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.2645,  3.1865, -3.6639],\n",
            "        [-4.5576, -4.0973,  3.9331],\n",
            "        [-4.6523, -4.4497,  4.1576],\n",
            "        [-3.5170,  3.1024, -3.1156],\n",
            "        [-4.0152, -4.0126,  4.2375],\n",
            "        [ 2.3734, -2.1643, -3.9080],\n",
            "        [ 3.6761, -3.3093, -3.6563],\n",
            "        [-4.5175, -3.8586,  4.2572],\n",
            "        [ 3.4082, -2.8772, -3.6986],\n",
            "        [-1.4901,  1.1696, -3.1233],\n",
            "        [-4.9195, -4.1724,  4.3792],\n",
            "        [-4.6356, -3.9824,  3.2276],\n",
            "        [-3.5688,  2.5354, -1.9647],\n",
            "        [-4.4923, -3.9500,  4.1642],\n",
            "        [-4.4049, -2.9602,  2.7956],\n",
            "        [-4.2832, -4.3786,  3.8914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.6186, -4.5770,  4.1962],\n",
            "        [-4.4384, -4.4503,  4.1504],\n",
            "        [-3.0593,  0.6425, -0.3842],\n",
            "        [-3.7342,  2.3644, -2.9111],\n",
            "        [-3.8177,  1.2528, -0.3891],\n",
            "        [-4.5019, -4.2930,  3.5507],\n",
            "        [-4.4535, -3.7678,  3.5682],\n",
            "        [-5.0876, -3.9036,  3.8053],\n",
            "        [ 1.6046, -1.9573, -3.3127],\n",
            "        [-3.1907,  3.5184, -2.9382],\n",
            "        [-4.9441, -3.8836,  4.5168],\n",
            "        [ 4.1984, -3.2341, -3.9802],\n",
            "        [ 3.3080, -2.9516, -3.5908],\n",
            "        [ 2.0019, -2.2116, -3.7225],\n",
            "        [-3.5648, -4.3299,  3.6215],\n",
            "        [-4.1656, -4.0516,  4.2147]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.3730, -3.6025,  4.3967],\n",
            "        [ 2.2075, -2.2289, -3.9108],\n",
            "        [-3.2274,  2.5957, -1.8760],\n",
            "        [-4.8978, -4.1924,  3.9347],\n",
            "        [-4.5461, -3.6269,  4.3177],\n",
            "        [-4.3449, -1.7133,  1.5367],\n",
            "        [-4.7489, -4.3349,  4.5474],\n",
            "        [-4.9271, -4.5239,  4.2127],\n",
            "        [ 2.1058, -2.3568, -3.9289],\n",
            "        [-4.7876, -3.8914,  4.0495],\n",
            "        [-1.8187,  1.5646, -3.7862],\n",
            "        [ 2.0041, -3.3827, -2.5761],\n",
            "        [ 3.5320, -3.9111, -3.2031],\n",
            "        [-4.8734, -3.8547,  3.7528],\n",
            "        [ 2.8136, -3.5934, -3.8131],\n",
            "        [-5.0388, -3.7926,  4.4224]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.8375, -3.1053,  4.1853],\n",
            "        [-4.9226, -3.9720,  4.0736],\n",
            "        [-2.2977,  1.6106, -2.1391],\n",
            "        [-4.7406, -4.4709,  4.1029],\n",
            "        [-4.3074, -3.4840,  3.8657],\n",
            "        [-4.2920, -4.2847,  3.8176],\n",
            "        [ 3.4642, -4.0967, -3.6784],\n",
            "        [-5.5064, -4.2019,  4.3835],\n",
            "        [-4.8518, -3.4925,  3.9468],\n",
            "        [ 2.7526, -3.1914, -4.3562],\n",
            "        [-4.5183, -3.9840,  4.6968],\n",
            "        [-5.1959, -4.3110,  4.0822],\n",
            "        [-0.6299,  1.0884, -4.1182],\n",
            "        [-4.0926, -2.7757,  2.2862],\n",
            "        [-5.0503, -4.2482,  4.3537],\n",
            "        [-5.1217, -3.6937,  4.0788]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2219, -2.1271, -3.1089],\n",
            "        [-1.4869,  0.6086, -3.0004],\n",
            "        [-4.7116, -3.7068,  3.5783],\n",
            "        [-4.4934, -3.6101,  3.9374],\n",
            "        [-4.8318, -3.2889,  3.8154],\n",
            "        [-4.6307, -4.1339,  4.4541],\n",
            "        [-4.6593, -3.8087,  4.2006],\n",
            "        [-3.1145,  0.8090, -0.7845],\n",
            "        [-4.6224, -3.8870,  4.2383],\n",
            "        [-4.3871, -4.2025,  4.1736],\n",
            "        [-5.1288, -1.9363,  2.5209],\n",
            "        [-4.4789, -4.1005,  4.5373],\n",
            "        [-4.1714,  2.6720, -1.5415],\n",
            "        [-5.1157, -3.9390,  4.3240],\n",
            "        [-4.7299, -3.9111,  4.2765],\n",
            "        [ 2.9623, -3.2113, -3.9944]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.2718, -3.1186, -4.0627],\n",
            "        [-4.8833, -2.4122,  2.8359],\n",
            "        [-4.6438, -4.2227,  3.8474],\n",
            "        [-4.5365, -4.6013,  4.3949],\n",
            "        [-4.8648, -2.5525,  2.4837],\n",
            "        [ 1.1904, -1.6915, -4.3883],\n",
            "        [-4.7808, -3.9667,  4.6668],\n",
            "        [ 3.1864, -3.6869, -3.6828],\n",
            "        [ 2.1215, -2.0923, -3.7883],\n",
            "        [-4.4726, -2.2839,  2.9282],\n",
            "        [-5.1055, -3.8014,  4.0073],\n",
            "        [-4.3645, -4.2208,  3.9812],\n",
            "        [ 2.2039, -1.8958, -4.3636],\n",
            "        [-3.4526, -2.3600,  2.3172],\n",
            "        [ 3.3467, -3.1102, -3.9364],\n",
            "        [-4.5135, -3.4125,  3.7638]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.5316,  3.3127, -2.8825],\n",
            "        [-4.7136, -3.6762,  4.6081],\n",
            "        [-3.8060, -3.1346,  3.4680],\n",
            "        [-4.8636, -3.8739,  4.6702],\n",
            "        [-5.1116, -3.6776,  3.7986],\n",
            "        [-2.5754,  1.2840, -2.0764],\n",
            "        [-4.9792, -4.2943,  3.9331],\n",
            "        [-2.2152, -1.2973,  0.0261],\n",
            "        [-4.5159, -3.6306,  4.0804],\n",
            "        [ 0.8727, -0.6639, -3.6381],\n",
            "        [ 1.0694, -1.5522, -2.7297],\n",
            "        [-0.6705, -0.2106, -4.4140],\n",
            "        [-3.3971, -4.2172,  3.0476],\n",
            "        [-3.7200,  2.9014, -2.7705],\n",
            "        [-4.7889, -2.6987,  2.6893],\n",
            "        [ 2.7925, -2.4116, -4.4992]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-5.2369, -4.1717,  4.7274],\n",
            "        [-4.8943, -4.0508,  3.7117],\n",
            "        [-2.1979,  2.4966, -3.2991],\n",
            "        [-4.5317, -3.9957,  4.0732],\n",
            "        [-0.4376, -0.1113, -4.5462],\n",
            "        [-1.9482,  1.2949, -3.0678],\n",
            "        [-4.5158, -4.4859,  4.4352],\n",
            "        [ 3.6219, -3.0730, -4.1806],\n",
            "        [-4.9739, -3.9967,  4.6831],\n",
            "        [-4.3134, -2.0167,  2.1871],\n",
            "        [-4.4577, -3.4834,  3.8828],\n",
            "        [-4.3388, -3.3030,  4.3774],\n",
            "        [-4.7344, -4.3492,  4.2592],\n",
            "        [-4.8420, -3.3959,  3.2699],\n",
            "        [-3.0113,  3.0664, -2.7109],\n",
            "        [ 2.7546, -2.8363, -4.2318]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.2025, -3.9939,  4.3883],\n",
            "        [-2.6887,  1.3698, -1.9330],\n",
            "        [-4.9074, -3.4119,  3.8592],\n",
            "        [-1.4406,  0.4315, -1.9534],\n",
            "        [-4.5741, -4.0747,  4.1785],\n",
            "        [-4.4932, -3.8518,  3.3822],\n",
            "        [-5.2563, -3.5396,  3.6744],\n",
            "        [-4.4554, -3.8315,  3.8774],\n",
            "        [-4.6865, -4.1147,  4.3292],\n",
            "        [-5.1429, -3.9378,  4.7976],\n",
            "        [-3.6349,  3.3605, -2.7163],\n",
            "        [-4.6994, -3.9722,  4.0152],\n",
            "        [-4.2157, -4.0228,  4.0817],\n",
            "        [ 2.7950, -2.9708, -3.4034],\n",
            "        [-5.2507, -3.4495,  3.7689],\n",
            "        [-1.4107,  1.0234, -2.8807]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.6386, -3.6655,  4.0850],\n",
            "        [-3.6309,  3.8425, -3.1556],\n",
            "        [-3.0210,  3.3233, -3.2258],\n",
            "        [-4.7834, -4.4478,  4.3464],\n",
            "        [-1.7050,  0.5269, -3.5176],\n",
            "        [ 3.2537, -3.9749, -3.2234],\n",
            "        [ 3.3161, -3.4679, -4.1500],\n",
            "        [-4.9065, -1.4426,  2.2193],\n",
            "        [-4.5387, -3.2228,  3.5283],\n",
            "        [-3.4203,  3.6678, -3.1864],\n",
            "        [ 1.8281, -2.3349, -4.0211],\n",
            "        [-4.8246, -4.3515,  4.1212],\n",
            "        [ 3.1940, -2.8388, -3.5233],\n",
            "        [ 2.8937, -3.3324, -3.1114],\n",
            "        [-4.4808, -4.0296,  4.5788],\n",
            "        [-2.6136,  3.1467, -3.1572]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.5476, -4.0032,  4.5941],\n",
            "        [-4.9434, -3.5608,  4.1163],\n",
            "        [-4.6167, -4.9294,  4.2350],\n",
            "        [-3.9247, -4.8080,  4.4904],\n",
            "        [-2.8686,  2.7943, -2.7423],\n",
            "        [-4.6733, -3.7780,  3.6369],\n",
            "        [-4.8654, -4.0239,  3.3809],\n",
            "        [-4.7684, -4.5568,  4.6324],\n",
            "        [-2.1113,  2.8725, -3.3687],\n",
            "        [-4.2979, -4.1686,  3.8874],\n",
            "        [ 3.1380, -3.5325, -3.9160],\n",
            "        [-4.2489, -4.0782,  4.6292],\n",
            "        [-4.8476, -4.3549,  4.4411],\n",
            "        [-3.2908,  2.1064, -2.8567],\n",
            "        [-4.4996, -3.4407,  3.3780],\n",
            "        [ 2.5400, -3.1292, -3.9318]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.6048, -4.2501,  4.6250],\n",
            "        [ 3.0789, -3.9601, -2.8446],\n",
            "        [-4.7210, -4.6074,  4.1759],\n",
            "        [ 2.4542, -2.0252, -4.4381],\n",
            "        [-2.7658,  2.9138, -2.3303],\n",
            "        [-4.4938, -3.5956,  3.7746],\n",
            "        [-4.6560,  0.1347,  0.6974],\n",
            "        [-5.2836, -3.8385,  3.6626],\n",
            "        [-4.2014, -4.0431,  3.9742],\n",
            "        [ 3.2046, -3.1385, -4.0563],\n",
            "        [ 1.9936, -2.0829, -4.0988],\n",
            "        [-4.1711, -3.8775,  3.8187],\n",
            "        [-4.6064, -3.6794,  2.9636],\n",
            "        [-4.3109,  2.3532, -1.4621],\n",
            "        [-4.6229, -4.0161,  4.0469],\n",
            "        [-4.3925, -3.9116,  3.4818]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.7309, -4.1872,  4.1544],\n",
            "        [-4.1637, -2.3232,  3.4053],\n",
            "        [-4.0590, -2.6718,  2.9443],\n",
            "        [-4.3036, -4.3163,  4.4610],\n",
            "        [-5.1430, -3.1447,  2.9108],\n",
            "        [-2.8756,  3.2481, -3.2184],\n",
            "        [-1.5626,  1.0551, -3.1086],\n",
            "        [-4.6100, -4.5378,  4.1980],\n",
            "        [-2.6831,  2.5318, -3.6190],\n",
            "        [ 0.1864, -0.1109, -3.7684],\n",
            "        [-3.6304, -3.6489,  2.5818],\n",
            "        [-3.1833,  3.0994, -3.6673],\n",
            "        [-4.4267, -4.4408,  4.4021],\n",
            "        [-4.9763, -2.4323,  2.3226],\n",
            "        [ 3.7766, -4.0497, -3.3511],\n",
            "        [-4.2438, -2.6075,  2.9924]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.8788, -3.7325,  4.2162],\n",
            "        [-1.7554,  1.7136, -4.2577],\n",
            "        [-4.2147, -3.5069,  3.8663],\n",
            "        [-4.0832, -3.5356,  3.5170],\n",
            "        [-4.8545, -3.8027,  4.2849],\n",
            "        [-4.4790, -3.4283,  4.4012],\n",
            "        [ 2.5143, -2.8245, -4.3292],\n",
            "        [-3.8640,  2.0511, -2.2321],\n",
            "        [-4.5746, -3.5185,  2.8544],\n",
            "        [-3.3181,  3.4377, -2.8209],\n",
            "        [-4.2401, -4.0519,  4.4094],\n",
            "        [-4.1256,  2.3994, -2.7357],\n",
            "        [-1.2771,  0.6312, -2.5028],\n",
            "        [ 2.7709, -3.2920, -4.0796],\n",
            "        [-3.5028,  2.8766, -3.0909],\n",
            "        [-4.4803, -2.9064,  3.4219]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.7430, -4.0659,  4.1401],\n",
            "        [-4.1169, -4.7317,  4.2896],\n",
            "        [-4.5477, -3.9744,  3.9671],\n",
            "        [-4.8095, -2.9990,  2.5600],\n",
            "        [-4.6370, -4.4179,  4.8657],\n",
            "        [-4.7009, -3.8849,  4.0086],\n",
            "        [ 3.6067, -4.1176, -3.4526],\n",
            "        [-4.6543, -3.0905,  3.6369],\n",
            "        [-5.4110, -3.6446,  3.8849],\n",
            "        [-4.1937, -3.6013,  3.2004],\n",
            "        [-4.4711, -4.6552,  4.1304],\n",
            "        [-4.2476, -3.7135,  3.9215],\n",
            "        [-4.5365, -4.3075,  4.4131],\n",
            "        [-4.7215, -2.2936,  2.9678],\n",
            "        [ 3.0025, -3.4032, -3.6150],\n",
            "        [ 3.3081, -3.2268, -3.6413]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.9184, -4.4287,  4.7825],\n",
            "        [-3.8794,  3.6954, -2.9521],\n",
            "        [-4.1190, -3.8435,  3.5554],\n",
            "        [ 3.3048, -3.7985, -3.3066],\n",
            "        [-4.8866, -3.5695,  3.9287],\n",
            "        [ 3.7980, -3.7937, -3.3786],\n",
            "        [-4.8737, -2.2103,  2.8843],\n",
            "        [-4.8591, -4.0215,  3.5105],\n",
            "        [-3.7288,  3.2580, -3.7049],\n",
            "        [-4.4899, -4.8704,  3.7355],\n",
            "        [-5.2161, -4.6327,  4.2858],\n",
            "        [-4.9880, -1.3557,  1.3428],\n",
            "        [-4.6293, -3.9637,  4.7083],\n",
            "        [ 3.3119, -2.8678, -3.3289],\n",
            "        [-2.1609, -2.7817,  2.0562],\n",
            "        [ 2.1177, -2.5316, -3.9676]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.6064, -4.7014,  4.5234],\n",
            "        [-4.6564, -4.2557,  4.0382],\n",
            "        [-5.1499, -3.8668,  4.6264],\n",
            "        [-4.4895, -3.3650,  4.0329],\n",
            "        [-4.9558, -4.4861,  4.5287],\n",
            "        [-5.0211, -4.6260,  4.5713],\n",
            "        [-4.4913, -4.3939,  4.2544],\n",
            "        [ 1.9273, -2.5001, -3.4263],\n",
            "        [-4.0629, -4.0540,  3.8942],\n",
            "        [ 3.1090, -3.8728, -3.3227],\n",
            "        [-4.1851, -4.1220,  3.6248],\n",
            "        [ 3.5989, -4.0819, -2.8846],\n",
            "        [-5.0452, -3.6420,  4.1304],\n",
            "        [-4.4392, -4.3256,  4.6193],\n",
            "        [-4.7455, -4.5756,  3.8073],\n",
            "        [ 3.6012, -4.0360, -3.2541]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.3682, -4.5416,  4.0116],\n",
            "        [-3.3609,  2.7568, -2.8557],\n",
            "        [ 2.4933, -2.5155, -4.2757],\n",
            "        [-1.5793,  1.4313, -2.0727],\n",
            "        [-4.3725, -4.0346,  3.9966],\n",
            "        [ 1.3463, -1.5130, -3.5953],\n",
            "        [-4.6977, -3.3407,  3.8545],\n",
            "        [-0.2738, -1.0389, -2.1311],\n",
            "        [-2.7659,  2.2730, -2.4980],\n",
            "        [ 3.5850, -3.3968, -4.1090],\n",
            "        [ 1.1827, -1.1275, -4.6551],\n",
            "        [-3.8090, -4.7319,  4.3791],\n",
            "        [ 1.5180, -1.9467, -3.7345],\n",
            "        [-4.7188, -4.3289,  4.1693],\n",
            "        [-4.6973, -4.2295,  4.1647],\n",
            "        [-3.9408, -4.2150,  4.2503]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.3481, -4.4670,  4.4819],\n",
            "        [-4.1419, -4.8095,  4.6985],\n",
            "        [-4.4823, -4.8529,  4.0253],\n",
            "        [-3.5724,  3.3473, -3.4096],\n",
            "        [-2.7234,  3.7498, -3.1578],\n",
            "        [-4.9085, -4.2106,  3.9462],\n",
            "        [ 2.7002, -2.7305, -3.4065],\n",
            "        [-4.3685, -4.7298,  4.3755],\n",
            "        [-4.0723,  1.6553, -0.8398],\n",
            "        [ 3.0522, -2.9983, -4.0882],\n",
            "        [-4.8021, -4.2791,  3.9556],\n",
            "        [-3.0312,  3.8307, -3.0345],\n",
            "        [-3.0824,  2.7914, -2.6131],\n",
            "        [-3.7648,  3.2851, -2.7360],\n",
            "        [-5.0302, -4.7594,  4.4428],\n",
            "        [-4.3326, -3.8806,  4.0191]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-5.2892, -5.0248,  4.6366],\n",
            "        [-3.7790, -3.3563,  3.2679],\n",
            "        [ 3.3410, -4.1416, -3.2572],\n",
            "        [-4.6701, -3.9492,  3.3534],\n",
            "        [-4.4578, -4.3504,  4.2327],\n",
            "        [-2.7176,  3.1227, -3.1178],\n",
            "        [-2.6519,  0.8040, -1.2098],\n",
            "        [-4.5152, -4.6617,  4.7300],\n",
            "        [-3.4152,  2.8191, -2.4702],\n",
            "        [-5.1204, -0.9765,  1.5430],\n",
            "        [-4.1128, -2.8338,  2.7728],\n",
            "        [-3.4862, -3.7555,  3.7310],\n",
            "        [-2.0498,  1.0959, -2.7241],\n",
            "        [-2.0087,  0.1015, -1.1799],\n",
            "        [-4.6861, -3.9453,  4.2333],\n",
            "        [ 3.1410, -3.4394, -3.6358]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2504, -1.0007, -1.3866],\n",
            "        [-4.8877, -4.3696,  4.8790],\n",
            "        [ 0.4920, -0.0693, -4.0177],\n",
            "        [ 3.3550, -4.0561, -3.8424],\n",
            "        [-2.8476,  3.7510, -3.9856],\n",
            "        [-3.5739,  2.8175, -3.2014],\n",
            "        [-4.7831, -4.0488,  4.4601],\n",
            "        [ 3.2261, -3.3801, -3.7457],\n",
            "        [-4.5560, -3.8842,  4.0735],\n",
            "        [-4.3995, -4.2226,  4.2439],\n",
            "        [-3.7267, -4.0961,  4.9280],\n",
            "        [-4.8292, -4.8832,  4.0488],\n",
            "        [ 3.2447, -3.5008, -2.7973],\n",
            "        [-4.1004,  3.3912, -1.8789],\n",
            "        [-4.5562, -4.0008,  4.0291],\n",
            "        [-4.2088, -4.7320,  4.1694]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.6713, -2.7574,  2.8054],\n",
            "        [-4.5522, -4.9345,  4.1352],\n",
            "        [ 3.4330, -3.2489, -4.2780],\n",
            "        [-4.8519, -3.5617,  3.7673],\n",
            "        [-5.2515, -4.6819,  4.5042],\n",
            "        [-4.5559, -3.8575,  3.7873],\n",
            "        [-4.2891, -4.0129,  4.5203],\n",
            "        [ 3.0384, -3.3153, -3.7789],\n",
            "        [-4.4705, -4.0994,  4.3514],\n",
            "        [-4.7847, -4.8592,  3.9444],\n",
            "        [-4.4185, -4.2993,  3.7908],\n",
            "        [-4.4011, -3.8602,  4.5017],\n",
            "        [ 3.0067, -3.2997, -2.8923],\n",
            "        [ 3.4617, -3.3049, -3.0996],\n",
            "        [ 3.7389, -3.2668, -3.4964],\n",
            "        [-4.3446, -4.0883,  4.3614]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.8503, -3.5572, -2.9262],\n",
            "        [-2.4891,  2.3050, -3.3245],\n",
            "        [ 1.5580, -1.9690, -3.4946],\n",
            "        [-4.4496, -3.8372,  4.4825],\n",
            "        [-4.1963, -4.6557,  4.4940],\n",
            "        [-4.3499, -4.7687,  3.8923],\n",
            "        [-4.6295, -3.8882,  5.1416],\n",
            "        [-2.5411,  2.5482, -3.8259],\n",
            "        [ 2.6015, -3.0029, -4.0967],\n",
            "        [-1.9488,  2.4415, -3.2753],\n",
            "        [ 3.8188, -3.8630, -3.8220],\n",
            "        [-4.1974, -4.6911,  3.9021],\n",
            "        [-4.6619, -3.9231,  4.6704],\n",
            "        [-5.0790, -4.4437,  4.9117],\n",
            "        [-4.2335, -5.1441,  4.6052],\n",
            "        [-4.4638, -2.6526,  2.9448]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.9027, -4.1896,  3.1686],\n",
            "        [-4.3462, -4.1027,  3.6550],\n",
            "        [-5.4361, -1.2665,  0.8509],\n",
            "        [-4.2573, -3.4416,  4.2941],\n",
            "        [ 3.7312, -4.2737, -3.4150],\n",
            "        [-4.5063, -4.0678,  4.7627],\n",
            "        [ 3.1724, -4.0192, -3.8046],\n",
            "        [-4.6318, -3.9845,  3.9525],\n",
            "        [-2.3564,  2.6394, -3.0939],\n",
            "        [-4.5337, -4.6424,  4.2739],\n",
            "        [ 2.5494, -2.6882, -2.8940],\n",
            "        [-1.4717,  1.7253, -3.8746],\n",
            "        [-0.2494, -0.3148, -3.5361],\n",
            "        [ 3.4178, -3.6870, -3.6284],\n",
            "        [-2.0999,  2.2304, -2.7053],\n",
            "        [-3.5528, -4.0679,  3.7244]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.4754, -4.2503, -3.0363],\n",
            "        [-4.7819, -4.4451,  4.3565],\n",
            "        [-4.7932, -4.5806,  4.0551],\n",
            "        [-4.3582, -4.9616,  4.3663],\n",
            "        [-4.8557, -3.9730,  4.4819],\n",
            "        [-3.0295,  2.9514, -3.0802],\n",
            "        [-4.1487, -4.6621,  3.6559],\n",
            "        [ 3.5048, -3.9082, -3.2885],\n",
            "        [-4.8986, -4.2324,  4.3248],\n",
            "        [ 3.5302, -3.6096, -3.1854],\n",
            "        [-4.1187, -4.5844,  4.0851],\n",
            "        [ 2.9927, -3.7077, -3.5996],\n",
            "        [-3.0432,  3.5471, -3.5974],\n",
            "        [-4.2827, -3.4069,  3.2338],\n",
            "        [-4.1190, -3.9861,  3.6537],\n",
            "        [-4.2998, -4.6678,  4.5681]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.9141, -3.9600,  5.1046],\n",
            "        [-4.0928, -4.2626,  3.8758],\n",
            "        [-3.0711,  3.3476, -3.4347],\n",
            "        [-4.6111, -4.2566,  3.8494],\n",
            "        [-1.3810,  1.0631, -3.0973],\n",
            "        [ 3.0469, -3.9207, -2.9905],\n",
            "        [-3.7089, -2.5704,  2.5072],\n",
            "        [-3.8424, -3.9967,  3.4119],\n",
            "        [-3.4627,  2.7568, -2.4318],\n",
            "        [-4.1174, -3.7313,  3.8356],\n",
            "        [-4.5514, -4.5501,  3.7840],\n",
            "        [ 3.3997, -3.3487, -3.5293],\n",
            "        [-2.9277,  3.6652, -3.3129],\n",
            "        [ 3.4714, -3.7316, -3.3485],\n",
            "        [-4.2099, -3.7770,  4.3366],\n",
            "        [-5.1156, -4.2557,  4.5588]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.3494, -4.0480,  4.5523],\n",
            "        [-4.7417, -3.4918,  3.8478],\n",
            "        [-0.3250,  0.2713, -2.2734],\n",
            "        [-2.4196, -1.0662,  0.3332],\n",
            "        [-4.3403, -4.2924,  4.5961],\n",
            "        [-4.1396, -4.6936,  4.7502],\n",
            "        [ 3.6957, -3.1124, -3.7553],\n",
            "        [-4.6358, -4.3672,  4.3654],\n",
            "        [-4.5754, -5.0523,  4.5638],\n",
            "        [-4.5836, -3.9887,  4.3643],\n",
            "        [-5.0229, -4.6232,  4.4342],\n",
            "        [-3.2860,  2.9689, -2.9790],\n",
            "        [-3.2130, -3.4223,  3.9025],\n",
            "        [-4.3105, -4.2688,  4.3090],\n",
            "        [-4.9461, -4.4092,  4.5755],\n",
            "        [-5.0443, -4.3948,  4.4622]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.1771, -4.1130,  4.9447],\n",
            "        [-4.9650, -3.9769,  3.4627],\n",
            "        [ 3.4697, -3.6732, -3.3325],\n",
            "        [-4.9781,  0.8806,  0.0085],\n",
            "        [-4.9455, -4.5269,  4.3784],\n",
            "        [-2.2482,  2.4575, -4.4258],\n",
            "        [-4.4183, -3.4244,  3.8730],\n",
            "        [-4.5178, -3.8764,  4.8774],\n",
            "        [-4.2468, -4.2349,  4.6629],\n",
            "        [ 3.8842, -3.8646, -3.0217],\n",
            "        [ 3.1498, -3.3776, -3.4165],\n",
            "        [-3.3124,  3.0478, -3.1671],\n",
            "        [ 3.4267, -2.7927, -4.2040],\n",
            "        [ 3.5540, -3.0773, -4.7544],\n",
            "        [-4.4940, -4.7439,  4.1501],\n",
            "        [ 3.8810, -3.6107, -3.2506]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.7638, -4.5596,  4.3224],\n",
            "        [-3.8311, -3.6809,  2.7000],\n",
            "        [-4.7426, -4.8000,  5.0365],\n",
            "        [-4.2814, -4.8694,  4.1976],\n",
            "        [ 3.5416, -3.4047, -2.7438],\n",
            "        [-4.1936, -4.1188,  3.7401],\n",
            "        [-4.0491, -4.0181,  3.9645],\n",
            "        [-3.2358,  3.5048, -3.0710],\n",
            "        [-4.2392, -3.8374,  4.3071],\n",
            "        [-4.7469, -4.5835,  4.1654],\n",
            "        [-2.7959,  3.5157, -3.5588],\n",
            "        [-4.0920, -4.1736,  4.4665],\n",
            "        [-3.0436,  3.0338, -3.1931],\n",
            "        [ 3.0315, -3.1607, -3.0051],\n",
            "        [-4.4763, -4.1417,  4.2968],\n",
            "        [ 2.2865, -2.4237, -3.6246]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.3484, -4.3558,  3.5546],\n",
            "        [-4.7894, -3.7960,  4.2456],\n",
            "        [-4.8251, -4.6955,  4.5559],\n",
            "        [-1.1232,  1.2590, -4.5055],\n",
            "        [-2.9989,  2.2508, -1.9211],\n",
            "        [-4.2548, -5.0214,  4.4619],\n",
            "        [ 3.1899, -2.1125, -3.6536],\n",
            "        [ 3.4633, -3.2344, -3.2007],\n",
            "        [-4.5009, -4.2158,  4.4075],\n",
            "        [-3.0513,  2.2650, -2.5395],\n",
            "        [-1.3105,  2.1746, -3.8755],\n",
            "        [-4.1359, -3.1297,  2.6258],\n",
            "        [ 1.7810, -1.9723, -3.6431],\n",
            "        [-4.5512, -3.9692,  4.2181],\n",
            "        [ 2.5169, -3.7162, -3.4700],\n",
            "        [-4.6071, -3.9716,  4.2617]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.3718, -1.5023,  1.9608],\n",
            "        [-4.3034, -4.0048,  4.2150],\n",
            "        [-1.3022,  0.3270, -2.7370],\n",
            "        [ 3.1154, -3.7514, -3.8707],\n",
            "        [-5.2205, -4.5228,  4.6031],\n",
            "        [-4.1838, -4.3812,  3.9771],\n",
            "        [-4.8434, -4.3197,  3.9159],\n",
            "        [ 3.0443, -3.8068, -3.9322],\n",
            "        [-4.0526, -4.4080,  3.7563],\n",
            "        [-3.8939, -0.1385,  0.3793],\n",
            "        [-4.4354, -4.2634,  3.8280],\n",
            "        [-4.0022, -4.7173,  4.5605],\n",
            "        [-3.2215,  3.2461, -3.0468],\n",
            "        [-4.9247, -2.9407,  2.6578],\n",
            "        [-3.4339, -0.4342,  0.4033],\n",
            "        [-4.1696, -4.8105,  4.3139]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.4489, -3.5302, -3.6774],\n",
            "        [-3.9302, -4.0222,  3.4687],\n",
            "        [-5.3491, -3.4997,  4.2796],\n",
            "        [-2.8163,  2.8372, -2.4791],\n",
            "        [-2.6959,  2.8144, -3.2925],\n",
            "        [-4.8023, -4.8366,  4.1366],\n",
            "        [ 3.5195, -3.8170, -3.6886],\n",
            "        [-2.7993,  2.8097, -3.0343],\n",
            "        [-4.3933, -3.5101,  3.8550],\n",
            "        [-4.7761, -4.4248,  4.6230],\n",
            "        [ 3.9754, -3.9192, -4.0071],\n",
            "        [-4.2008, -3.7873,  4.2481],\n",
            "        [-3.1775,  1.7080, -2.3424],\n",
            "        [-4.7483, -4.6187,  4.1684],\n",
            "        [-1.9562,  1.6768, -3.4615],\n",
            "        [-2.5645,  3.0207, -4.1922]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2640, -2.7264, -3.8430],\n",
            "        [ 3.3002, -3.5242, -3.9564],\n",
            "        [-4.6111, -3.8519,  4.5712],\n",
            "        [-4.4054, -4.1252,  4.2005],\n",
            "        [-4.3047,  0.8405, -1.3796],\n",
            "        [ 3.2496, -3.2497, -3.4995],\n",
            "        [-4.3946, -4.1436,  4.5441],\n",
            "        [-5.2001, -2.4611,  3.2936],\n",
            "        [-2.9032,  2.9217, -3.1550],\n",
            "        [-4.5749, -3.8054,  4.2074],\n",
            "        [ 3.6686, -4.5361, -3.4931],\n",
            "        [-4.0351, -4.0480,  3.7686],\n",
            "        [-4.0672, -4.2106,  3.8617],\n",
            "        [-3.8888, -0.8103,  0.6186],\n",
            "        [ 3.8427, -3.6041, -3.6938],\n",
            "        [-4.6170, -4.4477,  4.4853]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.6666, -4.2078,  4.0643],\n",
            "        [-4.8239, -3.5796,  3.1327],\n",
            "        [-4.4183, -3.4733,  3.7280],\n",
            "        [-4.9236, -3.8977,  4.2627],\n",
            "        [-4.4603, -3.2630,  3.2831],\n",
            "        [-4.3799, -3.9604,  3.6963],\n",
            "        [-3.5413,  3.7374, -3.3545],\n",
            "        [-4.7543, -3.6913,  3.8668],\n",
            "        [ 3.7595, -3.7565, -3.5545],\n",
            "        [ 2.7344, -3.2299, -2.9697],\n",
            "        [ 3.9375, -3.8843, -3.3272],\n",
            "        [ 4.0596, -3.9239, -3.3059],\n",
            "        [-4.4651, -4.3597,  3.9817],\n",
            "        [-4.8260, -3.7991,  3.6499],\n",
            "        [-5.2593, -4.7166,  4.5675],\n",
            "        [-4.5258, -4.4308,  4.6641]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.4448, -3.6427, -3.3759],\n",
            "        [-4.3510, -3.9670,  3.9460],\n",
            "        [-4.7730, -4.5028,  4.5791],\n",
            "        [-4.0326,  2.3348, -2.3037],\n",
            "        [-4.6853, -3.9543,  3.9501],\n",
            "        [ 2.3695, -2.3033, -4.4882],\n",
            "        [-1.6148,  1.0253, -4.0368],\n",
            "        [-4.2670, -4.2662,  4.0670],\n",
            "        [-4.1699, -3.8263,  4.1091],\n",
            "        [-4.3293, -4.4845,  3.9521],\n",
            "        [-5.2079, -3.8418,  3.8474],\n",
            "        [-1.1410, -0.2932, -1.5859],\n",
            "        [-4.4183, -3.6944,  4.2096],\n",
            "        [-4.2430, -3.3231,  4.2346],\n",
            "        [-3.8392,  2.0518, -1.8378],\n",
            "        [-5.2736, -4.1000,  4.2630]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.3859, -3.4362, -3.7921],\n",
            "        [-4.5974, -4.1226,  3.8276],\n",
            "        [-4.9000, -3.9930,  4.5770],\n",
            "        [-3.1468,  2.7398, -2.4179],\n",
            "        [-4.6087, -4.6748,  3.9443],\n",
            "        [-4.5856, -3.8112,  4.5443],\n",
            "        [ 3.8344, -3.2105, -3.4401],\n",
            "        [ 0.1800, -0.8857, -3.1273],\n",
            "        [-3.4680,  2.7008, -2.5826],\n",
            "        [-4.2847, -4.5269,  4.7773],\n",
            "        [-1.1289,  1.1035, -2.8327],\n",
            "        [-5.5428, -2.8142,  2.8475],\n",
            "        [-3.9642, -0.1574,  0.7114],\n",
            "        [ 3.1300, -3.7422, -3.6459],\n",
            "        [-4.2212, -4.1488,  3.9974],\n",
            "        [-4.7833, -4.1014,  4.1422]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.7408, -3.6892,  4.3014],\n",
            "        [-4.9363, -3.5621,  3.8054],\n",
            "        [ 4.0629, -3.7470, -3.5047],\n",
            "        [-5.0874, -3.5862,  3.7071],\n",
            "        [ 3.5093, -3.5739, -3.6398],\n",
            "        [-4.9374, -3.8433,  4.6513],\n",
            "        [-4.4863, -2.9314,  2.8411],\n",
            "        [-5.2316, -4.1964,  4.0316],\n",
            "        [-4.1993, -4.2159,  4.2798],\n",
            "        [ 1.5141, -2.3064, -2.1430],\n",
            "        [-4.5486, -4.1823,  3.9892],\n",
            "        [-4.1066, -2.9136,  2.1373],\n",
            "        [-4.3659, -4.5930,  4.2222],\n",
            "        [ 2.8671, -2.4147, -4.5421],\n",
            "        [-4.1612,  2.3613, -2.5352],\n",
            "        [-5.5276, -2.8402,  2.4854]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.6130, -4.2571,  4.3965],\n",
            "        [-4.5365, -4.8741,  4.4508],\n",
            "        [-0.6924,  0.5346, -2.9909],\n",
            "        [-5.0461, -4.6449,  4.4867],\n",
            "        [-4.5911, -3.8329,  4.0143],\n",
            "        [-1.8977,  2.5048, -3.3551],\n",
            "        [ 3.6704, -3.5693, -3.1426],\n",
            "        [-4.8863, -4.6914,  3.9320],\n",
            "        [-4.4637, -4.2496,  4.1430],\n",
            "        [-2.9426,  3.4081, -3.4356],\n",
            "        [-3.1840,  3.0996, -3.3796],\n",
            "        [-4.6243, -3.7958,  3.7082],\n",
            "        [-3.9483, -3.6033,  3.4797],\n",
            "        [-4.6355, -5.0908,  4.0814],\n",
            "        [ 3.7414, -3.6128, -3.6090],\n",
            "        [-4.7274, -3.4438,  4.3299]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.4542,  2.3358, -2.8192],\n",
            "        [-4.6887, -4.7904,  3.5823],\n",
            "        [-4.9846,  0.8337, -0.9798],\n",
            "        [-3.3759,  0.6376, -1.2443],\n",
            "        [-4.6190, -4.3618,  4.4574],\n",
            "        [-3.0369,  2.6938, -3.9349],\n",
            "        [ 2.7714, -3.2277, -3.4588],\n",
            "        [-4.3523, -4.3479,  4.2761],\n",
            "        [-4.4846, -4.2626,  4.4242],\n",
            "        [ 3.9535, -3.1690, -3.4579],\n",
            "        [-4.8832, -3.2601,  2.9755],\n",
            "        [ 4.1883, -3.2128, -4.0111],\n",
            "        [-4.6044, -4.1047,  3.8981],\n",
            "        [-4.7077, -3.7401,  4.4282],\n",
            "        [-1.9086, -0.6648, -1.1614],\n",
            "        [-4.5206, -4.6650,  4.1539]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.0017, -3.7615,  4.1159],\n",
            "        [-4.7661, -4.1365,  3.8014],\n",
            "        [-4.8372, -3.3898,  4.2781],\n",
            "        [-3.9119, -3.8862,  2.9840],\n",
            "        [-4.5755, -3.9059,  3.5215],\n",
            "        [-4.7434, -3.9587,  4.3664],\n",
            "        [-3.9362, -3.3611,  3.5438],\n",
            "        [-4.4951, -4.5178,  4.7029],\n",
            "        [-4.6426, -3.9568,  4.1436],\n",
            "        [-4.4237, -4.0599,  4.2894],\n",
            "        [-3.6352,  2.9572, -2.3629],\n",
            "        [ 2.2331, -2.4260, -3.7359],\n",
            "        [ 3.2505, -3.0478, -3.9053],\n",
            "        [-4.5537, -5.3928,  3.9872],\n",
            "        [-4.2821, -4.1267,  3.9327],\n",
            "        [-4.3578, -3.9887,  3.8626]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4707, -1.6375, -0.9593],\n",
            "        [-4.7122, -4.6332,  4.3852],\n",
            "        [-4.0580, -4.0159,  3.9085],\n",
            "        [-4.5229, -4.2689,  4.1579],\n",
            "        [-3.7205, -3.0629,  2.7403],\n",
            "        [-4.8010, -4.6755,  3.9602],\n",
            "        [-4.6573, -4.0375,  4.1710],\n",
            "        [-3.9757,  2.8846, -2.7867],\n",
            "        [-4.8439, -4.6895,  4.3659],\n",
            "        [-3.3102,  3.7698, -3.5584],\n",
            "        [-3.2302,  2.9719, -3.6204],\n",
            "        [-4.3805, -3.7595,  4.7759],\n",
            "        [-3.9142,  2.6767, -2.9148],\n",
            "        [-4.5306, -3.7946,  4.0159],\n",
            "        [-5.0471, -3.6977,  4.6489],\n",
            "        [-4.6929, -4.2580,  3.6747]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.2343, -3.8963,  4.0672],\n",
            "        [-4.8393, -4.4409,  3.9960],\n",
            "        [-4.5646, -4.3115,  4.2500],\n",
            "        [ 3.8368, -3.2047, -3.4117],\n",
            "        [-5.1010, -4.2387,  4.8261],\n",
            "        [-4.8214, -4.9219,  4.5509],\n",
            "        [-4.8960, -2.7335,  3.4248],\n",
            "        [-5.0014, -4.1382,  3.7947],\n",
            "        [-4.1529, -4.5932,  4.0682],\n",
            "        [-3.1400,  2.3300, -2.5400],\n",
            "        [-3.2462,  2.9096, -3.2363],\n",
            "        [-5.3479, -3.9464,  4.4817],\n",
            "        [ 3.9872, -3.8915, -3.6402],\n",
            "        [-4.5297, -4.8102,  4.5300],\n",
            "        [-4.6137, -3.8414,  4.1752],\n",
            "        [-5.0969, -4.3100,  4.5511]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9903, -0.0855, -4.1272],\n",
            "        [-0.1694, -3.6160,  0.4104],\n",
            "        [-3.5415, -4.9655,  3.5542],\n",
            "        [ 3.1770, -2.2660, -3.7265],\n",
            "        [-3.5141,  3.1970, -3.2327],\n",
            "        [-4.7226, -4.0847,  3.3692],\n",
            "        [-4.0823, -4.1607,  4.4960],\n",
            "        [-3.9812, -4.3040,  3.7030],\n",
            "        [-5.1272, -4.3258,  4.4140],\n",
            "        [-4.4660, -4.1026,  4.5534],\n",
            "        [ 2.4784, -2.6581, -3.8106],\n",
            "        [-4.3704, -3.2214,  4.6144],\n",
            "        [-4.6611, -4.0931,  4.7456],\n",
            "        [-5.1499, -2.0181,  2.8398],\n",
            "        [-4.2897, -4.4497,  4.4841],\n",
            "        [-4.5243, -4.5002,  4.0460]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-5.4194e+00, -4.0205e+00,  3.9788e+00],\n",
            "        [-4.9252e+00, -3.5172e+00,  3.9240e+00],\n",
            "        [-3.8497e+00, -3.8947e+00,  4.1336e+00],\n",
            "        [ 7.3799e-01,  3.3931e-02, -5.3143e+00],\n",
            "        [-4.2209e+00,  3.0231e+00, -2.8592e+00],\n",
            "        [-4.3858e+00, -4.2027e+00,  4.9224e+00],\n",
            "        [ 4.0953e+00, -3.5461e+00, -3.7606e+00],\n",
            "        [-4.1155e+00, -3.8419e+00,  4.1566e+00],\n",
            "        [-5.2008e+00,  5.0793e-03,  5.0374e-01],\n",
            "        [-4.5973e+00, -3.8804e+00,  4.9433e+00],\n",
            "        [-3.8010e+00,  2.8996e+00, -2.0399e+00],\n",
            "        [-5.5480e+00, -3.9324e+00,  4.3571e+00],\n",
            "        [-3.1455e+00,  3.2507e+00, -2.9724e+00],\n",
            "        [ 3.1837e+00, -3.7542e+00, -3.3663e+00],\n",
            "        [-4.3409e+00, -3.4630e+00,  3.7476e+00],\n",
            "        [ 3.2185e+00, -3.7449e+00, -3.3099e+00]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.3053, -4.3404,  4.5840],\n",
            "        [-4.7011, -4.2650,  4.2132],\n",
            "        [-5.7088, -4.3233,  4.4425],\n",
            "        [-4.6460, -4.5600,  4.4418],\n",
            "        [-3.1231,  2.2068, -1.9668],\n",
            "        [-3.2386,  2.8178, -3.4467],\n",
            "        [-4.6042, -4.1401,  3.9413],\n",
            "        [-4.4939, -3.8185,  4.3453],\n",
            "        [-4.2434, -3.8877,  3.6724],\n",
            "        [ 2.5908, -3.0102, -4.4336],\n",
            "        [-3.6459,  3.2072, -3.1922],\n",
            "        [ 2.4755, -2.6251, -4.6256],\n",
            "        [-4.3965, -3.2431,  3.3619],\n",
            "        [-4.1290, -4.0877,  3.8738],\n",
            "        [ 2.1148, -2.0938, -4.4803],\n",
            "        [-4.1584, -4.4300,  4.3854]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.7222, -1.8306,  2.0992],\n",
            "        [ 3.5315, -3.9320, -3.5949],\n",
            "        [-4.6605, -4.4579,  4.3418],\n",
            "        [-4.4562, -4.6488,  3.7693],\n",
            "        [ 3.3748, -4.1240, -3.8275],\n",
            "        [-4.0747, -4.0637,  3.5226],\n",
            "        [-4.6244, -3.8288,  4.3095],\n",
            "        [ 0.8060, -0.9372, -4.3855],\n",
            "        [-3.3131, -1.6504,  0.4755],\n",
            "        [-4.7824, -4.3639,  4.6535],\n",
            "        [-4.3361, -4.6340,  4.3897],\n",
            "        [ 3.4058, -3.4599, -4.0634],\n",
            "        [-4.2935, -3.9527,  3.9120],\n",
            "        [-5.0352, -4.3773,  3.9567],\n",
            "        [-4.3880, -4.1564,  4.2955],\n",
            "        [-2.2984,  2.6413, -3.3059]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3754,  0.2172, -4.2245],\n",
            "        [-4.1510, -5.0503,  4.4967],\n",
            "        [-4.4490, -4.3087,  4.3018],\n",
            "        [ 2.1600, -3.0806, -2.8327],\n",
            "        [-3.5854, -4.3722,  3.9481],\n",
            "        [-5.1680, -1.8672,  2.0635],\n",
            "        [-5.2235, -4.1580,  3.6682],\n",
            "        [-3.9840,  2.6115, -1.3243],\n",
            "        [-3.4417,  3.2050, -3.1384],\n",
            "        [-4.7884, -4.1780,  3.4800],\n",
            "        [-4.2922, -4.6484,  4.2970],\n",
            "        [-3.9757, -4.1647,  4.1455],\n",
            "        [-4.2103, -3.8154,  3.5845],\n",
            "        [-4.3424, -4.3942,  4.3296],\n",
            "        [-4.1912, -4.4451,  4.0243],\n",
            "        [-4.3038, -4.3796,  4.2464]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.2825,  2.8420, -2.1584],\n",
            "        [-4.1654, -3.7791,  4.0900],\n",
            "        [ 3.1688, -3.7071, -3.5436],\n",
            "        [-4.5572, -4.0113,  4.0848],\n",
            "        [-4.3846, -4.2346,  3.9818],\n",
            "        [-3.9403, -4.6999,  4.6309],\n",
            "        [-4.1691, -4.2527,  4.8151],\n",
            "        [ 3.5275, -3.1549, -3.8390],\n",
            "        [ 3.7512, -3.3996, -4.2312],\n",
            "        [-4.4460, -3.4977,  4.5707],\n",
            "        [-4.1122, -4.0665,  4.1991],\n",
            "        [-3.9689,  3.6991, -2.5473],\n",
            "        [ 3.7970, -3.6871, -2.9950],\n",
            "        [-4.5862, -4.7959,  4.7564],\n",
            "        [-4.1121,  3.3429, -2.7882],\n",
            "        [-4.4536, -4.2106,  4.8295]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.8593, -3.6427, -3.7845],\n",
            "        [-2.9365,  3.1028, -3.1799],\n",
            "        [ 3.8374, -3.9789, -3.6581],\n",
            "        [-4.7330, -4.2031,  4.2530],\n",
            "        [ 0.0118, -0.0892, -3.1602],\n",
            "        [-4.2586, -4.2435,  4.6604],\n",
            "        [ 3.8346, -3.0601, -4.2281],\n",
            "        [-4.3128, -4.2515,  3.8597],\n",
            "        [-4.2068, -4.2818,  4.6594],\n",
            "        [-4.0448, -4.9223,  3.8296],\n",
            "        [-5.0926, -1.1585,  0.9872],\n",
            "        [ 3.5243, -3.1760, -3.5164],\n",
            "        [-4.3714, -3.5008,  4.0293],\n",
            "        [-4.6442, -4.5729,  4.5448],\n",
            "        [ 3.1597, -3.6610, -3.5567],\n",
            "        [-3.6089,  3.6197, -3.1296]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.3885, -2.9720, -3.0647],\n",
            "        [ 2.3900, -2.1435, -4.3664],\n",
            "        [-4.8277, -3.6922,  4.1970],\n",
            "        [-3.6715, -2.5712,  1.7305],\n",
            "        [-4.4474, -4.3387,  4.0045],\n",
            "        [-3.7242,  2.2107, -2.7787],\n",
            "        [-3.8114,  3.2619, -2.7371],\n",
            "        [-3.0189,  3.1720, -3.3910],\n",
            "        [-5.3803, -2.6775,  2.7782],\n",
            "        [-4.3632, -4.0008,  4.3245],\n",
            "        [-4.4236, -4.4879,  3.9486],\n",
            "        [-4.1946, -4.3006,  3.9523],\n",
            "        [ 2.9418, -2.0629, -3.9139],\n",
            "        [-4.6425, -4.1714,  4.5437],\n",
            "        [ 3.7269, -3.9388, -3.7936],\n",
            "        [-3.6219,  3.1413, -2.0875]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-5.2738, -3.4603,  3.8539],\n",
            "        [-3.6769,  2.8305, -3.2240],\n",
            "        [ 2.4146, -2.4963, -3.0482],\n",
            "        [-4.2793, -4.6596,  4.1175],\n",
            "        [-4.0448,  2.2181, -2.1300],\n",
            "        [-4.3255, -3.8697,  3.6092],\n",
            "        [-4.7959, -3.8516,  4.0890],\n",
            "        [-3.6684,  3.4506, -2.8319],\n",
            "        [-4.2081, -3.6971,  3.8998],\n",
            "        [-4.3569, -4.5135,  4.4817],\n",
            "        [-4.1151, -4.1201,  4.0202],\n",
            "        [-5.2700, -4.2696,  4.3032],\n",
            "        [-3.9382, -4.0401,  3.9065],\n",
            "        [-4.2834, -3.9642,  4.0767],\n",
            "        [-3.1988,  4.0853, -3.3921],\n",
            "        [ 3.9726, -4.1587, -3.4381]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.7347,  3.7587, -2.7680],\n",
            "        [ 3.1638, -3.3612, -3.3088],\n",
            "        [-4.6146, -4.3003,  4.4404],\n",
            "        [-4.8038, -4.5694,  4.5164],\n",
            "        [-3.2024,  3.5846, -3.0980],\n",
            "        [-4.4293, -4.2388,  4.0770],\n",
            "        [-3.9885, -4.1093,  3.7267],\n",
            "        [ 2.2987, -2.8853, -2.2657],\n",
            "        [-4.3217, -1.1535,  1.8555],\n",
            "        [-4.9274, -3.9728,  3.9696],\n",
            "        [-2.6876,  2.9050, -3.0651],\n",
            "        [-3.1596,  3.6501, -2.6743],\n",
            "        [-4.7403, -3.8653,  4.8167],\n",
            "        [-4.3292, -4.6762,  4.2405],\n",
            "        [ 0.8990, -0.8976, -3.8632],\n",
            "        [ 3.8012, -4.1930, -3.7235]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.1213, -4.7772,  4.8509],\n",
            "        [ 2.0033, -1.3507, -4.4529],\n",
            "        [-4.7160, -3.8249,  4.1245],\n",
            "        [-2.8907,  3.1630, -3.4666],\n",
            "        [-4.5997, -4.2420,  4.1392],\n",
            "        [-3.7286,  1.9300, -1.7700],\n",
            "        [ 3.8840, -4.1386, -3.5610],\n",
            "        [ 2.7984, -3.3744, -3.8044],\n",
            "        [-4.6476, -4.7028,  4.2408],\n",
            "        [-4.1271, -4.0887,  4.4500],\n",
            "        [-4.7301, -4.3665,  3.8521],\n",
            "        [-4.6398, -3.5709,  3.7987],\n",
            "        [ 1.3347, -0.2080, -4.2743],\n",
            "        [-2.5814,  2.1636, -3.7017],\n",
            "        [-3.4698,  3.6238, -3.0378],\n",
            "        [-4.0162, -4.5911,  4.3041]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.8065,  3.7471, -2.5324],\n",
            "        [-4.1738, -4.2700,  4.1852],\n",
            "        [-3.8954, -3.8255,  3.6601],\n",
            "        [ 3.3354, -3.0390, -3.7052],\n",
            "        [-2.6001,  2.4938, -2.6045],\n",
            "        [ 1.7030, -2.0206, -2.5443],\n",
            "        [-4.7788, -3.8168,  3.5321],\n",
            "        [-4.7743, -2.7720,  3.0916],\n",
            "        [-5.4676, -4.8956,  4.9577],\n",
            "        [-4.6556, -4.2319,  4.7336],\n",
            "        [-4.0684, -3.8355,  4.4065],\n",
            "        [-4.4285, -4.9958,  4.2799],\n",
            "        [ 3.8394, -3.8104, -3.5891],\n",
            "        [-5.0385, -3.4226,  4.0782],\n",
            "        [-4.3242, -4.2237,  4.3877],\n",
            "        [-4.6637, -4.2449,  4.2548]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2022, -1.1300, -3.2132],\n",
            "        [-4.6176, -4.1742,  3.9322],\n",
            "        [-4.9479, -4.4055,  3.8535],\n",
            "        [-0.4848,  0.2996, -4.4227],\n",
            "        [ 3.5698, -3.7392, -2.9507],\n",
            "        [-4.5012, -4.2891,  4.3640],\n",
            "        [-3.4546,  2.9123, -3.1756],\n",
            "        [-4.5850, -3.7585,  4.8349],\n",
            "        [-4.4477, -3.9535,  3.8871],\n",
            "        [ 2.2876, -2.3645, -3.5804],\n",
            "        [-1.3227,  0.8248, -3.5438],\n",
            "        [-3.3026,  3.2931, -3.1645],\n",
            "        [ 2.1168, -2.6079, -3.1422],\n",
            "        [-5.1156, -4.1824,  4.4268],\n",
            "        [-4.1457, -4.3649,  3.8012],\n",
            "        [ 3.2378, -2.6624, -4.3162]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.2325, -4.0901,  4.2606],\n",
            "        [-4.4828, -4.4205,  4.6647],\n",
            "        [ 3.8751, -3.9457, -2.5332],\n",
            "        [-4.3916, -4.6540,  4.3534],\n",
            "        [-4.7844, -4.6513,  4.5850],\n",
            "        [ 3.4985, -3.7479, -3.4054],\n",
            "        [-4.6576, -4.3961,  4.2001],\n",
            "        [ 3.5995, -3.6530, -3.6351],\n",
            "        [ 2.9928, -3.7861, -3.7693],\n",
            "        [ 3.6360, -3.4424, -3.6301],\n",
            "        [ 3.5647, -3.6647, -3.2780],\n",
            "        [-3.8076, -4.0281,  4.3312],\n",
            "        [-4.1298, -4.8311,  4.4807],\n",
            "        [-4.3689, -4.4164,  3.7015],\n",
            "        [ 3.4013, -3.5989, -3.0237],\n",
            "        [-3.8986, -4.2325,  3.2976]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.1450, -3.3168, -2.8166],\n",
            "        [-3.8960, -4.1722,  4.5033],\n",
            "        [-2.7565,  2.2472, -2.3126],\n",
            "        [ 1.8710, -1.8835, -3.2383],\n",
            "        [-4.4080,  1.8307, -1.6517],\n",
            "        [ 2.9721, -2.9277, -3.6409],\n",
            "        [-4.2179, -4.3354,  4.2123],\n",
            "        [-4.1519,  3.2927, -2.3149],\n",
            "        [ 2.0109, -2.3048, -3.1403],\n",
            "        [-3.3090,  2.2646, -3.3741],\n",
            "        [-4.9628, -4.2982,  4.2373],\n",
            "        [-4.2684, -4.5129,  4.3694],\n",
            "        [-4.5910, -4.1020,  4.2579],\n",
            "        [-4.8149, -4.5106,  4.5374],\n",
            "        [-4.0492, -3.8031,  4.4255],\n",
            "        [-3.0894,  2.8738, -2.7735]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.3407, -3.6280,  4.7780],\n",
            "        [-3.8751,  2.9733, -2.8442],\n",
            "        [-4.2374, -4.2577,  4.2456],\n",
            "        [-4.4803, -3.7290,  3.8778],\n",
            "        [-4.0980, -4.1471,  3.8450],\n",
            "        [-4.5848, -4.0168,  4.2841],\n",
            "        [ 4.0145, -3.4584, -3.9025],\n",
            "        [-4.4839, -4.5498,  4.1651],\n",
            "        [ 3.7715, -3.3817, -3.2683],\n",
            "        [-4.4125, -4.5635,  4.3708],\n",
            "        [-4.4917, -3.8236,  4.0698],\n",
            "        [-0.5026,  0.8240, -2.7182],\n",
            "        [-4.2699, -4.0964,  4.2436],\n",
            "        [ 3.2254, -3.4117, -3.4408],\n",
            "        [-4.3803, -3.5899,  4.6368],\n",
            "        [ 3.1688, -4.2778, -2.9691]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.6882, -4.4624,  4.0962],\n",
            "        [-4.4181, -4.7791,  4.5388],\n",
            "        [-2.8803, -3.5996,  2.9568],\n",
            "        [ 1.2786, -1.5243, -3.6988],\n",
            "        [-4.2574, -4.4221,  5.0035],\n",
            "        [-1.5901,  0.5898, -3.0000],\n",
            "        [-2.6440,  2.7967, -3.3473],\n",
            "        [-4.8363, -4.6807,  4.1755],\n",
            "        [-3.9452, -4.7692,  4.4686],\n",
            "        [-3.4573, -0.8653, -0.2097],\n",
            "        [-3.8419, -4.5044,  3.5857],\n",
            "        [-3.8366,  3.1816, -3.2993],\n",
            "        [-4.4502, -4.5747,  4.3942],\n",
            "        [-4.3822, -4.4461,  3.6246],\n",
            "        [-3.1853,  0.6791, -0.5175],\n",
            "        [-3.3805,  3.3110, -3.2963]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.5657,  0.9873, -3.3988],\n",
            "        [-4.8460, -4.3396,  4.5090],\n",
            "        [-3.9377, -4.2843,  4.1937],\n",
            "        [-1.7665,  1.6637, -2.7971],\n",
            "        [-5.8812, -4.5727,  4.6299],\n",
            "        [ 3.5921, -2.9859, -4.4779],\n",
            "        [-4.5867, -3.9000,  4.1154],\n",
            "        [-4.2765, -2.9033,  3.3329],\n",
            "        [ 4.5546, -4.0102, -3.1558],\n",
            "        [ 3.1853, -3.2479, -3.1724],\n",
            "        [ 3.2986, -3.1461, -3.9212],\n",
            "        [ 3.3634, -3.9958, -3.0824],\n",
            "        [ 3.4646, -3.4913, -3.2055],\n",
            "        [-4.3251, -4.4264,  4.2331],\n",
            "        [ 3.9255, -3.4685, -3.6774],\n",
            "        [-3.9472, -3.5764,  3.9191]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.6521, -4.1463,  3.9985],\n",
            "        [-4.8749, -3.2385,  3.6760],\n",
            "        [ 3.7262, -3.3004, -3.4206],\n",
            "        [ 4.0999, -4.0425, -3.3217],\n",
            "        [-4.9644, -4.6469,  4.8328],\n",
            "        [-2.0169,  1.4071, -3.3174],\n",
            "        [-4.4318, -4.0371,  4.1623],\n",
            "        [-4.5776, -4.5267,  4.2793],\n",
            "        [-3.5909, -4.0163,  4.0074],\n",
            "        [ 2.5160, -2.6282, -3.5326],\n",
            "        [-4.3802, -4.2177,  4.6194],\n",
            "        [ 3.9043, -3.7458, -3.7108],\n",
            "        [-4.0589, -4.1885,  4.2215],\n",
            "        [-4.3755, -4.6302,  4.4021],\n",
            "        [-2.7983,  3.2889, -3.4750],\n",
            "        [-4.8781, -4.7068,  5.0434]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.0100, -3.7295,  4.0779],\n",
            "        [-4.3141, -4.4340,  3.9339],\n",
            "        [-3.6299,  2.3983, -2.5624],\n",
            "        [-5.4105, -3.8936,  3.5303],\n",
            "        [-2.6686,  3.2631, -3.3578],\n",
            "        [-2.5688,  1.3901, -2.4150],\n",
            "        [-4.6096, -4.1369,  4.1135],\n",
            "        [-0.4071,  0.1423, -3.1841],\n",
            "        [ 3.2269, -3.7357, -2.9449],\n",
            "        [-3.9643, -4.3663,  4.0430],\n",
            "        [-3.8771, -4.7401,  3.7000],\n",
            "        [ 3.7657, -3.2709, -3.1256],\n",
            "        [ 4.1036, -3.9643, -3.2918],\n",
            "        [-4.0353, -4.2876,  4.4030],\n",
            "        [ 3.0697, -3.8248, -2.1743],\n",
            "        [-4.1268, -3.8368,  4.3645]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.7399, -4.0729,  3.8660],\n",
            "        [ 3.7198, -3.6075, -3.3399],\n",
            "        [-3.8938, -2.3399,  2.1171],\n",
            "        [ 3.6995, -3.7359, -3.5155],\n",
            "        [ 3.4169, -3.6663, -3.3769],\n",
            "        [ 3.5774, -3.4699, -3.5748],\n",
            "        [-4.8877, -4.0512,  4.4244],\n",
            "        [-4.8887, -3.3389,  3.5405],\n",
            "        [-4.8669, -4.5160,  4.4902],\n",
            "        [ 2.8138, -2.4672, -3.8444],\n",
            "        [-3.2349,  1.8411, -2.4413],\n",
            "        [-1.5397,  2.2373, -3.4520],\n",
            "        [-4.6294, -3.8910,  4.4351],\n",
            "        [ 3.3122, -2.9593, -3.5008],\n",
            "        [ 3.9077, -3.4735, -3.1922],\n",
            "        [-4.4952, -3.6572,  3.4504]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3750, -3.1037, -2.4851],\n",
            "        [-5.5770, -2.5251,  2.7983],\n",
            "        [-4.9819, -4.4710,  4.7226],\n",
            "        [-4.3181, -4.6626,  4.9507],\n",
            "        [-4.2804, -4.5564,  4.1955],\n",
            "        [ 3.6038, -3.8980, -3.5791],\n",
            "        [-2.0140,  1.6776, -3.1854],\n",
            "        [-3.1898,  2.8172, -1.9027],\n",
            "        [-4.7340, -4.2474,  3.7334],\n",
            "        [-4.9569, -3.3130,  3.2428],\n",
            "        [ 3.2707, -3.7371, -3.3789],\n",
            "        [-3.3999, -3.3600,  2.9288],\n",
            "        [-1.9254,  2.9192, -3.9765],\n",
            "        [-4.3457, -4.4511,  4.2614],\n",
            "        [-4.3338, -4.0768,  3.5338],\n",
            "        [-4.3410, -4.7369,  4.1923]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.1847, -3.2874,  3.5811],\n",
            "        [-2.2768,  3.5551, -4.3797],\n",
            "        [ 2.9503, -2.7669, -4.7974],\n",
            "        [ 4.2271, -3.7075, -3.8678],\n",
            "        [-3.9742, -4.5543,  4.1557],\n",
            "        [-4.2671, -4.2539,  4.4274],\n",
            "        [-4.5564, -4.0466,  3.6862],\n",
            "        [ 0.6866, -3.6019,  0.0491],\n",
            "        [-4.8053, -4.3023,  3.5578],\n",
            "        [-4.8013, -4.0522,  3.8135],\n",
            "        [-2.3615,  2.6344, -3.9361],\n",
            "        [ 4.4322, -3.7708, -4.1739],\n",
            "        [-4.6173, -4.9966,  4.6565],\n",
            "        [-4.1425, -3.5307,  3.8533],\n",
            "        [ 3.9878, -3.7981, -3.2430],\n",
            "        [-4.5564, -3.9323,  3.6327]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.9423, -4.9215,  3.9288],\n",
            "        [-4.4930, -3.4647,  3.6649],\n",
            "        [-4.1612, -3.3327,  3.7226],\n",
            "        [-4.3890, -3.8190,  3.8062],\n",
            "        [ 1.6240, -1.7550, -4.1101],\n",
            "        [-2.2398,  2.5747, -3.3919],\n",
            "        [-4.1012, -3.7476,  3.1968],\n",
            "        [-2.6904,  3.3055, -3.6358],\n",
            "        [-3.9756, -1.4402,  1.7403],\n",
            "        [-4.5928, -4.3894,  4.8043],\n",
            "        [-4.2115, -4.8546,  5.0804],\n",
            "        [ 3.5079, -3.3887, -3.7327],\n",
            "        [ 3.9628, -3.3556, -3.9366],\n",
            "        [-4.4252, -4.2284,  3.7167],\n",
            "        [ 1.6625, -1.2593, -4.4924],\n",
            "        [-2.9476,  3.5033, -3.5769]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.7845, -4.1281,  4.2975],\n",
            "        [-3.8299, -2.9297,  2.7619],\n",
            "        [-4.2138, -4.5798,  4.1970],\n",
            "        [-4.7314, -4.1332,  4.5035],\n",
            "        [-3.1403, -3.4865,  3.0360],\n",
            "        [-4.1577, -4.5121,  4.0948],\n",
            "        [-4.6708, -4.1446,  4.6137],\n",
            "        [-2.8075,  3.3575, -2.6664],\n",
            "        [-4.5279, -4.4482,  4.0316],\n",
            "        [ 3.3770, -3.3008, -4.7064],\n",
            "        [-2.0803,  1.7699, -2.2653],\n",
            "        [ 3.3920, -3.5917, -3.2310],\n",
            "        [-4.1355, -4.5202,  4.1579],\n",
            "        [ 2.9397, -3.1227, -3.9603],\n",
            "        [-4.1516, -4.3788,  4.1222],\n",
            "        [-4.3431, -4.7278,  4.1730]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.1046, -3.2600, -3.5492],\n",
            "        [-2.0337,  2.6341, -2.9866],\n",
            "        [ 4.4518, -3.8153, -3.4334],\n",
            "        [ 3.5133, -3.6365, -3.2240],\n",
            "        [-3.9611, -3.6928,  4.5642],\n",
            "        [-4.4970, -3.8605,  3.9031],\n",
            "        [-4.2740, -3.5866,  4.4363],\n",
            "        [-4.5803, -3.6698,  3.9581],\n",
            "        [-5.0341, -3.8594,  4.8956],\n",
            "        [-4.7701, -3.6145,  4.4059],\n",
            "        [-2.7685,  3.3151, -4.0787],\n",
            "        [-5.3547, -4.4173,  4.0072],\n",
            "        [-4.1967, -4.5134,  3.8308],\n",
            "        [-4.7814, -4.0999,  4.8500],\n",
            "        [-4.1308, -4.1941,  3.5723],\n",
            "        [-4.2693, -4.3545,  4.1953]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.8767, -4.2324,  4.7407],\n",
            "        [-2.2172,  2.3028, -2.9636],\n",
            "        [ 4.0519, -4.0557, -3.6986],\n",
            "        [-5.2917, -4.2722,  4.1663],\n",
            "        [ 1.8452, -2.1359, -3.5806],\n",
            "        [-3.9840,  1.8948, -1.7862],\n",
            "        [-4.2906, -4.0548,  3.9966],\n",
            "        [ 4.1547, -3.7556, -3.7809],\n",
            "        [-5.2444, -3.9220,  4.4328],\n",
            "        [-1.7846, -3.7106,  1.5858],\n",
            "        [-4.1221, -2.8392,  2.3610],\n",
            "        [-1.1314,  1.5021, -4.7898],\n",
            "        [-3.9079, -3.7425,  3.4676],\n",
            "        [-4.1250, -3.8985,  4.1377],\n",
            "        [-4.9651, -4.5283,  4.7111],\n",
            "        [-4.1337, -4.1007,  4.0025]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-5.3514, -4.3046,  4.7009],\n",
            "        [ 0.7181, -2.5124, -1.5634],\n",
            "        [-4.4642, -4.5950,  4.5921],\n",
            "        [-5.0032, -4.4201,  4.4772],\n",
            "        [-4.3748, -3.7297,  3.7807],\n",
            "        [-3.6900,  0.1257,  0.6901],\n",
            "        [-4.1276, -4.1053,  3.8646],\n",
            "        [ 2.4823, -2.4461, -4.3559],\n",
            "        [-4.4128, -1.3771,  0.1989],\n",
            "        [-2.9593,  3.1661, -3.6675],\n",
            "        [ 4.1807, -4.0257, -3.2425],\n",
            "        [-2.5950,  2.5958, -3.8811],\n",
            "        [-4.0472, -3.7810,  3.5010],\n",
            "        [-0.0598, -2.2267, -1.2710],\n",
            "        [-5.2630, -3.9500,  3.8654],\n",
            "        [-3.1905,  2.7930, -2.3414]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 4.0145, -4.3625, -3.7032],\n",
            "        [-4.1861,  1.0137, -0.9128],\n",
            "        [-4.8991, -4.2917,  5.2975],\n",
            "        [ 3.5068, -3.1793, -3.0074],\n",
            "        [-4.4594, -3.6573,  3.5461],\n",
            "        [ 2.9871, -1.9725, -4.2678],\n",
            "        [-4.4512, -4.4184,  4.0773],\n",
            "        [-4.8302, -4.1037,  4.7589],\n",
            "        [-4.4615, -0.4456,  1.2393],\n",
            "        [ 1.1197, -0.4478, -4.1452],\n",
            "        [-4.6090, -3.8992,  3.3372],\n",
            "        [-4.7232, -4.8833,  4.2379],\n",
            "        [-4.8516, -2.7028,  2.7599],\n",
            "        [-4.3994, -3.8444,  4.3155],\n",
            "        [ 3.6180, -3.3937, -3.5986],\n",
            "        [-4.7969, -4.5863,  4.5927]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.4324, -4.0463,  4.3282],\n",
            "        [-4.3707, -4.3151,  4.1247],\n",
            "        [-4.4238, -3.7907,  3.3780],\n",
            "        [-4.3636, -4.0852,  3.9888],\n",
            "        [-4.7391, -3.8987,  4.2821],\n",
            "        [ 2.7366, -2.3316, -3.4107],\n",
            "        [ 3.0199, -3.3228, -3.7883],\n",
            "        [-4.0655, -3.6868,  2.4574],\n",
            "        [-2.6091,  2.1981, -2.7005],\n",
            "        [-4.4632, -3.9123,  4.6747],\n",
            "        [-4.7521, -3.6867,  3.8495],\n",
            "        [-4.2023, -4.3357,  4.9495],\n",
            "        [-4.9046, -4.1553,  4.3873],\n",
            "        [-4.8912, -3.7296,  3.7243],\n",
            "        [-3.2224,  3.1547, -3.4621],\n",
            "        [-4.8129, -4.7869,  4.7723]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.4817, -4.5385,  4.2888],\n",
            "        [-4.7056, -3.9465,  3.9794],\n",
            "        [ 4.0828, -3.7226, -3.7696],\n",
            "        [-3.8525, -3.9364,  3.7944],\n",
            "        [-4.6028, -3.9544,  4.2941],\n",
            "        [-3.0891, -2.0840,  1.4342],\n",
            "        [ 3.7291, -2.7100, -3.5305],\n",
            "        [-4.5417, -4.0992,  4.2109],\n",
            "        [-2.2778,  2.2426, -4.0610],\n",
            "        [-4.5907, -3.3294,  4.1278],\n",
            "        [-3.8646, -3.9153,  4.4046],\n",
            "        [-4.8316, -3.5267,  4.2224],\n",
            "        [-4.7431, -4.5951,  3.8025],\n",
            "        [-5.3805, -3.9517,  4.0716],\n",
            "        [-4.7499, -3.8593,  3.8628],\n",
            "        [-3.7025,  2.2633, -2.2731]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.3881,  2.1251, -2.9265],\n",
            "        [-1.2595,  1.7228, -4.1622],\n",
            "        [-3.2477, -3.6793,  2.1568],\n",
            "        [-4.7833, -4.5107,  4.7948],\n",
            "        [-2.4620,  2.6514, -3.4430],\n",
            "        [-4.8899, -4.4488,  4.3562],\n",
            "        [-3.7081, -1.3733,  1.6114],\n",
            "        [ 3.5131, -3.7681, -3.6637],\n",
            "        [-4.9606, -3.4033,  3.4385],\n",
            "        [ 3.2627, -3.6944, -3.6552],\n",
            "        [ 1.1011, -1.6399, -3.0177],\n",
            "        [-2.7976,  2.8027, -2.7071],\n",
            "        [-4.6537, -4.3594,  4.4198],\n",
            "        [-0.7231,  0.9244, -4.6278],\n",
            "        [-4.3007, -4.2106,  4.2277],\n",
            "        [-5.1762, -3.8964,  3.8173]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.4282,  1.9424, -3.3057],\n",
            "        [-4.2198, -3.4565,  3.7054],\n",
            "        [-4.4534, -3.8672,  2.9721],\n",
            "        [-5.2550, -4.1333,  4.8583],\n",
            "        [ 3.8660, -3.3064, -3.9007],\n",
            "        [-2.3600,  3.3077, -3.2844],\n",
            "        [ 3.2090, -3.6370, -3.7693],\n",
            "        [-4.0318, -0.0302,  0.5082],\n",
            "        [-4.9211, -4.3375,  4.6244],\n",
            "        [ 4.4160, -4.1228, -4.0123],\n",
            "        [-4.9360, -3.6311,  3.6346],\n",
            "        [ 3.5796, -2.9182, -3.5106],\n",
            "        [-4.9595, -4.1059,  4.0549],\n",
            "        [-4.6234, -4.3047,  3.6343],\n",
            "        [-4.5494, -4.2576,  4.3306],\n",
            "        [-3.3245,  3.1053, -2.7294]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1647, -0.7499, -1.7876],\n",
            "        [-1.4271,  1.4459, -3.2471],\n",
            "        [-5.1477, -3.4829,  3.4165],\n",
            "        [ 3.5106, -3.7347, -4.1086],\n",
            "        [-2.3403,  2.4665, -3.5282],\n",
            "        [ 2.8240, -3.3336, -3.8375],\n",
            "        [-4.6326, -4.6391,  4.4748],\n",
            "        [-4.6259, -3.0741,  3.9222],\n",
            "        [-5.6132, -1.4880,  1.8227],\n",
            "        [-5.2342, -0.3749,  0.3185],\n",
            "        [-5.1820, -4.7321,  4.2648],\n",
            "        [-3.5839,  2.0176, -1.6503],\n",
            "        [-4.7005, -3.5228,  3.2936],\n",
            "        [-3.6118, -0.4606,  0.0449],\n",
            "        [-3.4341,  2.6230, -2.8465],\n",
            "        [-4.5189, -3.8382,  4.4561]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.7416, -4.2978,  4.0981],\n",
            "        [-0.0605, -0.6168, -3.1147],\n",
            "        [-4.4071, -4.6131,  4.4788],\n",
            "        [-4.1389, -4.2979,  4.5580],\n",
            "        [ 1.1677, -1.4426, -4.4383],\n",
            "        [ 3.3275, -3.3462, -3.9130],\n",
            "        [ 3.4480, -2.9759, -3.0250],\n",
            "        [-4.9191, -3.9804,  4.1022],\n",
            "        [ 3.4416, -3.2524, -4.3928],\n",
            "        [-4.5207, -3.5787,  3.1490],\n",
            "        [-3.9283, -4.2469,  4.2115],\n",
            "        [-3.8482,  2.2124, -2.4362],\n",
            "        [-5.2830, -3.0733,  3.8961],\n",
            "        [-4.4542, -4.4454,  3.9280],\n",
            "        [-4.4423, -4.2236,  4.2207],\n",
            "        [-4.8943, -4.3322,  4.4825]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.5832,  1.4081, -1.5829],\n",
            "        [ 2.3260, -2.8447, -3.5918],\n",
            "        [-4.6586, -3.9097,  4.6813],\n",
            "        [ 3.1509, -3.3916, -4.3412],\n",
            "        [-3.2123, -1.1211,  0.0977],\n",
            "        [-4.8815, -3.9151,  4.1770],\n",
            "        [-4.5957, -4.1415,  4.2451],\n",
            "        [ 3.6654, -3.7013, -3.0415],\n",
            "        [ 0.6752, -1.5928, -3.9712],\n",
            "        [-4.7344, -4.5098,  3.8670],\n",
            "        [-5.1571, -4.7661,  4.7518],\n",
            "        [-5.4784, -4.2117,  4.2734],\n",
            "        [-4.8974, -4.7355,  4.4825],\n",
            "        [ 3.5350, -4.4582, -2.8334],\n",
            "        [-4.0386, -4.3568,  3.9706],\n",
            "        [-2.9614,  3.0618, -3.8178]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-5.2350, -3.8226,  3.9365],\n",
            "        [ 3.3727, -2.9745, -3.8615],\n",
            "        [-5.3000, -4.9953,  4.5912],\n",
            "        [-4.0166, -3.6424,  4.0047],\n",
            "        [-4.4471, -5.3659,  4.0606],\n",
            "        [-4.4205, -4.0738,  3.9285],\n",
            "        [-4.6327, -3.7028,  3.7442],\n",
            "        [-4.5711, -3.4803,  4.5808],\n",
            "        [-4.3203, -4.4261,  4.5328],\n",
            "        [ 1.7780, -1.3613, -4.2372],\n",
            "        [ 2.7827, -3.1117, -3.3021],\n",
            "        [ 3.9481, -3.8915, -3.2537],\n",
            "        [ 3.0738, -3.5794, -3.3462],\n",
            "        [-3.9709, -3.9928,  3.4163],\n",
            "        [-4.2817, -3.9711,  3.3056],\n",
            "        [ 3.9733, -3.6824, -3.3761]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.6299, -3.1097, -4.0974],\n",
            "        [-3.8083,  3.7072, -3.0809],\n",
            "        [-4.6228, -4.7393,  4.6715],\n",
            "        [ 3.6248, -3.5179, -3.7312],\n",
            "        [-4.4389,  3.4053, -3.7480],\n",
            "        [-4.2029, -4.4951,  3.9047],\n",
            "        [ 3.6871, -3.7761, -3.3137],\n",
            "        [-3.8374, -5.0098,  3.5060],\n",
            "        [ 3.3294, -3.4562, -2.7390],\n",
            "        [ 3.0404, -3.4829, -4.1235],\n",
            "        [-4.2224, -4.5279,  3.7682],\n",
            "        [-4.7362, -4.2021,  4.0225],\n",
            "        [-2.6666,  3.0316, -3.0776],\n",
            "        [-4.7252, -4.9937,  4.5731],\n",
            "        [ 2.3101, -2.1272, -3.7283],\n",
            "        [ 3.4371, -4.0029, -2.9971]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.8372, -4.0105, -3.9759],\n",
            "        [ 3.6694, -3.5610, -3.4968],\n",
            "        [-4.5896, -2.7820,  3.3573],\n",
            "        [ 4.1784, -3.7678, -4.2398],\n",
            "        [ 3.6079, -3.3367, -3.4437],\n",
            "        [-2.8050,  2.6526, -3.5842],\n",
            "        [-4.8337, -4.5587,  2.8913],\n",
            "        [-4.2509, -4.0726,  4.0135],\n",
            "        [-5.0340, -4.2084,  3.9901],\n",
            "        [ 3.5325, -3.7806, -3.2097],\n",
            "        [-4.5600, -4.0711,  4.2039],\n",
            "        [-4.9218, -4.6455,  4.4934],\n",
            "        [-4.5703, -4.1467,  4.6749],\n",
            "        [-2.1416, -2.0982,  2.0468],\n",
            "        [-2.9353, -1.6282,  1.9904],\n",
            "        [-4.6354, -4.7766,  4.3197]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.7482,  2.7854, -2.5403],\n",
            "        [-4.5380, -4.2140,  4.9314],\n",
            "        [-3.1077,  2.6682, -2.4617],\n",
            "        [-4.1230, -4.4967,  4.3632],\n",
            "        [-3.5037,  2.9471, -3.2346],\n",
            "        [-4.5826, -4.5564,  5.0298],\n",
            "        [ 3.6700, -3.3447, -3.9482],\n",
            "        [-3.7629,  2.5331, -2.6700],\n",
            "        [-4.4572, -3.8406,  4.4183],\n",
            "        [-4.8233, -3.9487,  4.3815],\n",
            "        [-2.4802,  1.7091, -2.6377],\n",
            "        [-4.9176, -4.6135,  4.0005],\n",
            "        [-0.5296, -1.2276, -2.5142],\n",
            "        [ 3.3752, -3.4738, -3.7793],\n",
            "        [-2.2669,  2.9908, -3.6319],\n",
            "        [-4.2673, -4.4347,  3.8020]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.9639,  3.4580, -2.2785],\n",
            "        [-4.1126, -4.3458,  3.8804],\n",
            "        [-4.5029, -4.2021,  4.6523],\n",
            "        [-3.3299, -1.2154,  0.4138],\n",
            "        [-3.1221,  3.4590, -3.5384],\n",
            "        [-4.5379, -4.2196,  4.6091],\n",
            "        [-5.0222, -4.1386,  4.2974],\n",
            "        [-3.4987,  0.3175,  0.1637],\n",
            "        [ 3.5301, -4.5605, -2.7812],\n",
            "        [-2.5421,  2.6592, -3.8273],\n",
            "        [-4.9198, -3.9015,  4.1331],\n",
            "        [-4.4745, -3.9537,  3.8697],\n",
            "        [-4.4774, -4.4058,  4.7242],\n",
            "        [-5.0507, -3.8163,  4.7225],\n",
            "        [-4.9222, -3.4649,  4.0391],\n",
            "        [-4.5466, -4.3418,  4.9508]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.8315, -4.4409,  4.2876],\n",
            "        [-3.5252,  0.3350, -1.8118],\n",
            "        [ 1.0250, -2.8873, -1.8079],\n",
            "        [-4.1746, -3.9883,  3.8189],\n",
            "        [-4.6972, -4.5373,  4.3205],\n",
            "        [-5.0341, -4.2959,  4.4116],\n",
            "        [-4.2461, -4.0945,  3.8579],\n",
            "        [-5.3817, -4.6184,  4.8791],\n",
            "        [-4.3653, -3.6976,  3.5950],\n",
            "        [-4.3005, -4.5562,  4.4936],\n",
            "        [-4.4864, -4.4227,  4.1378],\n",
            "        [-4.4488, -4.4836,  4.7981],\n",
            "        [-4.5721, -4.3518,  4.8306],\n",
            "        [-3.1412,  0.1181, -0.5368],\n",
            "        [-4.8579, -3.8197,  4.4737],\n",
            "        [-3.9485, -4.4614,  3.8022]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.1614,  2.2113, -3.3558],\n",
            "        [-4.5011, -4.4802,  4.4218],\n",
            "        [-4.2882, -4.3882,  4.2442],\n",
            "        [-3.8547,  1.5624, -1.7556],\n",
            "        [-4.9742, -4.1347,  4.3986],\n",
            "        [-4.6472, -4.2450,  4.3499],\n",
            "        [-3.6803,  3.3038, -2.6074],\n",
            "        [-0.7937, -0.0224, -4.0990],\n",
            "        [ 3.9499, -3.7476, -3.7067],\n",
            "        [ 3.2949, -3.3707, -3.1369],\n",
            "        [-4.5183, -3.9400,  4.1073],\n",
            "        [-5.0568, -4.6050,  4.8682],\n",
            "        [-4.3851, -4.4360,  4.7588],\n",
            "        [ 2.8603, -2.8067, -3.4393],\n",
            "        [-4.9889, -3.6844,  4.1595],\n",
            "        [-4.5808, -4.2420,  4.5181]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.4607, -4.6788,  4.4132],\n",
            "        [ 4.2522, -3.8041, -3.5445],\n",
            "        [-1.9790, -0.2878, -1.4483],\n",
            "        [ 4.4020, -4.1827, -3.7855],\n",
            "        [ 3.1779, -2.7510, -4.0200],\n",
            "        [ 3.9831, -4.4128, -3.1464],\n",
            "        [ 3.9711, -3.8143, -3.0353],\n",
            "        [ 3.3406, -3.0961, -3.7244],\n",
            "        [-4.6036,  0.2860, -0.0476],\n",
            "        [ 3.6705, -3.2628, -3.8557],\n",
            "        [-4.4085, -4.1830,  4.3392],\n",
            "        [ 2.3482, -2.2292, -3.5258],\n",
            "        [-3.3283,  2.3987, -2.0795],\n",
            "        [ 3.7302, -3.8146, -3.1956],\n",
            "        [ 3.7398, -3.9392, -3.3307],\n",
            "        [-4.6364, -4.2484,  4.4531]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.6946,  2.8646, -3.0306],\n",
            "        [-4.2918, -1.4043,  1.8405],\n",
            "        [-4.8100, -4.1681,  4.5396],\n",
            "        [-4.4682, -4.4430,  4.3557],\n",
            "        [-4.3270, -4.6863,  3.7426],\n",
            "        [-5.1907, -4.9740,  4.6289],\n",
            "        [-4.5661, -4.0192,  4.0858],\n",
            "        [-4.5464, -4.4093,  4.3470],\n",
            "        [-4.2544, -4.3194,  4.2666],\n",
            "        [-4.6630, -4.6859,  4.2691],\n",
            "        [ 3.4233, -3.8566, -2.7788],\n",
            "        [-3.4174,  0.7509, -2.0387],\n",
            "        [-4.6444, -4.4886,  4.6363],\n",
            "        [ 3.6610, -3.8457, -3.5881],\n",
            "        [ 3.2506, -3.4637, -3.7562],\n",
            "        [ 2.9093, -4.1138, -2.1702]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.8330, -4.2818,  4.3411],\n",
            "        [ 2.9748, -3.2096, -4.0989],\n",
            "        [ 4.3509, -4.2965, -3.9584],\n",
            "        [-4.9184, -4.6678,  4.5853],\n",
            "        [ 3.7932, -3.6023, -3.7190],\n",
            "        [-4.7456, -4.0079,  4.7218],\n",
            "        [ 3.1686, -3.1022, -3.7383],\n",
            "        [-3.9158, -4.1710,  4.3167],\n",
            "        [-4.5774, -3.5573,  4.5406],\n",
            "        [-3.3835, -0.8304,  1.2213],\n",
            "        [-4.0606, -3.8191,  4.0481],\n",
            "        [-4.8331, -3.7550,  5.1461],\n",
            "        [-5.0103, -2.2645,  1.5132],\n",
            "        [-4.2507,  3.2246, -2.0739],\n",
            "        [ 3.9637, -4.4431, -3.4570],\n",
            "        [-4.0825, -4.5105,  4.2743]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.2617, -3.8833,  4.2053],\n",
            "        [-3.1029, -3.2417,  2.3747],\n",
            "        [-2.8772,  1.9523, -2.2081],\n",
            "        [-4.4092, -4.0088,  4.6596],\n",
            "        [-4.3240, -4.1817,  4.1391],\n",
            "        [ 3.6749, -3.5465, -3.2261],\n",
            "        [-2.2450, -0.0382, -0.8115],\n",
            "        [-4.9062, -4.3426,  4.8292],\n",
            "        [-4.6352, -2.9939,  3.0000],\n",
            "        [-3.9032, -4.6974,  4.1605],\n",
            "        [ 3.9101, -3.5873, -3.1904],\n",
            "        [-4.2160, -3.8830,  4.0931],\n",
            "        [-4.2548, -4.1988,  4.5640],\n",
            "        [-3.9453, -3.6652,  4.0250],\n",
            "        [ 1.9649, -2.5011, -3.2601],\n",
            "        [-4.5035, -4.2932,  4.2278]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6802, -0.0829, -1.6507],\n",
            "        [-4.7513, -4.1599,  4.4325],\n",
            "        [-5.0593, -4.2586,  4.3214],\n",
            "        [-4.7791, -4.0104,  4.1374],\n",
            "        [-4.6006, -4.1162,  4.7958],\n",
            "        [ 3.7716, -4.1814, -4.1567],\n",
            "        [-3.3637,  2.7684, -2.7493],\n",
            "        [-4.6406, -4.3210,  4.5282],\n",
            "        [ 4.2210, -3.6649, -2.7672],\n",
            "        [-4.1481, -4.7264,  3.9691],\n",
            "        [-4.0243, -4.2764,  4.1730],\n",
            "        [-3.9768, -3.8993,  4.7326],\n",
            "        [-4.3561, -4.4811,  4.5208],\n",
            "        [-4.5839, -4.5801,  4.0900],\n",
            "        [ 1.1248, -1.0681, -4.0819],\n",
            "        [-4.1809, -3.6077,  4.2367]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.3353, -4.1894,  3.9713],\n",
            "        [ 3.2604, -3.5784, -3.2906],\n",
            "        [ 4.3460, -3.9423, -3.6739],\n",
            "        [-3.8068,  1.7757, -2.0462],\n",
            "        [-4.8062, -4.6870,  4.7252],\n",
            "        [-3.1119,  0.0648, -0.4230],\n",
            "        [-4.4917, -4.5657,  4.5238],\n",
            "        [-4.2065, -4.3964,  4.2476],\n",
            "        [ 3.8811, -4.0036, -3.4742],\n",
            "        [-5.3822, -2.5004,  2.5449],\n",
            "        [-4.5247,  0.3468, -0.5003],\n",
            "        [-3.9434,  2.1023, -2.5058],\n",
            "        [ 3.2815, -4.1766, -3.2672],\n",
            "        [-5.0273, -4.1752,  4.5668],\n",
            "        [-5.0852, -4.1616,  4.2955],\n",
            "        [-5.0747, -4.0478,  4.4578]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.9503, -4.1490,  4.1137],\n",
            "        [ 2.3286, -2.8409, -3.4278],\n",
            "        [ 1.3657, -1.3355, -4.1391],\n",
            "        [-4.9285, -3.7463,  4.6857],\n",
            "        [ 3.6952, -3.7836, -3.4904],\n",
            "        [-4.9485, -3.9954,  4.6568],\n",
            "        [-4.7834, -4.4274,  4.6937],\n",
            "        [-3.0449,  2.7726, -3.6448],\n",
            "        [-4.4507, -3.5575,  3.3725],\n",
            "        [ 4.3572, -4.0879, -3.7335],\n",
            "        [-4.5379, -4.3631,  4.5057],\n",
            "        [-4.7287, -3.7111,  3.7054],\n",
            "        [-4.9433, -3.0631,  3.6261],\n",
            "        [-4.6520, -4.7662,  4.5097],\n",
            "        [ 3.3217, -3.5020, -3.4419],\n",
            "        [-4.9899, -4.0025,  4.5405]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.4573,  2.9241, -2.0367],\n",
            "        [-4.5093, -4.3218,  4.0848],\n",
            "        [-3.9347, -4.6182,  4.3690],\n",
            "        [-5.0640, -3.7453,  4.1430],\n",
            "        [-3.0861,  3.4229, -3.4317],\n",
            "        [-5.0250, -3.8097,  4.5365],\n",
            "        [-4.6381, -4.1600,  4.1597],\n",
            "        [-4.5710, -3.9999,  3.8711],\n",
            "        [-4.8163, -4.1938,  3.8836],\n",
            "        [-4.7662, -4.1208,  4.1311],\n",
            "        [-4.7696, -2.7745,  3.2528],\n",
            "        [-5.0339, -3.9298,  4.4039],\n",
            "        [-4.6809, -4.6665,  4.4228],\n",
            "        [-4.3166, -4.8128,  4.6537],\n",
            "        [-4.8040, -4.2697,  4.7989],\n",
            "        [-4.3715, -3.9303,  4.0840]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.1223, -4.5639,  4.2542],\n",
            "        [-5.1330, -3.9763,  4.4690],\n",
            "        [-4.4389,  1.4945, -0.4352],\n",
            "        [-3.9397,  3.7277, -3.0369],\n",
            "        [ 3.1493, -3.5640, -3.5658],\n",
            "        [-3.3548,  3.2090, -2.6264],\n",
            "        [ 3.8451, -3.8249, -3.4051],\n",
            "        [-4.7757, -4.0383,  4.4559],\n",
            "        [-4.8281, -3.9385,  4.5598],\n",
            "        [-4.1204, -3.7984,  4.1392],\n",
            "        [-2.9255,  2.3728, -3.3622],\n",
            "        [-3.7354,  3.2462, -3.5683],\n",
            "        [-3.2931,  4.3158, -3.1526],\n",
            "        [ 3.0251, -3.4081, -3.0295],\n",
            "        [-4.2315, -4.5425,  4.4698],\n",
            "        [ 3.6651, -3.1506, -4.1628]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.9891,  3.1050, -3.0966],\n",
            "        [-4.6660, -4.3003,  4.0357],\n",
            "        [-4.7854, -4.7283,  4.2212],\n",
            "        [-4.5589, -3.6631,  3.7661],\n",
            "        [-4.5105, -3.4046,  3.3868],\n",
            "        [-4.5535, -3.5600,  3.3774],\n",
            "        [-3.9424, -3.8665,  4.2315],\n",
            "        [-4.7795, -4.3982,  3.4712],\n",
            "        [-4.4865, -4.3594,  4.1377],\n",
            "        [ 3.8466, -2.8647, -4.4572],\n",
            "        [-4.4387, -4.0285,  3.7072],\n",
            "        [-4.8403, -4.1030,  4.1936],\n",
            "        [ 0.4921, -0.7244, -3.8209],\n",
            "        [-4.8755, -4.2197,  4.0483],\n",
            "        [-5.2363, -4.1619,  4.6901],\n",
            "        [-4.5042, -3.8666,  3.9981]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.8073, -3.7986, -4.2805],\n",
            "        [ 3.0931, -3.6016, -3.3101],\n",
            "        [ 4.0034, -4.4025, -3.6405],\n",
            "        [ 3.8529, -4.0398, -3.5259],\n",
            "        [-2.8734,  2.8115, -3.5586],\n",
            "        [-4.0772, -0.0727,  0.8195],\n",
            "        [ 4.4431, -3.4306, -3.4123],\n",
            "        [ 0.8985, -1.4765, -3.8611],\n",
            "        [-3.4457,  2.9530, -2.6854],\n",
            "        [ 3.7553, -3.9366, -3.8800],\n",
            "        [ 4.2127, -4.0243, -3.3572],\n",
            "        [-5.2949, -4.7411,  4.5037],\n",
            "        [ 2.4803, -2.8438, -3.1596],\n",
            "        [ 3.2615, -3.8249, -3.1181],\n",
            "        [-0.9917,  0.6731, -3.3195],\n",
            "        [-4.2913, -4.2984,  4.5788]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4891, -0.0359, -4.0263],\n",
            "        [-4.3718, -4.4839,  4.1252],\n",
            "        [ 2.4241, -3.0523, -3.1439],\n",
            "        [ 3.8726, -3.1163, -3.8489],\n",
            "        [-4.2161,  3.5049, -3.2814],\n",
            "        [ 3.3110, -4.0728, -3.6805],\n",
            "        [ 3.5339, -3.8248, -3.9027],\n",
            "        [-1.2518,  1.6474, -4.1443],\n",
            "        [-4.8125, -4.0902,  4.7072],\n",
            "        [-4.8830, -3.5298,  3.8465],\n",
            "        [ 3.4329, -3.5363, -3.9427],\n",
            "        [ 4.1457, -3.9304, -3.4224],\n",
            "        [-1.9750,  2.3122, -3.7909],\n",
            "        [-4.4935, -4.0746,  4.2321],\n",
            "        [-4.1559, -3.6994,  3.7219],\n",
            "        [-4.1891, -4.8906,  3.9224]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.6484, -2.8830, -4.2124],\n",
            "        [-2.4250,  2.8365, -4.0088],\n",
            "        [-1.9055, -1.7054,  0.3405],\n",
            "        [-4.6526, -4.4112,  3.6673],\n",
            "        [-4.3152, -4.2643,  4.3282],\n",
            "        [-4.4016, -3.1209,  4.0910],\n",
            "        [-2.4714,  2.2260, -3.6833],\n",
            "        [-3.9344, -4.4216,  4.0390],\n",
            "        [ 2.7982, -2.5677, -3.5774],\n",
            "        [-4.6432, -3.7321,  3.0182],\n",
            "        [-3.0608,  2.9560, -2.8286],\n",
            "        [-4.8287, -4.3840,  4.3849],\n",
            "        [-2.5634,  2.0757, -3.1502],\n",
            "        [-5.1616, -4.5171,  4.0002],\n",
            "        [-4.6528, -4.0042,  4.2167],\n",
            "        [-5.0716, -4.8514,  4.1102]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.8177, -4.3641,  4.1766],\n",
            "        [-4.7034, -4.0669,  4.0820],\n",
            "        [ 3.5564, -3.1255, -3.7684],\n",
            "        [ 3.6389, -3.7452, -3.6776],\n",
            "        [ 3.4080, -3.4607, -4.0765],\n",
            "        [-4.8762, -2.7269,  3.0475],\n",
            "        [ 0.7322, -1.1539, -2.9101],\n",
            "        [-2.8010,  0.9780, -2.0513],\n",
            "        [-4.4207, -3.9357,  3.9645],\n",
            "        [ 3.6473, -3.4022, -3.3777],\n",
            "        [-4.7237, -3.9339,  4.2166],\n",
            "        [-4.9207, -3.7857,  3.5634],\n",
            "        [-3.1140,  3.3195, -3.8610],\n",
            "        [ 3.3344, -3.6210, -3.9389],\n",
            "        [-4.7721, -4.4150,  4.0741],\n",
            "        [-5.2820, -4.0087,  4.3321]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.0487, -4.6166,  3.8362],\n",
            "        [-3.3742,  0.3057, -0.8336],\n",
            "        [-4.6713, -3.7567,  3.9006],\n",
            "        [-5.1396, -4.0029,  4.5290],\n",
            "        [-3.3619,  2.6989, -2.2440],\n",
            "        [-4.3086, -4.7553,  3.8505],\n",
            "        [-5.1269, -4.5270,  4.2358],\n",
            "        [-5.0511, -4.4493,  4.5196],\n",
            "        [-3.2826,  2.7166, -2.8589],\n",
            "        [ 4.2610, -3.9994, -3.5992],\n",
            "        [-4.9826, -4.4955,  4.8214],\n",
            "        [-3.3075,  3.6418, -3.5714],\n",
            "        [-4.4730, -4.1628,  3.9779],\n",
            "        [-4.6344, -4.3926,  3.9650],\n",
            "        [ 4.1562, -3.9054, -3.6226],\n",
            "        [-2.2689,  2.2149, -3.6698]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.7748, -0.6197,  0.9545],\n",
            "        [-3.1507,  3.2238, -3.4050],\n",
            "        [-4.6613, -3.8314,  3.7942],\n",
            "        [-2.8669,  3.0878, -4.3326],\n",
            "        [-2.8125,  3.2948, -3.8635],\n",
            "        [-4.9978, -3.9323,  4.1773],\n",
            "        [-2.3376,  2.7548, -3.1986],\n",
            "        [-5.4044, -4.4983,  4.5963],\n",
            "        [-4.1319,  3.4928, -2.8702],\n",
            "        [-4.6614, -4.3216,  4.5248],\n",
            "        [-3.9790, -4.4198,  3.7861],\n",
            "        [-5.1000, -3.4125,  3.8674],\n",
            "        [-5.1888, -4.3110,  4.5402],\n",
            "        [ 3.7793, -4.1022, -3.0610],\n",
            "        [ 3.9715, -3.6610, -4.1077],\n",
            "        [ 3.5387, -3.8309, -2.9259]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.5530, -3.8279,  4.1354],\n",
            "        [ 3.7355, -4.0685, -3.3254],\n",
            "        [-4.9521, -4.2552,  3.9858],\n",
            "        [-4.1135, -3.7452,  4.1412],\n",
            "        [-2.8300,  3.0025, -3.6681],\n",
            "        [-4.2274, -3.3455,  3.1287],\n",
            "        [ 2.9999, -3.0049, -3.4299],\n",
            "        [ 2.9261, -3.3629, -2.7178],\n",
            "        [-5.3890, -3.7521,  4.1380],\n",
            "        [-3.6820,  3.3778, -3.2605],\n",
            "        [ 2.5325, -1.4410, -4.0320],\n",
            "        [-1.4424,  1.3038, -2.8323],\n",
            "        [-4.1922, -4.1592,  3.7444],\n",
            "        [ 3.2842, -3.5401, -4.4410],\n",
            "        [-2.4217,  2.9578, -3.3530],\n",
            "        [ 3.2151, -3.2541, -3.5963]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.1942,  0.9435, -1.1035],\n",
            "        [-4.8359, -4.3909,  4.2194],\n",
            "        [-5.0308, -4.2233,  4.5288],\n",
            "        [-2.4942,  2.7714, -3.3283],\n",
            "        [-4.1800,  1.3632, -1.1155],\n",
            "        [-3.5191,  3.4014, -3.1909],\n",
            "        [ 3.3235, -3.6876, -3.0467],\n",
            "        [ 4.0906, -3.2501, -4.0040],\n",
            "        [-4.7817,  0.1635,  0.5961],\n",
            "        [-4.6543, -4.2927,  4.8912],\n",
            "        [-5.2358, -4.4917,  4.6834],\n",
            "        [ 4.3545, -3.4240, -3.7517],\n",
            "        [-5.0632, -4.1151,  4.4328],\n",
            "        [-1.4767,  0.0176, -1.5802],\n",
            "        [-3.0789,  2.9594, -2.0371],\n",
            "        [-4.7761, -4.1836,  4.3235]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-5.3266, -4.3313,  4.1125],\n",
            "        [ 3.8851, -3.4618, -3.2246],\n",
            "        [-2.6986,  2.3273, -3.4012],\n",
            "        [-4.6331, -4.1660,  3.7948],\n",
            "        [-4.5529, -3.8685,  4.3724],\n",
            "        [-4.5862, -4.5204,  4.7441],\n",
            "        [-3.8852, -3.5971,  4.0568],\n",
            "        [-4.5803, -2.8338,  3.3415],\n",
            "        [ 3.0374, -3.3494, -3.6296],\n",
            "        [-4.9027, -3.7239,  3.7762],\n",
            "        [ 4.0890, -3.6422, -4.0377],\n",
            "        [-4.3792, -4.1843,  3.6527],\n",
            "        [ 3.3461, -3.7394, -3.4756],\n",
            "        [-5.0303, -3.7637,  3.6622],\n",
            "        [-5.2286, -4.0003,  3.9320],\n",
            "        [-4.6528, -3.3835,  3.7972]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.8461, -4.1227,  3.5880],\n",
            "        [-3.9606, -4.6813,  3.9004],\n",
            "        [ 3.9699, -3.5860, -3.0458],\n",
            "        [ 3.4562, -4.1049, -3.6399],\n",
            "        [-3.6047, -1.4082,  1.4704],\n",
            "        [-4.2434, -3.8534,  3.7848],\n",
            "        [-4.9886, -4.7144,  4.4515],\n",
            "        [ 4.0923, -4.3898, -3.4431],\n",
            "        [-4.9118, -4.1135,  3.8910],\n",
            "        [-2.5964,  2.6540, -4.1762],\n",
            "        [-5.4934, -3.0596,  3.8862],\n",
            "        [-4.1009, -3.9676,  4.3407],\n",
            "        [-3.5651,  3.6262, -3.3991],\n",
            "        [-4.4653, -2.9905,  3.2629],\n",
            "        [-1.5496, -1.4862,  0.1785],\n",
            "        [-4.4620, -2.6565,  3.1311]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.7626, -3.5146,  3.4771],\n",
            "        [-5.1662, -4.2754,  4.6233],\n",
            "        [-4.6537, -3.3198,  3.1825],\n",
            "        [-5.4661, -0.6907,  0.7149],\n",
            "        [-2.0377,  2.2395, -2.9045],\n",
            "        [ 3.1773, -3.1956, -3.4793],\n",
            "        [-2.7877,  1.8053, -2.0455],\n",
            "        [-4.4014, -2.5901,  2.5644],\n",
            "        [-2.6957,  3.2393, -3.8213],\n",
            "        [-4.9451, -2.6565,  2.8410],\n",
            "        [-4.7235, -3.7185,  3.9402],\n",
            "        [-4.4345, -3.9726,  4.2715],\n",
            "        [-4.9017, -3.3517,  3.5129],\n",
            "        [-5.3026, -2.8568,  3.3069],\n",
            "        [ 3.1768, -3.2060, -3.7845],\n",
            "        [-3.2674,  3.5183, -3.3230]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.3687,  2.1206, -2.1910],\n",
            "        [-4.1788, -4.4778,  4.1893],\n",
            "        [-4.6302, -4.0358,  3.9580],\n",
            "        [-4.8581, -5.1105,  5.2019],\n",
            "        [-2.4446,  3.5228, -3.7730],\n",
            "        [-4.5613, -4.4721,  4.4799],\n",
            "        [-4.6138, -3.9019,  4.2562],\n",
            "        [-5.0118, -4.4807,  4.5870],\n",
            "        [-4.5097, -4.4624,  4.0700],\n",
            "        [-4.4391, -4.1154,  4.1813],\n",
            "        [ 2.7668, -3.1751, -4.0813],\n",
            "        [-3.8988, -4.5080,  3.7502],\n",
            "        [-2.8151,  2.7965, -2.6466],\n",
            "        [-4.4330, -3.9140,  4.2529],\n",
            "        [-4.7877, -4.4162,  4.2270],\n",
            "        [-3.9474, -4.1446,  4.2293]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2279, -1.9460, -4.4306],\n",
            "        [-4.9975, -3.4827,  3.0138],\n",
            "        [-4.3009, -3.3957,  3.3492],\n",
            "        [-4.9285, -4.6051,  3.8215],\n",
            "        [-4.8104, -3.2973,  3.4589],\n",
            "        [ 3.5478, -3.8556, -3.1468],\n",
            "        [-4.6303, -3.7254,  3.5731],\n",
            "        [-5.2126, -3.4563,  3.1982],\n",
            "        [ 3.5288, -3.4521, -4.4140],\n",
            "        [-5.1388, -4.6029,  4.6820],\n",
            "        [-4.9462, -4.1690,  4.7046],\n",
            "        [-4.8105, -4.2891,  4.1278],\n",
            "        [-4.6344, -3.8673,  4.2319],\n",
            "        [-4.6352, -1.6719,  2.4373],\n",
            "        [ 3.7534, -3.7067, -3.0106],\n",
            "        [-0.4588,  1.3422, -4.5202]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.4814, -4.7239,  4.3416],\n",
            "        [ 3.4980, -3.5597, -3.6002],\n",
            "        [-2.9243, -3.3995,  1.5290],\n",
            "        [-4.5024, -4.2288,  3.8948],\n",
            "        [-4.5929, -4.6007,  4.8795],\n",
            "        [-5.3644, -3.0890,  3.1221],\n",
            "        [-4.7875, -4.0868,  4.3735],\n",
            "        [-4.8840, -3.4911,  4.4522],\n",
            "        [-2.8002,  2.3699, -2.6029],\n",
            "        [-4.7231, -2.4928,  3.0226],\n",
            "        [-5.1009, -3.2318,  3.9291],\n",
            "        [-4.8057, -3.9698,  4.3308],\n",
            "        [ 3.8091, -2.9689, -4.0283],\n",
            "        [-4.4710, -2.8636,  2.5584],\n",
            "        [ 0.3467, -0.2728, -4.7645],\n",
            "        [-4.9906, -4.1595,  3.5116]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.4738,  2.4298, -3.6454],\n",
            "        [-4.3344, -4.5868,  4.2692],\n",
            "        [ 1.7720, -1.6106, -3.9175],\n",
            "        [-4.3880, -4.1841,  2.9130],\n",
            "        [-4.6845, -4.0370,  4.0068],\n",
            "        [-4.7851, -4.5278,  4.2913],\n",
            "        [-3.4673,  3.6337, -3.8405],\n",
            "        [-4.2508, -4.4935,  4.0730],\n",
            "        [-4.5511, -3.8713,  4.4861],\n",
            "        [-4.2595, -4.5070,  3.9640],\n",
            "        [-3.7364, -3.9055,  3.7445],\n",
            "        [-4.9586, -3.8340,  3.3430],\n",
            "        [-4.5488, -3.3638,  2.9392],\n",
            "        [ 3.5607, -3.3218, -3.5783],\n",
            "        [-4.7908, -4.5801,  4.4773],\n",
            "        [-4.9286, -3.8560,  3.9858]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-5.1666, -2.9692,  3.7108],\n",
            "        [ 0.6089, -1.3085, -3.0444],\n",
            "        [ 3.2988, -3.7484, -3.0764],\n",
            "        [-3.3032,  1.3917, -2.2327],\n",
            "        [ 0.9028, -1.9180, -2.7285],\n",
            "        [-2.8920,  1.5825, -2.3238],\n",
            "        [-4.7369, -4.1557,  4.1836],\n",
            "        [-2.9778,  2.9089, -3.4083],\n",
            "        [-5.0105, -2.6345,  3.0963],\n",
            "        [-4.8509, -4.2063,  4.2644],\n",
            "        [-3.1048,  3.6822, -3.4566],\n",
            "        [-4.5069, -3.3837,  4.1684],\n",
            "        [-4.3884, -2.0673,  2.3379],\n",
            "        [-4.2552, -4.2752,  4.5369],\n",
            "        [-4.5399, -4.1632,  4.1729],\n",
            "        [-4.8807, -3.8375,  4.3349]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.9767, -4.4643,  4.5913],\n",
            "        [ 1.1125, -2.3515, -3.0481],\n",
            "        [-4.5560, -3.4175,  4.0994],\n",
            "        [-3.4196,  0.1743, -0.7316],\n",
            "        [-0.0581, -0.0063, -3.7810],\n",
            "        [-4.8545, -4.5160,  4.2808],\n",
            "        [ 3.8682, -3.3343, -3.2416],\n",
            "        [-4.1628, -3.4546,  4.2476],\n",
            "        [-4.5676, -3.1679,  3.9248],\n",
            "        [-4.7327, -4.1985,  4.5149],\n",
            "        [-4.4624, -4.0448,  4.7545],\n",
            "        [-5.0535, -4.7817,  4.5029],\n",
            "        [ 3.3175, -3.6526, -3.1258],\n",
            "        [-4.6777, -4.1420,  3.9997],\n",
            "        [-5.3968, -3.4160,  3.5506],\n",
            "        [-4.4606, -3.5483,  3.8260]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.8685, -3.6364,  2.8537],\n",
            "        [-5.0278, -4.2026,  4.3040],\n",
            "        [-3.8937, -4.0623,  3.9464],\n",
            "        [-4.7528, -3.9194,  4.2472],\n",
            "        [-4.2775, -3.7274,  4.2004],\n",
            "        [-4.9254, -4.7137,  4.5862],\n",
            "        [-3.8948, -1.4184,  1.2603],\n",
            "        [-4.5552, -4.0904,  4.1953],\n",
            "        [-4.8809, -3.8187,  4.2978],\n",
            "        [-3.3436,  3.5399, -3.0784],\n",
            "        [ 3.0808, -3.8398, -2.7538],\n",
            "        [ 3.5541, -3.2598, -4.4035],\n",
            "        [-4.2914, -4.2118,  3.8857],\n",
            "        [-4.2985, -4.2356,  4.1517],\n",
            "        [ 1.4654, -2.8345, -2.9296],\n",
            "        [-4.3799, -4.8129,  3.6450]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.4390, -3.7792,  3.8682],\n",
            "        [-2.2871,  0.3222, -1.5707],\n",
            "        [-1.0866,  0.9901, -4.1533],\n",
            "        [-3.7818, -3.9310,  3.9363],\n",
            "        [-4.2690, -3.8785,  3.6262],\n",
            "        [ 3.4249, -3.6392, -3.7920],\n",
            "        [ 2.3807, -2.9533, -3.5403],\n",
            "        [-4.6783, -4.5038,  4.4374],\n",
            "        [-2.9038,  2.2734, -2.3094],\n",
            "        [-4.2091, -4.4468,  3.7423],\n",
            "        [-4.6998, -4.5373,  4.5016],\n",
            "        [-4.8277, -4.6315,  4.3131],\n",
            "        [-4.1962, -4.0157,  4.2769],\n",
            "        [-4.5441, -3.9628,  3.6634],\n",
            "        [-4.5889, -4.1714,  3.7441],\n",
            "        [ 3.8483, -3.8755, -4.0203]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-5.0797, -4.3311,  4.2797],\n",
            "        [ 3.7149, -4.2612, -3.4205],\n",
            "        [ 3.8383, -3.5751, -3.1462],\n",
            "        [ 3.6026, -3.7080, -3.4741],\n",
            "        [-3.4126,  2.5545, -2.3227],\n",
            "        [ 3.1879, -3.4917, -3.1342],\n",
            "        [-4.5990, -4.0803,  4.6235],\n",
            "        [-2.1057,  1.4725, -2.0073],\n",
            "        [-3.7146,  3.2677, -3.4556],\n",
            "        [-3.4828,  3.1618, -3.1290],\n",
            "        [-4.8653, -4.8383,  4.6000],\n",
            "        [-5.2004, -3.1663,  3.3659],\n",
            "        [-4.6462, -4.2046,  4.3539],\n",
            "        [ 4.0081, -3.8580, -3.2362],\n",
            "        [-4.5728, -4.3306,  4.4014],\n",
            "        [-4.7572, -4.6706,  4.4294]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8492,  0.6779, -3.2121],\n",
            "        [-4.7673, -4.5271,  4.0000],\n",
            "        [ 3.0668, -3.4777, -4.0079],\n",
            "        [ 3.8677, -3.1935, -3.5023],\n",
            "        [ 2.7759, -3.2190, -3.4934],\n",
            "        [-4.4282, -4.2333,  4.5980],\n",
            "        [-0.6629,  0.6728, -2.5099],\n",
            "        [-4.4763, -4.5342,  4.0584],\n",
            "        [-5.1456, -3.5052,  4.3951],\n",
            "        [ 3.0228, -2.8818, -3.8098],\n",
            "        [-5.0700, -3.9499,  4.3979],\n",
            "        [-4.4888, -4.0337,  4.7589],\n",
            "        [-2.4026, -1.8329,  0.6801],\n",
            "        [-5.1055, -4.3900,  4.9648],\n",
            "        [-3.2612, -0.8099,  0.3824],\n",
            "        [ 4.2207, -4.1858, -3.9385]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-5.1514, -4.7193,  4.3318],\n",
            "        [-4.5550, -4.4123,  4.5600],\n",
            "        [-5.0391, -4.3255,  4.4981],\n",
            "        [-4.9107, -4.4271,  4.5232],\n",
            "        [-4.0039, -4.1203,  3.2839],\n",
            "        [-2.8864,  3.1494, -3.0254],\n",
            "        [-2.6881,  3.0323, -3.2792],\n",
            "        [-4.2583, -4.3528,  4.3869],\n",
            "        [-4.5936, -3.4460,  3.9726],\n",
            "        [-2.1976, -0.8889, -0.1514],\n",
            "        [-4.8889, -4.2566,  4.2206],\n",
            "        [-4.3249, -3.2952,  2.6338],\n",
            "        [-1.6049,  2.4665, -4.4324],\n",
            "        [-4.0627, -4.1453,  4.3384],\n",
            "        [-4.0883, -4.4195,  4.1417],\n",
            "        [-4.2331, -4.2839,  3.5479]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.5443, -3.6356, -4.1728],\n",
            "        [-4.6080, -4.6179,  3.6632],\n",
            "        [-4.4947, -4.3026,  4.2127],\n",
            "        [ 3.2857, -3.2812, -3.5902],\n",
            "        [-4.4661, -4.1447,  3.7934],\n",
            "        [-4.5944, -4.5870,  4.5506],\n",
            "        [-4.1905, -4.2015,  4.4505],\n",
            "        [-4.5758, -4.2798,  4.6880],\n",
            "        [-4.4233, -4.0384,  4.2877],\n",
            "        [-3.2959,  2.9008, -2.2034],\n",
            "        [ 2.1012, -2.5042, -2.5327],\n",
            "        [-3.1770,  2.0201, -2.5330],\n",
            "        [-5.0288, -4.2817,  5.1358],\n",
            "        [-4.6790, -4.0676,  3.4668],\n",
            "        [-3.7567, -3.6140,  3.6441],\n",
            "        [-4.5461, -3.4512,  4.1725]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.9227, -3.7026, -3.1844],\n",
            "        [ 4.0132, -3.4231, -3.6807],\n",
            "        [-4.0096, -3.2866,  3.2658],\n",
            "        [-4.5059, -4.2201,  4.0937],\n",
            "        [-4.3930, -3.5506,  4.5285],\n",
            "        [-4.8089, -4.6345,  3.9793],\n",
            "        [-4.6788, -4.5470,  4.3097],\n",
            "        [-3.9966, -4.1061,  3.3703],\n",
            "        [-4.3851, -3.8628,  4.8271],\n",
            "        [-4.8210, -4.2785,  3.8345],\n",
            "        [-4.6035, -4.2258,  4.3510],\n",
            "        [-3.9355, -4.2063,  4.0042],\n",
            "        [-4.6468, -2.9315,  3.3448],\n",
            "        [-3.8486, -3.6970,  3.6188],\n",
            "        [-1.1863,  0.8708, -1.5167],\n",
            "        [-4.7373, -4.8136,  4.3022]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.8944, -5.0661,  4.6261],\n",
            "        [ 3.5547, -4.5021, -3.4337],\n",
            "        [-4.5530, -4.8807,  3.8724],\n",
            "        [-4.5585, -4.1642,  4.2941],\n",
            "        [-4.9086, -4.4650,  3.7648],\n",
            "        [-4.5523, -4.7163,  4.4159],\n",
            "        [-4.8402, -4.1995,  4.6306],\n",
            "        [-4.0118, -4.4169,  3.7062],\n",
            "        [ 3.3417, -4.0758, -3.5167],\n",
            "        [-4.3615, -4.9942,  4.5308],\n",
            "        [-1.7913,  1.5192, -3.7156],\n",
            "        [-4.6654, -4.2076,  4.4555],\n",
            "        [ 0.2866,  0.4645, -4.1681],\n",
            "        [-4.3485, -4.0183,  4.1305],\n",
            "        [-4.3817, -4.3217,  4.1660],\n",
            "        [ 3.3529, -3.7660, -2.8854]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.8987,  2.8931, -2.9447],\n",
            "        [-2.5680,  3.3304, -3.1492],\n",
            "        [-2.8606, -4.8217,  2.8418],\n",
            "        [-4.5176, -4.2283,  3.9365],\n",
            "        [-4.7844, -4.4336,  4.5141],\n",
            "        [-4.0479, -4.3675,  4.1032],\n",
            "        [ 3.7342, -3.9262, -3.5554],\n",
            "        [-4.9529, -4.2276,  4.4147],\n",
            "        [-0.1677, -2.6403, -1.1802],\n",
            "        [-4.5001, -3.7778,  4.1487],\n",
            "        [-4.1855, -4.1659,  4.6780],\n",
            "        [ 3.1669, -3.5512, -3.3823],\n",
            "        [-4.7534, -4.2203,  4.2518],\n",
            "        [-4.9583, -4.3594,  4.3080],\n",
            "        [-4.2090, -4.1556,  4.2281],\n",
            "        [ 3.7626, -3.1966, -3.2258]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.7982, -5.0826,  4.1322],\n",
            "        [-4.6527, -4.0705,  4.1755],\n",
            "        [ 3.7722, -3.5291, -3.7280],\n",
            "        [ 3.5981, -3.8091, -3.5583],\n",
            "        [ 3.7388, -3.8437, -3.1322],\n",
            "        [ 4.0084, -3.8904, -3.8903],\n",
            "        [-3.9950, -4.6261,  4.3324],\n",
            "        [-4.4125, -4.2636,  4.1945],\n",
            "        [ 3.4628, -3.9364, -4.1744],\n",
            "        [-3.0982,  2.1474, -2.3698],\n",
            "        [-2.6189,  3.4675, -3.4510],\n",
            "        [-4.4653, -3.7442,  2.9627],\n",
            "        [-4.2383, -4.5328,  4.6074],\n",
            "        [ 3.4331, -3.7892, -3.8235],\n",
            "        [-2.4189,  1.4805, -2.3679],\n",
            "        [-4.6633, -4.5587,  4.4746]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.7933, -3.8356, -3.7301],\n",
            "        [-5.0091, -4.3671,  4.5392],\n",
            "        [-4.0504, -4.4532,  4.0618],\n",
            "        [-4.6145, -4.8009,  4.0854],\n",
            "        [-4.5988, -4.1687,  2.9915],\n",
            "        [-3.3082,  2.2883, -2.6022],\n",
            "        [-4.5943, -4.0663,  4.4301],\n",
            "        [-4.6603, -4.5122,  4.0945],\n",
            "        [-2.6370,  3.8678, -3.6091],\n",
            "        [-5.2398, -4.9687,  4.7199],\n",
            "        [-4.4976, -4.1008,  4.7264],\n",
            "        [ 2.9849, -3.9686, -2.9276],\n",
            "        [-4.6624, -4.4152,  4.2763],\n",
            "        [-4.3190, -4.4766,  3.7307],\n",
            "        [-3.9924, -4.1237,  4.5689],\n",
            "        [ 1.7392, -2.3337, -3.3389]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.6800,  3.2062, -2.5895],\n",
            "        [-2.8664,  3.6198, -3.6474],\n",
            "        [-4.2419, -4.5461,  4.0918],\n",
            "        [ 4.1784, -3.9624, -3.5161],\n",
            "        [-4.1771, -4.6080,  3.7885],\n",
            "        [-3.3564, -2.5987,  1.5304],\n",
            "        [-4.3303, -3.8110,  4.0683],\n",
            "        [-5.0059, -4.9619,  4.3575],\n",
            "        [-4.7254, -4.3841,  4.5571],\n",
            "        [-3.8869, -4.6074,  4.6606],\n",
            "        [-4.5659, -4.0566,  3.9780],\n",
            "        [-4.6203, -4.7284,  5.1705],\n",
            "        [-4.3973, -4.6328,  4.7333],\n",
            "        [-4.2935, -3.8940,  4.6099],\n",
            "        [-4.5381, -4.2869,  4.2028],\n",
            "        [-3.9924, -3.7530,  3.2780]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.5685, -2.7614,  2.5485],\n",
            "        [-4.0036, -4.2782,  3.9587],\n",
            "        [-4.9686, -4.5875,  4.6076],\n",
            "        [-5.3165, -4.4405,  4.7189],\n",
            "        [-3.9149, -0.7096,  0.2357],\n",
            "        [-4.5632, -4.8260,  3.5799],\n",
            "        [-3.9586, -4.9240,  4.4192],\n",
            "        [-4.2341, -4.4292,  3.7076],\n",
            "        [-5.1543, -4.6441,  4.2673],\n",
            "        [-5.1729, -4.7725,  4.4619],\n",
            "        [-5.0827, -4.3278,  4.9838],\n",
            "        [ 3.1409, -3.5939, -3.4589],\n",
            "        [ 3.7570, -3.8685, -3.4123],\n",
            "        [ 4.0973, -4.1455, -3.9962],\n",
            "        [-4.5378, -4.0863,  4.0879],\n",
            "        [-0.9202,  1.5027, -4.1218]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.7858, -3.5301, -4.2585],\n",
            "        [-4.7065, -4.7808,  4.6914],\n",
            "        [ 3.9065, -3.7257, -3.9398],\n",
            "        [ 3.5421, -2.9422, -3.3652],\n",
            "        [-4.6438, -4.7083,  4.8546],\n",
            "        [ 2.3664, -3.0120, -2.6310],\n",
            "        [-3.9235, -4.4238,  4.4817],\n",
            "        [-4.3823, -4.7641,  4.1657],\n",
            "        [-5.0002, -4.3708,  4.8293],\n",
            "        [ 0.8888, -1.0718, -3.4689],\n",
            "        [-4.6034, -4.0853,  4.8128],\n",
            "        [-3.8042, -3.3599,  3.6230],\n",
            "        [-4.7095, -4.3549,  4.9440],\n",
            "        [ 3.8367, -3.4556, -3.8544],\n",
            "        [ 0.0590, -4.6109,  0.9016],\n",
            "        [-4.3902,  2.2400, -2.8772]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.2275, -4.1740,  4.2264],\n",
            "        [-3.4308,  0.3839, -1.1414],\n",
            "        [-4.6094, -4.2652,  4.0532],\n",
            "        [-0.4683, -0.2645, -2.3269],\n",
            "        [-4.8547, -4.1404,  4.5088],\n",
            "        [-4.7701, -4.5453,  3.8192],\n",
            "        [-2.1770,  0.6138, -2.2199],\n",
            "        [-4.2164, -3.8163,  3.5571],\n",
            "        [-1.6847,  2.2452, -3.6742],\n",
            "        [-4.7424, -3.5936,  3.7135],\n",
            "        [-4.0774, -4.1964,  4.0941],\n",
            "        [-4.5110, -4.2741,  3.8734],\n",
            "        [ 3.5992, -3.2522, -4.0604],\n",
            "        [-4.9148, -4.0485,  3.9246],\n",
            "        [-4.8249, -4.1252,  4.1602],\n",
            "        [-4.0159, -4.4238,  4.2483]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.9106, -3.7882, -3.6953],\n",
            "        [-3.9761, -4.4649,  3.6775],\n",
            "        [-1.1708,  1.0731, -2.9628],\n",
            "        [-4.9919, -4.2593,  4.7984],\n",
            "        [-1.0045, -0.5227, -1.0742],\n",
            "        [-4.5837, -5.3922,  4.1520],\n",
            "        [-4.2111, -4.6634,  4.4002],\n",
            "        [-4.9467, -2.4859,  2.1281],\n",
            "        [-4.7822, -4.2656,  3.8041],\n",
            "        [-3.8708, -4.7313,  4.0707],\n",
            "        [-4.2698, -4.5038,  4.2658],\n",
            "        [-2.7724,  1.6113, -2.2572],\n",
            "        [-4.1629, -3.7422,  3.2313],\n",
            "        [-4.7744, -4.7829,  4.2540],\n",
            "        [-5.2165, -3.8545,  3.7909],\n",
            "        [-4.7432, -4.3803,  4.6480]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.2524, -3.6105,  3.5428],\n",
            "        [-4.7383, -4.5620,  5.0314],\n",
            "        [ 0.1633,  0.0703, -3.8653],\n",
            "        [ 3.6558, -3.0237, -4.5179],\n",
            "        [-4.5057, -4.1255,  3.4681],\n",
            "        [ 3.4437, -3.4880, -3.6432],\n",
            "        [-4.3656, -4.4758,  3.9668],\n",
            "        [-4.4207, -4.3770,  3.9749],\n",
            "        [-5.1049, -4.7313,  5.0183],\n",
            "        [-4.2398, -3.3749,  3.1812],\n",
            "        [-4.4319, -3.6339,  3.9466],\n",
            "        [-4.5404, -3.4640,  4.1791],\n",
            "        [-4.6560, -4.6139,  4.4478],\n",
            "        [-4.4514, -4.6661,  4.1419],\n",
            "        [ 3.6006, -3.6738, -3.0391],\n",
            "        [ 3.3213, -3.5411, -4.1356]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2804, -0.3763, -4.3318],\n",
            "        [-4.3648, -3.9143,  3.0186],\n",
            "        [-3.8630, -4.8021,  3.8704],\n",
            "        [-4.4123, -4.1636,  4.1669],\n",
            "        [ 4.1245, -3.7432, -4.2122],\n",
            "        [-4.1512, -4.3817,  3.7104],\n",
            "        [ 3.7575, -3.8732, -4.4657],\n",
            "        [-3.9629, -4.4356,  4.4706],\n",
            "        [-2.4057, -0.5326, -0.8876],\n",
            "        [-4.4279, -3.9982,  4.3805],\n",
            "        [-2.8053,  2.4864, -3.4804],\n",
            "        [-5.2035, -4.4814,  4.8561],\n",
            "        [-4.7796, -3.3576,  3.8148],\n",
            "        [-4.0216,  3.0074, -3.0005],\n",
            "        [-4.4803, -3.3857,  4.4713],\n",
            "        [-4.5936, -4.1234,  4.3476]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.0846, -3.7866,  3.4021],\n",
            "        [-1.5197,  0.4038, -3.8424],\n",
            "        [-4.5077, -3.5012,  3.5043],\n",
            "        [ 3.6070, -3.8755, -3.6497],\n",
            "        [-4.9081, -4.3236,  4.3141],\n",
            "        [-4.5604, -2.6381,  2.9768],\n",
            "        [-4.0376, -3.5440,  3.2591],\n",
            "        [-5.0663, -3.7272,  4.4798],\n",
            "        [-4.2386, -4.0677,  3.7000],\n",
            "        [-3.9805, -4.3026,  4.1311],\n",
            "        [-4.5029, -2.3446,  2.0815],\n",
            "        [-3.8767, -4.4853,  3.8195],\n",
            "        [-3.0717, -2.8217,  2.2979],\n",
            "        [-4.8068, -3.7813,  3.9700],\n",
            "        [ 3.6066, -3.2943, -3.6047],\n",
            "        [-5.4613, -3.0015,  3.6206]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.7806, -4.4253,  4.6167],\n",
            "        [-1.1078,  0.8443, -4.5083],\n",
            "        [-4.2169, -4.5761,  3.6779],\n",
            "        [-2.6721,  3.4765, -3.7355],\n",
            "        [-4.4145, -4.1500,  3.9521],\n",
            "        [-4.0801, -4.4642,  2.9109],\n",
            "        [-4.3197, -4.7663,  4.3242],\n",
            "        [-1.0503, -2.5434,  0.6890],\n",
            "        [-3.0811,  3.4166, -2.7431],\n",
            "        [-4.4518, -2.3075,  2.1988],\n",
            "        [-5.0320, -5.0558,  4.9599],\n",
            "        [ 3.7870, -3.3672, -4.0866],\n",
            "        [-4.5575, -3.8908,  4.2729],\n",
            "        [-1.8444,  1.7668, -3.0571],\n",
            "        [-4.6705, -4.1520,  4.1263],\n",
            "        [-4.5107, -4.8468,  3.9451]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.7766, -4.1530,  4.5393],\n",
            "        [-5.4900, -4.3819,  4.4240],\n",
            "        [-3.3986,  3.6723, -3.6300],\n",
            "        [-4.9841, -3.9701,  3.6224],\n",
            "        [-4.7491, -4.1317,  4.3448],\n",
            "        [-4.4841, -2.8879,  2.4962],\n",
            "        [-4.5069, -4.4550,  4.5079],\n",
            "        [ 3.2972, -2.9374, -3.2727],\n",
            "        [ 3.4196, -3.8751, -3.8332],\n",
            "        [-2.9856,  2.5927, -3.1552],\n",
            "        [-4.8446, -4.2822,  4.3768],\n",
            "        [-4.8463, -4.2486,  3.9273],\n",
            "        [-4.8832, -3.3427,  4.0038],\n",
            "        [ 3.5436, -3.3342, -3.9160],\n",
            "        [-4.7237, -4.7483,  3.7462],\n",
            "        [-4.8945, -4.2125,  4.0248]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.6941, -4.5831,  4.4016],\n",
            "        [-5.1056, -3.9946,  4.4007],\n",
            "        [-3.4609, -4.0611,  2.5337],\n",
            "        [-2.7168,  3.6170, -4.0871],\n",
            "        [-1.0464,  0.9448, -4.2419],\n",
            "        [-2.9388,  3.7367, -3.0427],\n",
            "        [-4.9167, -4.2311,  4.3711],\n",
            "        [-4.9433, -2.9097,  2.7903],\n",
            "        [-4.4401, -4.3231,  4.2856],\n",
            "        [-4.9449, -4.5932,  4.1531],\n",
            "        [-2.9412,  3.3729, -3.4540],\n",
            "        [-0.3567,  0.2518, -3.3191],\n",
            "        [-5.2488, -4.0107,  4.3824],\n",
            "        [-3.9674, -3.8404,  3.0258],\n",
            "        [-2.9313,  3.5792, -3.4815],\n",
            "        [-4.3829, -4.3569,  4.1107]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.2989, -3.1004, -3.6336],\n",
            "        [-4.6495, -4.0745,  4.0853]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wep_15F993GH"
      },
      "source": [
        "def validation(epoch):\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float) \n",
        "            #print(targets.shape)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV7gJOVp4m72",
        "outputId": "d4db82f0-a68d-4b02-c459-8a298cbcb472"
      },
      "source": [
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    outputs, targets = validation(epoch)\n",
        "    outputs = np.array(outputs) >= 0.5\n",
        "    accuracy = metrics.accuracy_score(targets, outputs)\n",
        "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "    precision_score_micro = metrics.precision_score(targets, outputs, average='micro')\n",
        "    precision_score_macro = metrics.precision_score(targets, outputs, average='macro')\n",
        "    recall_score_micro = metrics.recall_score(targets, outputs, average='micro')\n",
        "    recall_score_macro = metrics.recall_score(targets, outputs, average='macro')\n",
        "    print(f\"Accuracy Score = {accuracy}\")\n",
        "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "    print(f\"F1 Score (Macro) = {f1_score_macro}\")\n",
        "    print(f\"precision_score (Micro) = {precision_score_micro}\")\n",
        "    print(f\"precision_score (Macro) = {precision_score_macro}\")\n",
        "    print(f\"recall_score (Micro) = {recall_score_micro}\")\n",
        "    print(f\"recall_score (Macro) = {recall_score_macro}\")\n",
        "    if accuracy > best_accuracy:\n",
        "      torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "      best_accuracy = accuracy"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score = 0.8392857142857143\n",
            "F1 Score (Micro) = 0.8491670418730302\n",
            "F1 Score (Macro) = 0.7950671912372246\n",
            "precision_score (Micro) = 0.8564940962761126\n",
            "precision_score (Macro) = 0.8067248079949612\n",
            "recall_score (Micro) = 0.8419642857142857\n",
            "recall_score (Macro) = 0.7897043432757719\n",
            "Accuracy Score = 0.8392857142857143\n",
            "F1 Score (Micro) = 0.8491670418730302\n",
            "F1 Score (Macro) = 0.7950671912372246\n",
            "precision_score (Micro) = 0.8564940962761126\n",
            "precision_score (Macro) = 0.8067248079949612\n",
            "recall_score (Micro) = 0.8419642857142857\n",
            "recall_score (Macro) = 0.7897043432757719\n",
            "Accuracy Score = 0.8392857142857143\n",
            "F1 Score (Micro) = 0.8491670418730302\n",
            "F1 Score (Macro) = 0.7950671912372246\n",
            "precision_score (Micro) = 0.8564940962761126\n",
            "precision_score (Macro) = 0.8067248079949612\n",
            "recall_score (Micro) = 0.8419642857142857\n",
            "recall_score (Macro) = 0.7897043432757719\n",
            "Accuracy Score = 0.8392857142857143\n",
            "F1 Score (Micro) = 0.8491670418730302\n",
            "F1 Score (Macro) = 0.7950671912372246\n",
            "precision_score (Micro) = 0.8564940962761126\n",
            "precision_score (Macro) = 0.8067248079949612\n",
            "recall_score (Micro) = 0.8419642857142857\n",
            "recall_score (Macro) = 0.7897043432757719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9sqpt6PK9p6",
        "outputId": "fdd79b59-953d-467a-e384-041813930ff2"
      },
      "source": [
        "class_names = ['Negative', 'Neutral', 'Positive']\n",
        "print(classification_report(outputs, targets, target_names=class_names))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.73      0.86      0.79       167\n",
            "     Neutral       0.73      0.63      0.68       229\n",
            "    Positive       0.90      0.93      0.91       705\n",
            "\n",
            "   micro avg       0.84      0.86      0.85      1101\n",
            "   macro avg       0.79      0.81      0.80      1101\n",
            "weighted avg       0.84      0.86      0.85      1101\n",
            " samples avg       0.84      0.84      0.84      1101\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF-WViMk-HBJ",
        "outputId": "cf5b2997-0097-498e-fc64-700a1b9f70a6"
      },
      "source": [
        "#class_names = ['Class_0', 'Class_1', 'Class_2']\n",
        "\n",
        "class_names = ['Negative', 'Neutral', 'Positive']\n",
        "#test_string = \"The shells were crisp and authentic, the filling was real ricotta cheese, not the fake junk a lot of Italian Places use these days.\"\n",
        "#test_string = \"The pizza and garlic bread are good, but the staff members are rude to us.\"\n",
        "test_string = \"The pizza and pasta are delicious, but the taste of garlic bread is not good.\"\n",
        "#at = \"staff members\"\n",
        "#at = \"garlic bread\"\n",
        "at = \"pasta\"\n",
        "#at = \"food\"\n",
        "#at = \"Italian Places\"\n",
        "\n",
        "inputs = tokenizer.encode_plus(\n",
        "            test_string,\n",
        "            at,\n",
        "            add_special_tokens=True,\n",
        "            max_length=80,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True,\n",
        "            return_tensors='pt',\n",
        ")\n",
        "\n",
        "input_ids = inputs['input_ids'].to(device)\n",
        "mask = inputs['attention_mask'].to(device)\n",
        "token_type_ids = inputs[\"token_type_ids\"].to(device)\n",
        "print(input_ids)\n",
        "print(mask)\n",
        "print(token_type_ids)\n",
        "\n",
        "target,  = model(input_ids, mask, token_type_ids)\n",
        "#output = model(input_ids, attention_mask)\n",
        "\n",
        "predict = torch.sigmoid(target)\n",
        "print(predict)\n",
        "\n",
        "predict = predict.cpu().detach().flatten().numpy()\n",
        "predictlabel = []\n",
        "\n",
        "for i, labelname in enumerate(class_names):\n",
        "  labelprob = predict[i]\n",
        "  if labelprob > 0.5:\n",
        "    predictlabel.append(labelname)\n",
        "predictlabel\n",
        "\n",
        "print(predictlabel)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  101,  1996, 10733,  1998, 24857,  2024, 12090,  1010,  2021,  1996,\n",
            "          5510,  1997, 20548,  7852,  2003,  2025,  2204,  1012,   102, 24857,\n",
            "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
            "       device='cuda:0')\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
            "tensor([0.0092, 0.0117, 0.9880], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "['Positive']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8Lt5wVVyH_n"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    }
  ]
}